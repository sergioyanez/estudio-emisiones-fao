import streamlit as st
import gdown
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import zipfile
import random
import numpy as np
import plotly.express as px
import pycountry
import geopandas as gpd
import plotly.graph_objects as go
import statsmodels.api as sm
import itertools
import time
import warnings
import logging

from statsmodels.tsa.statespace.sarimax import SARIMAX
from prophet import Prophet
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import STL
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import acf
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tools.sm_exceptions import ValueWarning
from sklearn.metrics import mean_absolute_percentage_error
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_absolute_percentage_error
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.stats.diagnostic import acorr_ljungbox
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.stats import norm
# Opcional: desactiva warnings excesivos
import warnings
warnings.filterwarnings("ignore")

st.set_page_config(
    page_title="TP Final - Ciencia de Datos",
    layout="wide"
)

st.title("üåç TP Final - Ciencia de Datos")
st.subheader("An√°lisis interactivo de emisiones de gases de efecto invernadero")
st.caption("Dataset FAOSTAT (1961‚Äì2021) ‚Ä¢ Visualizaci√≥n din√°mica ‚Ä¢ Comparaci√≥n por pa√≠s y fuente de emisi√≥n ‚Ä¢ Predicci√≥n a futuro")


def download_and_extract_zip_from_google_drive(file_id, output_dir, zip_name):
    URL = "https://docs.google.com/uc?export=download"
    session = requests.Session()
    response = session.get(URL, params={'id': file_id}, stream=True)
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            response = session.get(URL, params={'id': file_id, 'confirm': value}, stream=True)
            break
    os.makedirs(output_dir, exist_ok=True)
    zip_path = os.path.join(output_dir, zip_name)
    with open(zip_path, 'wb') as f:
        for chunk in response.iter_content(32768):
            f.write(chunk)
    with ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(output_dir)
    os.remove(zip_path)

csv_path = "data/raw/excercise/Emisiones_Totales_S_Todos_los_Datos_(Normalizado).csv"
if not os.path.exists(csv_path):
    st.info("Descargando dataset desde Google Drive...")
    download_and_extract_zip_from_google_drive(
        file_id="1hDcwMcaajRkoaO8trMqqc8DWObGkZl8v",
        output_dir="data/raw/excercise",
        zip_name="Emisiones_Totales_S_Todos_los_Datos_(Normalizado).zip"
    )

df = pd.read_csv(csv_path)
df = df[df['Valor'].notna()]
df['Valor_Mt'] = df['Valor'] / 1e3           # megatoneladas
df['Valor_Gt'] = df['Valor'] / 1e6           # gigatoneladas
df['A√±o'] = pd.to_datetime(df['A√±o'], format='%Y')

# KPIs
# C√°lculos
total_emisiones = df['Valor_Mt'].sum()
anio_min = df['A√±o'].dt.year.min()
anio_max = df['A√±o'].dt.year.max()
total_paises = df['√Årea'].nunique()

# Dise√±o con columnas
col1, col2, col3 = st.columns(3)

col1.metric("üåç Total emisiones (Mt)", f"{total_emisiones:,.2f}")
col2.metric("üìÖ A√±os cubiertos", f"{anio_min} ‚Äì {anio_max}")
col3.metric("üó∫Ô∏è Pa√≠ses √∫nicos", total_paises)


# Mostrar rango temporal
anio_min = df['A√±o'].min().strftime('%Y')
anio_max = df['A√±o'].max().strftime('%Y')

st.subheader(f'üìÜ Rango temporal de los datos: {anio_min}  a  {anio_max}')


# Evoluci√≥n por a√±o
df_anual = df.groupby(df['A√±o'].dt.year).size().reset_index(name='Cantidad')
fig_anual = px.bar(df_anual, x='A√±o', y='Cantidad', title="Cantidad de registros por a√±o")
st.plotly_chart(fig_anual, use_container_width=True)

df_cleaned = df.drop(columns=['Nota','C√≥digo del √°rea', 'C√≥digo del √°rea (M49)', 'C√≥digo del elemento', 'C√≥digo del a√±o', 'C√≥digo fuente']).copy()


regiones = [
    'Mundo', 'Pa√≠ses Anexo I', 'Pa√≠ses No-Anexo I', 'Uni√≥n Europea (27)', 'Uni√≥n Europea (28)',
    '√Åfrica', 'Am√©ricas', 'Europa', 'Asia', 'Ocean√≠a',
    '√Åfrica occidental', '√Åfrica central', '√Åfrica oriental', '√Åfrica meridional', '√Åfrica septentrional',
    'Am√©rica central', 'Am√©rica del Sur', 'Am√©rica septentrional',
    'Europa occidental', 'Europa oriental', 'Europa septentrional', 'Europa meridional',
    'Asia central', 'Asia oriental', 'Asia occidental', 'Asia sudoriental', 'Asia meridional',
    'Australia y Nueva Zelandia', 'El Caribe', 'Melanesia', 'Polinesia', 'Micronesia',
    'OECD', 'URSS', 'Checoslovaq', 'Yugoslav RFS',
    'Los pa√≠ses menos desarrollados', 'Pa√≠ses sin litoral en v√≠as de desarrollo',
    'Pa√≠ses de bajos ingresos y con d√©ficit de alim.', 'Peque√±as islas en v√≠as de Desarrollo',
    'Import netos alim en Des', 'Territorio de las Islas del Pac√≠fico', 'China, Continental'
    ]
df_regiones = df_cleaned[df_cleaned['√Årea'].isin(regiones)].copy()
df_countries = df_cleaned[~df_cleaned['√Årea'].isin(regiones)].copy()
st.subheader("Cantidad de pa√≠ses: " + str(df_countries['√Årea'].nunique()))
# Total original
total_original = len(df_cleaned)

# Total despu√©s de separar
total_regiones = len(df_regiones)
total_paises = len(df_countries)

# Verificar
col1, col2 = st.columns(2)

with col1:
    st.metric("üßÆ Total original", total_original)
    st.metric("üåç Total regiones", total_regiones)

with col2:
    st.metric("üåé Total pa√≠ses", total_paises)
    st.metric("‚ûï Suma regiones + pa√≠ses", total_regiones + total_paises)


countries = df_countries['√Årea'].unique()
fixes = {
    'Anguila': 'Anguilla',
    'Bahrein': 'Bahrain',
    'Bermudas': 'Bermuda',
    'Bhut√°n': 'Bhutan',
    'B√©lgica': 'Belgium',
    'Cabo Verde': 'Cape Verde',
    'Chequia': 'Czechia',
    'Chipre': 'Cyprus',
    'Comoras': 'Comoros',
    'Emiratos √Årabes Unidos': 'United Arab Emirates',
    'Gambia': 'The Gambia',
    'Granada': 'Grenada',
    'Guadalupe': 'Guadeloupe',
    'Guayana Francesa': 'French Guiana',
    'Isla Norfolk': 'Norfolk Island',
    'Isla de Man': 'Isle of Man',
    'Islas Anglonormandas': 'Channel Islands',
    'Islas Caim√°n': 'Cayman Islands',
    'Islas Cook': 'Cook Islands',
    'Islas Feroe': 'Faroe Islands',
    'Islas Marianas del Norte': 'Northern Mariana Islands',
    'Islas Marshall': 'Marshall Islands',
    'Islas Salom√≥n': 'Solomon Islands',
    'Islas Svalbard y Jan Mayen': 'Svalbard and Jan Mayen',
    'Islas Turcas y Caicos': 'Turks and Caicos Islands',
    'Islas V√≠rgenes Brit√°nicas': 'British Virgin Islands',
    'Islas V√≠rgenes de los Estados Unidos': 'United States Virgin Islands',
    'Islas Wallis y Futuna': 'Wallis and Futuna',
    'Martinica': 'Martinique',
    'M√≥naco': 'Monaco',
    'Nueva Caledonia': 'New Caledonia',
    'Palestina': 'Palestine',
    'Pa√≠ses Bajos (Reino de los)': 'Netherlands',
    'Polinesia Francesa': 'French Polynesia',
    'Rep√∫blica Democr√°tica del Congo': 'Democratic Republic of the Congo',
    'Rep√∫blica Democr√°tica Popular Lao': "Lao People's Democratic Republic",
    'Rep√∫blica Popular Democr√°tica de Corea': "Democratic People's Republic of Korea",
    'Reuni√≥n': 'R√©union',
    'Saint Kitts y Nevis': 'Saint Kitts and Nevis',
    'Samoa Americana': 'American Samoa',
    'San Pedro y Miquel√≥n': 'Saint Pierre and Miquelon',
    'Santa Elena, Ascensi√≥n y Trist√°n de Acu√±a': 'Saint Helena, Ascension and Tristan da Cunha',
    'Santa Sede': 'Holy See',
    'Sierra Leona': 'Sierra Leone',
    'Sud√°n (ex)': 'Sudan',
    'S√°hara Occidental': 'Western Sahara',
    'Timor-Leste': 'Timor-Leste',
    'Trinidad y Tabago': 'Trinidad and Tobago',
    'Yugoslav RFS': 'Yugoslavia',
    "Afganist√°n": "Afghanistan",
    "Albania": "Albania",
    "Alemania": "Germany",
    "Angola": "Angola",
    "Antigua y Barbuda": "Antigua and Barbuda",
    "Arabia Saudita": "Saudi Arabia",
    "Argelia": "Algeria",
    "Argentina": "Argentina",
    "Armenia": "Armenia",
    "Austria": "Austria",
    "Azerbaiy√°n": "Azerbaijan",
    "Banglad√©s": "Bangladesh",
    "Bar√©in": "Bahrain",
    "Belice": "Belize",
    "Belar√∫s": "Belarus",
    "Bolivia (Estado Plurinacional de)": "Bolivia",
    "Bosnia y Herzegovina": "Bosnia and Herzegovina",
    "Botsuana": "Botswana",
    "Brasil": "Brazil",
    "Brun√©i Darussalam": "Brunei",
    "Bulgaria": "Bulgaria",
    "Burkina Faso": "Burkina Faso",
    "Camboya": "Cambodia",
    "Camer√∫n": "Cameroon",
    "Canad√°": "Canada",
    "Chad": "Chad",
    "Chile": "Chile",
    "China": "China",
    "Colombia": "Colombia",
    "Corea, Rep√∫blica de": "South Korea",
    "Costa de Marfil": "Ivory Coast",
    "Croacia": "Croatia",
    "Cuba": "Cuba",
    "Dinamarca": "Denmark",
    "Ecuador": "Ecuador",
    "Egipto": "Egypt",
    "El Salvador": "El Salvador",
    "Eritrea": "Eritrea",
    "Eslovaquia": "Slovakia",
    "Eslovenia": "Slovenia",
    "Espa√±a": "Spain",
    "Estados Unidos de Am√©rica": "United States of America",
    "Estonia": "Estonia",
    "Esuatini": "Eswatini",
    "Etiop√≠a": "Ethiopia",
    "Filipinas": "Philippines",
    "Finlandia": "Finland",
    "Francia": "France",
    "Gab√≥n": "Gabon",
    "Georgia": "Georgia",
    "Ghana": "Ghana",
    "Grecia": "Greece",
    "Groenlandia": "Greenland",
    "Guatemala": "Guatemala",
    "Guinea": "Guinea",
    "Guinea-Bissau": "Guinea-Bissau",
    "Guinea Ecuatorial": "Equatorial Guinea",
    "Hait√≠": "Haiti",
    "Honduras": "Honduras",
    "Hungr√≠a": "Hungary",
    "India": "India",
    "Indonesia": "Indonesia",
    "Irak": "Iraq",
    "Ir√°n (Rep√∫blica Isl√°mica del)": "Iran",
    "Irlanda": "Ireland",
    "Islandia": "Iceland",
    "Israel": "Israel",
    "Italia": "Italy",
    "Jap√≥n": "Japan",
    "Jordania": "Jordan",
    "Kazajst√°n": "Kazakhstan",
    "Kenia": "Kenya",
    "Kirguist√°n": "Kyrgyzstan",
    "L√≠bano": "Lebanon",
    "Liberia": "Liberia",
    "Libia": "Libya",
    "Lesoto": "Lesotho",
    "Letonia": "Latvia",
    "Lituania": "Lithuania",
    "Luxemburgo": "Luxembourg",
    "Madagascar": "Madagascar",
    "Malasia": "Malaysia",
    "Malawi": "Malawi",
    "Maldivas": "Maldives",
    "Mal√≠": "Mali",
    "Malta": "Malta",
    "Marruecos": "Morocco",
    "Mauricio": "Mauritius",
    "Mauritania": "Mauritania",
    "M√©xico": "Mexico",
    "Micronesia (Estados Federados de)": "Federated States of Micronesia",
    "Mongolia": "Mongolia",
    "Montenegro": "Montenegro",
    "Mozambique": "Mozambique",
    "Namibia": "Namibia",
    "Nepal": "Nepal",
    "Nicaragua": "Nicaragua",
    "N√≠ger": "Niger",
    "Nigeria": "Nigeria",
    "Noruega": "Norway",
    "Nueva Zelandia": "New Zealand",
    "Om√°n": "Oman",
    "Pakist√°n": "Pakistan",
    "Panam√°": "Panama",
    "Papua Nueva Guinea": "Papua New Guinea",
    "Paraguay": "Paraguay",
    "Per√∫": "Peru",
    "Polonia": "Poland",
    "Portugal": "Portugal",
    "Qatar": "Qatar",
    "Reino Unido de Gran Breta√±a e Irlanda del Norte": "United Kingdom",
    "Rep√∫blica √Årabe Siria": "Syria",
    "Rep√∫blica Centroafricana": "Central African Republic",
    "Rep√∫blica Checa": "Czech Republic",
    "Rep√∫blica de Corea": "South Korea",
    "Rep√∫blica de Moldova": "Moldova",
    "Rep√∫blica Dominicana": "Dominican Republic",
    'Rep√∫blica Unida de Tanzan√≠a': 'Tanzania',
    "RDP Lao": "Laos",
    "Ruman√≠a": "Romania",
    "Federaci√≥n de Rusia": "Russian Federation",
    "San Crist√≥bal y Nieves": "Saint Kitts and Nevis",
    "Santa Luc√≠a": "Saint Lucia",
    "San Vicente y las Granadinas": "Saint Vincent and the Grenadines",
    "Santo Tom√© y Pr√≠ncipe": "Sao Tome and Principe",
    "Samoa": "Samoa",
    "Senegal": "Senegal",
    "Serbia": "Serbia",
    "Seychelles": "Seychelles",
    "Singapur": "Singapore",
    "Sri Lanka": "Sri Lanka",
    "Sud√°frica": "South Africa",
    "Sud√°n": "Sudan",
    "Sud√°n del Sur": "South Sudan",
    "Suecia": "Sweden",
    "Suiza": "Switzerland",
    "Suriname": "Suriname",
    "Tailandia": "Thailand",
    "Tanzania, Rep√∫blica Unida de": "Tanzania",
    "Tayikist√°n": "Tajikistan",
    "Timor-Leste": "East Timor",
    "Tonga": "Tonga",
    "Trinidad y Tobago": "Trinidad and Tobago",
    "T√∫nez": "Tunisia",
    "Turkmenist√°n": "Turkmenistan",
    "Turqu√≠a": "T√ºrkiye",
    "Ucrania": "Ukraine",
    "Uruguay": "Uruguay",
    "Uzbekist√°n": "Uzbekistan",
    "Venezuela (Rep√∫blica Bolivariana de)": "Venezuela",
    "Viet Nam": "Vietnam",
    "Yemen": "Yemen",
    "Zambia": "Zambia",
    "Zimbabue": "Zimbabwe",
    "Estado de Palestina": "Palestine",
    "Macedonia del Norte": "North Macedonia",
    'Rep√∫blica del Congo': 'Congo',
}

# Aplicar correcciones
fixed_countries = [fixes.get(p, p) for p in countries]

# Obtener c√≥digo ISO-3 para cada pa√≠s
def get_iso3(name):
    '''
    Esta funci√≥n busca cada nombre en la base de datos oficial de pycountry:

    Si encuentra el pa√≠s  devuelve el c√≥digo ISO-3 (ARG para Argentina, BRA para Brasil, etc.).

    Si falla (nombre raro, no existe)  devuelve None
    '''
    try:
        return pycountry.countries.lookup(name).alpha_3
    except:
        return None

iso_codes = [get_iso3(p) for p in fixed_countries] #  obtiene una lista de c√≥digos ISO-3 o None si fall√≥
df_map = pd.DataFrame({'country': countries, 'iso_alpha': iso_codes}) # Crea un nuevo DataFrame con dos columnas:'country' ‚Üí nombre original (sin correcci√≥n), 'iso_alpha' ‚Üí c√≥digo ISO-3 resultante (de la versi√≥n corregida)
df_map = df_map.dropna()  # Elimina las filas donde iso_alpha es None.

# A√±adir una columna "coverage" para indicar cobertura
df_map['coverage'] = 1  # 1 = incluido en el dataset

st.subheader("Cobertura geogr√°fica del dataset FAOSTAT")
fig = px.choropleth(
    df_map,
    locations='iso_alpha',
    color='coverage',
    hover_name='country',
    color_continuous_scale=[[0, 'lightgrey'], [1, 'green']],
    title='Cobertura FAOSTAT'
)
fig.update_geos(bgcolor='lightblue',showcountries=True, showcoastlines=True, showland=True, fitbounds="locations")
fig.update_layout(coloraxis_showscale=False, margin={"r":10,"t":40,"l":10,"b":10})
st.plotly_chart(fig, use_container_width=True)



st.subheader("Registros por pa√≠s por a√±o:")
st.markdown("Expansi√≥n en la cobertura de pa√≠ses a partir de 1990*  \n"
            "A partir del a√±o 1990 se observa un incremento significativo en la cantidad de pa√≠ses con datos disponibles. Este cambio no necesariamente implica un aumento real en las emisiones,"
            " sino una mejora en la cobertura geogr√°fica del dataset.  \n"
            "En total, se incorporan 52 nuevos pa√≠ses/regiones despu√©s de 1990, lo que puede influir en los an√°lisis agregados si no se controla adecuadamente.*  \n"
            "Para evitar conclusiones err√≥neas, este notebook incluye filtros y comparaciones que tienen en cuenta este cambio estructural en la base de datos.*")

#Agrupar por pa√≠s y a√±o
df_anual = df_countries.groupby(['√Årea', 'A√±o']).size().reset_index(name='records')
df_group = df_countries.groupby('√Årea').agg({'Valor_Mt': 'sum'}).reset_index()

#Aplicar equivalencias de nombres
df_anual['country'] = df_anual['√Årea'].replace(fixes)
df_anual['iso_alpha'] = df_anual['country'].apply(get_iso3)
df_anual = df_anual[df_anual['iso_alpha'].notnull()]


#Crear mapa animado
fig = px.choropleth(
    df_anual,
    locations='iso_alpha',
    color='records',
    hover_name='country',
    color_continuous_scale='Viridis',
    animation_frame='A√±o',
    title='Evoluci√≥n anual de registros por pa√≠s'
)

fig.update_geos(showcountries=True, showcoastlines=True, showland=True, fitbounds="locations")
fig.update_layout(margin={"r":0,"t":50,"l":0,"b":0})
st.plotly_chart(fig, use_container_width=True)


# Selector de pa√≠s
st.subheader("Evoluci√≥n temporal por pa√≠s")
pais_sel = st.selectbox("Seleccionar pa√≠s", sorted(df['√Årea'].unique()))
df_pais = df[df['√Årea'] == pais_sel]
df_serie = df_pais.groupby(df_pais['A√±o'].dt.year)['Valor_Mt'].sum().reset_index()
fig_pais = px.line(df_serie, x='A√±o', y='Valor_Mt', title=f"Evoluci√≥n de emisiones en {pais_sel}")
st.plotly_chart(fig_pais, use_container_width=True)

st.markdown("""## Expansi√≥n en la cobertura de pa√≠ses a partir de 1990
A partir del a√±o 1990 se observa un incremento significativo en la cantidad de pa√≠ses con datos disponibles. Este cambio no necesariamente implica un aumento real en las emisiones, sino una mejora en la cobertura geogr√°fica del dataset.

En total, se incorporan 52 nuevos pa√≠ses/regiones despu√©s de 1990, lo que puede influir en los an√°lisis agregados si no se controla adecuadamente.

Para evitar conclusiones err√≥neas, este notebook incluye filtros y comparaciones que tienen en cuenta este cambio estructural en la base de datos.""")


st.subheader("Nuevas √°reas registradas despu√©s de 1990")
# Conjuntos de pa√≠ses por per√≠odo
df_cleaned['A√±o'] = df_cleaned['A√±o'].dt.year
areas_before_1990 = set(df_cleaned[df_cleaned['A√±o'] < 1990]['√Årea'].unique())
areas_after_1990 = set(df_cleaned[df_cleaned['A√±o'] > 1990]['√Årea'].unique())
# Nuevas √°reas que no estaban antes
new_areas = sorted(list(areas_after_1990 - areas_before_1990))
st.write(f"Cantidad de nuevas √°reas: **{len(new_areas)}**")
for area in new_areas:
    st.markdown(f"- {area}")


# Top pa√≠ses
st.subheader("Top 10 pa√≠ses con m√°s emisiones")
df_top = df_group.sort_values("Valor_Mt", ascending=False).head(10)
fig_top = px.bar(df_top, x='√Årea', y='Valor_Mt', title="Top 10 pa√≠ses con m√°s emisiones")
st.plotly_chart(fig_top, use_container_width=True)

st.subheader("Consideraciones sobre Productos Reportados")
st.markdown("El n√∫mero de productos reportados cambia significativamente con el tiempo:  \n"
            "- **Antes de 1990**: solo 16 productos reportados.  \n"
            "- **Despu√©s de 1990**: m√°s de 40 productos.  \n"
            "Este cambio refleja una expansi√≥n en el nivel de detalle del inventario de emisiones, tanto en cobertura tem√°tica como en precisi√≥n metodol√≥gica. "
            "Sin embargo, tambi√©n introduce un **sesgo estructural** en los an√°lisis temporales agregados.")

products_before_1990 = set(df_cleaned[df_cleaned['A√±o'] < 1990]['Producto'].unique())
products_after_1990 = set(df_cleaned[df_cleaned['A√±o'] >= 1990]['Producto'].unique())

products = products_before_1990 & products_after_1990
new_products = products_after_1990 - products_before_1990

st.subheader("Comparaci√≥n de productos por per√≠odo")

st.write(f"üì¶ Productos antes de 1990: {len(products_before_1990)}")
st.write(f"üì¶ Productos despu√©s de 1990: {len(products_after_1990)}")
st.write(f"üîÅ Productos comunes: {len(products)}")
st.write(f"üÜï Productos nuevos desde 1990: {len(new_products)}")

st.subheader("""Adem√°s, el dataset incluye algunos productos agregados. Es decir, productos que incluyen dentro a otros productos. Es importante saber diferenciarlos para que las comparaciones tengan sentido.""")
codes_agg = [6518, 6516, 6517, 6996, 6995, 5084, 5085,
             6825, 6829, 6824, 67292, 67291, 69921, 6821, 6817, 6820, 1707, 1711]
aggregated_products = df[df['C√≥digo del producto'].isin(codes_agg)]['Producto'].unique()
st.subheader("Productos agregados")
for producto in aggregated_products:
    st.markdown(f"- {producto}")


st.markdown("""## Delimitaci√≥n temporal del an√°lisis

Debido a los cambios estructurales observados en la cobertura geogr√°fica y tem√°tica del dataset, se ha decidido restringir el an√°lisis a los datos disponibles **a partir del a√±o 1990**.

Esta decisi√≥n responde a dos razones principales:

- **Mayor cobertura geogr√°fica**: a partir de 1990 se incorporan 52 nuevos pa√≠ses, alcanzando un total de 238. Esto garantiza que los an√°lisis comparativos entre regiones y pa√≠ses no est√©n sesgados por datos ausentes en d√©cadas anteriores.
  
- **Mayor cobertura tem√°tica**: el n√∫mero de productos reportados aumenta de 16 (antes de 1990) a m√°s de 40 (despu√©s), lo que introduce una mejora en el detalle metodol√≥gico, pero tambi√©n limita la comparabilidad hist√≥rica.

### Justificaci√≥n

Trabajar con el subconjunto de datos posterior a 1990 permite realizar an√°lisis **m√°s consistentes, representativos y comparables** reduciendo el riesgo de conclusiones err√≥neas causadas por diferencias de cobertura y disponibilidad de informaci√≥n.

En consecuencia, **todas las visualizaciones y estad√≠sticas agregadas en este informe se basar√°n en datos desde 1990 hasta la actualidad, por lo cual no vamos a tener en cuenta estimaciones futuras**."""
)

df_completed = df_cleaned.copy()
df_01 = df_cleaned[(df_cleaned['A√±o'] >= 1990) & (df_cleaned['A√±o'] <= 2025)].copy()


st.markdown("## Variables de Emisi√≥n  \n"
            "El conjunto de datos original incluye m√∫ltiples tipos de elementos relacionados con las emisiones de gases, entre ellos: ")

elementos = df_01['Elemento'].unique()
st.markdown("### Tipos de emisiones registradas:")
for elem in elementos:
    st.markdown(f"- {elem}")
st.subheader("")
st.markdown("## Comparaci√≥n de Cobertura por Fuente (FAO vs UNFCCC)")


# Ver pa√≠ses √∫nicos por fuente
fao_data = set(df_01[df_01['Fuente'] == 'FAO TIER 1']['√Årea'].unique())
unfccc_data = set(df_01[df_01['Fuente'] == 'UNFCCC']['√Årea'].unique())

st.subheader("Comparaci√≥n de cobertura por fuente de datos")
st.write(f"üåæ Pa√≠ses y regiones con datos **FAO TIER 1**: {len(fao_data)}")
st.write(f"üåç Pa√≠ses y regiones con datos **UNFCCC**: {len(unfccc_data)}")
st.write(f"‚úÖ Pa√≠ses y regiones en **ambas fuentes**: {len(fao_data & unfccc_data)}")
st.write(f"üü¢ Solo en **FAO TIER 1**: {len(fao_data - unfccc_data)}")
st.write(f"üîµ Solo en **UNFCCC**: {len(unfccc_data - fao_data)}")

st.markdown("""
### üìö Sobre las fuentes de datos

El conjunto de datos incluye emisiones reportadas por dos fuentes distintas: **FAO TIER 1** y **UNFCCC**. Estas fuentes utilizan metodolog√≠as diferentes:

- **FAO TIER 1**: Estimaciones generadas por la FAO usando metodolog√≠as estandarizadas (*IPCC Tier 1*). Ofrece cobertura global y permite analizar series temporales largas de manera consistente, aunque con menor precisi√≥n pa√≠s-espec√≠fica.

- **UNFCCC**: Datos reportados directamente por los pa√≠ses miembros del Convenio Marco de las Naciones Unidas sobre el Cambio Clim√°tico. Son m√°s precisos pero no est√°n disponibles para todos los pa√≠ses ni todos los a√±os.

Para garantizar la **consistencia del an√°lisis exploratorio** y evitar duplicidades (m√∫ltiples registros para un mismo pa√≠s, a√±o y tipo de emisi√≥n), separamos los datos por fuente.  
En este an√°lisis general utilizaremos principalmente los datos provenientes de **FAO TIER 1**, ya que brindan una cobertura m√°s amplia y continua en el tiempo.

üìå En secciones posteriores, se podr√° comparar con los datos de **UNFCCC** para identificar posibles diferencias metodol√≥gicas o validar tendencias observadas.
""")

df_fao = df_01[df_01['Fuente'] == 'FAO TIER 1'].copy()

st.markdown("""
## üßæ Descripci√≥n de los indicadores

### 1. Emisiones directas (N‚ÇÇO)
Emisiones de √≥xido nitroso (**N‚ÇÇO**) que se liberan directamente al aire desde su fuente, por ejemplo:

- Aplicaci√≥n de fertilizantes nitrogenados al suelo.

---

### 2. Emisiones indirectas (N‚ÇÇO)
Emisiones de **N‚ÇÇO** que ocurren despu√©s de procesos intermedios, como:

- Lixiviaci√≥n de nitr√≥geno al agua.  
- Volatilizaci√≥n (evaporaci√≥n y deposici√≥n posterior).

Estas emisiones ocurren fuera del punto de aplicaci√≥n pero son atribuibles a pr√°cticas agr√≠colas.

---

### 3. Emisiones (N‚ÇÇO)
Suma total de **Emisiones directas + Emisiones indirectas** de N‚ÇÇO.  
Representa la emisi√≥n completa de N‚ÇÇO atribuible a la agricultura/ganader√≠a.

---

### 4. Emisiones (CO‚ÇÇeq) proveniente de N‚ÇÇO (AR5)
Las emisiones de N‚ÇÇO convertidas a **CO‚ÇÇ equivalente** usando el factor del 5¬∫ Informe del IPCC (AR5):  

- N‚ÇÇO tiene un GWP (Global Warming Potential) de **265**.  
- Ejemplo: 1 kt de N‚ÇÇO ‚Üí 265 kt de CO‚ÇÇeq.

Esto permite comparar gases con diferente efecto clim√°tico.

---

### 5. Emisiones (CO‚ÇÇeq) (AR5)
Este es el indicador total combinado, ya convertido a **CO‚ÇÇeq (seg√∫n AR5)**.  
Incluye:

- CO‚ÇÇ  
- CH‚ÇÑ convertido a CO‚ÇÇeq  
- N‚ÇÇO convertido a CO‚ÇÇeq  
- F-gases  

Es la m√©trica recomendada para **comparaciones globales** de impacto clim√°tico.

---

### 6. Emisiones (CH‚ÇÑ)
Emisiones directas de metano (**CH‚ÇÑ**), especialmente desde:

- Fermentaci√≥n ent√©rica en ganado.  
- Cultivo de arroz.

üìè Unidad: kilotoneladas de CH‚ÇÑ.

---

### 7. Emisiones (CO‚ÇÇeq) proveniente de CH‚ÇÑ (AR5)
CH‚ÇÑ convertido a **CO‚ÇÇeq** usando GWP del AR5:

- CH‚ÇÑ tiene un GWP de **28**.  
- 1 kt de CH‚ÇÑ ‚Üí 28 kt de CO‚ÇÇeq.

Permite estimar el efecto clim√°tico del metano en t√©rminos comparables.

---

### 8. Emisiones (CO‚ÇÇ)
Emisiones directas de di√≥xido de carbono (**CO‚ÇÇ**).  
Pueden provenir de maquinaria agr√≠cola, quema de residuos, etc.

üìè Unidad: kilotoneladas de CO‚ÇÇ.

---

### 9. Emisiones (CO‚ÇÇeq) proveniente de F-gases (AR5)
Gases fluorados (**HFCs, PFCs, SF‚ÇÜ**) convertidos a CO‚ÇÇeq.  
Aunque no provienen t√≠picamente de agricultura, pueden aparecer si se incluyen procesos industriales vinculados.

üí• Tienen alt√≠simos GWP (hasta miles de veces el del CO‚ÇÇ).
""")


st.markdown("# An√°lisis Exploratorio de Datos (EDA)  \n")
with st.expander("üåç An√°lisis Global y Comparativo por Continente de Emisiones Totales incluyendo LULUCF"):
    st.markdown("""
Para este an√°lisis vamos a tomar en cuenta el indicador **CO‚ÇÇeq (AR5)**, que es la suma estimada de los tres gases principales, ya convertidos por su impacto clim√°tico.

Adem√°s, vamos a utilizar el agregado **"Emisiones Totales incluyendo LULUCF"**. Este agregado es la suma de todas las fuentes de gases de efecto invernadero del sistema agroalimentario (farm gate + cambio de uso del suelo + procesos pre- y pos-producci√≥n) m√°s el resto de sectores **IPCC**.

**¬øQu√© significa LULUCF?**  
Land Use, Land-Use Change and Forestry.

Es el sector que captura o emite **CO‚ÇÇ (u otros gases)** cuando se utiliza la tierra (pasturas, cultivos), se cambia el uso de la tierra (deforestaci√≥n, expansi√≥n urbana) y silvicultura (tala y repoblaci√≥n forestal, incendios forestales).
""")

gas = 'Emisiones (CO2eq) (AR5)'
continents = [
    'Am√©ricas',
    '√Åfrica',
    'Europa',
    'Asia',
    'Ocean√≠a',
    'Mundo'
]
product_code = 6825 # Emisiones Totales incluyendo LULUCF

df_continents = df_fao[
    (df_fao['√Årea'].isin(continents)) &
    (df_fao['Elemento'] == gas) &
    (df_fao['C√≥digo del producto'] == product_code)
    ].copy()

df_emissions_by_continent_year = df_continents.groupby(['√Årea', 'Elemento', 'A√±o'])['Valor_Gt'].sum().reset_index()
df_emissions_by_continent_year.sort_values(by='Valor_Gt', ascending=False, inplace=True)

df_emissions_by_continent = df_continents.groupby(['√Årea'])['Valor_Gt'].sum().reset_index()
df_emissions_by_continent = df_emissions_by_continent.drop(df_emissions_by_continent[df_emissions_by_continent['√Årea'] == 'Mundo'].index)

st.subheader("Primeras filas del DataFrame de emisiones por continente")
st.dataframe(df_emissions_by_continent.head())



# Crear paleta
palette = sns.color_palette('Set2', len(continents))

# Copiar datos para graficar
df_plot = df_emissions_by_continent_year.copy()

# Estilo y figura
sns.set_style("whitegrid")
fig, (ax_line, ax_pie) = plt.subplots(1, 2, figsize=(14, 5),
                                      gridspec_kw={"width_ratios":[2, 1]})

# Gr√°fico de l√≠neas por continente
for idx, cont in enumerate(continents):
    sub = df_plot[df_plot['√Årea'] == cont].sort_values('A√±o')
    ax_line.plot(sub['A√±o'], sub['Valor_Gt'], marker='o', linewidth=1.4,
                 label=cont, color=palette[idx])

ax_line.set_title('CO‚ÇÇ-eq (AR5) ‚Äî serie temporal')
ax_line.set_ylabel('Gt CO‚ÇÇ-eq')
ax_line.set_xlabel('')
ax_line.grid(ls='--', alpha=.4)
ax_line.legend(title='Continente', ncol=3, fontsize=8)

# Gr√°fico de torta
ax_pie.pie(df_emissions_by_continent['Valor_Gt'],
           labels=df_emissions_by_continent['√Årea'],
           autopct='%1.1f%%',
           startangle=90,
           colors=palette)
ax_pie.set_title('Porcentaje de emisiones (CO‚ÇÇeq AR5) por continente')
ax_pie.axis('equal')

# T√≠tulo general
plt.suptitle('Emisiones Totales incluyendo LULUCF ‚Äî CO‚ÇÇ-eq 1990 - 2022',
             fontsize=14, y=1.03)
plt.tight_layout()

# ‚úÖ Mostrar en Streamlit
st.pyplot(fig)


st.markdown("""
### üß† Interpretaci√≥n y conclusiones del gr√°fico

**Interpretaci√≥n:**

En el gr√°fico de la izquierda, podemos observar c√≥mo fueron evolucionando las emisiones totales de **CO‚ÇÇeq (AR5)** en cada continente desde **1990 a 2022**.  
Cada l√≠nea representa las emisiones en gigatoneladas por continente.  
En el gr√°fico de torta, se visualiza el **aporte proporcional de cada continente** a la suma total de emisiones de CO‚ÇÇeq (AR5) en el mismo per√≠odo.

---

**Conclusiones:**

- **üåè Asia**  
  - Aporta el **46%** del total mundial y contin√∫a en crecimiento.  
  - Su curva crece de forma continua, pasando de **10 Gt en 1990 a 30 Gt en 2022**.

- **üåé Am√©rica**  
  - Aporta el **26%** del total mundial.  
  - Presenta un ligero crecimiento hasta 2005 (~12 Gt), luego una meseta, y a partir de 2010, un descenso.

- **üåç Europa**  
  - Muestra una **disminuci√≥n sostenida** desde 1990 hasta la actualidad.

- **üåç √Åfrica**  
  - Representa el **9%** del total de emisiones.  
  - Tiene un crecimiento sostenido de aproximadamente **3 Gt a 5 Gt** (un aumento del 60%).  
  - Sin embargo, la aceleraci√≥n es mucho menor comparada con Asia.

- **üåè Ocean√≠a**  
  - Es el continente con **menos emisiones**.  
  - Su l√≠nea permanece pr√°cticamente **plana** desde 1990 hasta hoy.

---

üìå **Resumen general:**  
**Asia y Am√©rica representan el 72%** del total de emisiones desde 1990 a 2022.  
**Europa** mantiene una tendencia de **reducci√≥n constante** en sus emisiones.
""")


df_covid = df_fao[
    (df_fao['√Årea'].isin(continents)) &
    (df_fao['A√±o'].between(2017, 2022)) &
    (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_fao['Producto'].isin(['Emisiones totales incluyendo LULUCF',
                              'Pre y\xa0post-producci√≥n',
                              'Farm gate',
                              'Cambios de uso de la tierra']))
].copy()

df_pct = (
    df_covid
    .groupby(['√Årea','Producto','A√±o'])['Valor_Mt'].sum()
    .unstack('A√±o')
    .pipe(lambda d: d.pct_change(axis=1)*100)
    [[2019,2020, 2021,2022]]            # columnas de inter√©s
    .reset_index()
)
# T√≠tulo y descripci√≥n
st.subheader("Variaci√≥n porcentual anual de emisiones CO‚ÇÇeq (AR5)")
st.caption("Comparaci√≥n a√±o a a√±o (2019-2022) por continente y tipo de producto.")

# Asegurarse que los nombres de columnas num√©ricas sean strings
df_pct.columns = [str(col.year) if isinstance(col, pd.Timestamp) else str(col) for col in df_pct.columns]

# Detectar columnas num√©ricas por su nombre (a√±os en string)
cols_numericas = [col for col in df_pct.columns if col.isdigit()]

# Estilo zebra + formato num√©rico
styled_df = (
    df_pct.style
    .format({col: "{:.2f}" for col in cols_numericas})
    .set_properties(**{'background-color': '#f9f9f9'}, subset=pd.IndexSlice[::2, :])
)

st.dataframe(styled_df, use_container_width=True)

st.subheader("Distribuci√≥n porcentual anual de emisiones por continente.")
world = df_emissions_by_continent_year[df_emissions_by_continent_year['√Årea'] == 'Mundo']
conts = df_emissions_by_continent_year[df_emissions_by_continent_year['√Årea'] != 'Mundo']
df_share = conts.merge(world, on='A√±o', suffixes=('_cont', '_world'))
df_share['share'] = df_share['Valor_Gt_cont'] / df_share['Valor_Gt_world'] * 100
pivot = (
    df_share.pivot(index='A√±o', columns='√Årea_cont', values='share')
            .loc[:, ['Asia','Am√©ricas','Europa','√Åfrica','Ocean√≠a']]
            .fillna(0)
)
# Estilo y paleta
sns.set_style('whitegrid')
palette = sns.color_palette('Set2', len(pivot.columns))

# Crear figura y eje
fig, ax = plt.subplots(figsize=(12, 6))

# Gr√°fico de barras apiladas
pivot.plot(kind='bar', stacked=True, color=palette, width=0.9, ax=ax)

# T√≠tulos y formato
ax.set_title('Distribuci√≥n porcentual de emisiones agroalimentarias por continente (1990-2025)')
ax.set_ylabel('% del total global')
ax.set_xlabel('A√±o')
ax.set_ylim(0, 100)
ax.legend(title='Continente', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)
plt.tight_layout()

# Mostrar en Streamlit
st.pyplot(fig)

# Texto interpretativo
st.markdown("""
### Interpretaci√≥n:
- Cada barra del gr√°fico representa el **100‚ÄØ% del total global de emisiones**. Los colores muestran el porcentaje que ocupa cada continente en ese a√±o.

### Conclusiones:
- **Asia**: pasa de representar un 30‚ÄØ% en 1990 a aproximadamente un 55‚ÄØ% en la actualidad.
- **Am√©rica**: mantiene aproximadamente un 30‚ÄØ% en toda la d√©cada del 90, luego cae al 23‚ÄØ% en 2010 y se estabiliza.
- **Europa**: pasa de 29‚ÄØ% en 1990 a menos del 15‚ÄØ% en 2022. La franja azul confirma la eficacia de sus pol√≠ticas contra la emisi√≥n de gases de efecto invernadero.
- **√Åfrica**: crece muy lentamente, del 8‚ÄØ% al 9‚ÄØ%.
- **Ocean√≠a**: en 32 a√±os (1990 - 2022) nunca super√≥ el 2‚ÄØ%.

Como se puede observar en el gr√°fico, **el eje de las emisiones se desplaz√≥ del Atl√°ntico (Europa - Am√©rica) al √çndico - Pac√≠fico**.  
**Asia es hoy el principal emisor absoluto y relativo. Adem√°s, es el motor del crecimiento de las emisiones a nivel global.**
""")


st.subheader('Promedio Anual de Emisiones Totales por d√©cada y continente')
df_dec = df_emissions_by_continent_year.copy()

# Crear columna de d√©cada
df_dec['D√©cada'] = (df_dec['A√±o'] // 10) * 10

# Excluir 'Mundo'
df_dec = df_dec[df_dec['√Årea'] != 'Mundo']

# Agrupar por d√©cada y √°rea
pivot_dec = (
    df_dec.groupby(['D√©cada', '√Årea'])['Valor_Gt']
          .mean()
          .reset_index()
)

# --- Gr√°fico ---
sns.set_style('whitegrid')
fig, ax = plt.subplots(figsize=(10, 5))

sns.barplot(
    data=pivot_dec,
    x='D√©cada', y='Valor_Gt', hue='√Årea',
    palette='Set2',
    ax=ax
)

ax.set_title('Promedio anual de CO‚ÇÇ-eq por d√©cada y continente')
ax.set_ylabel('Gt CO‚ÇÇ-eq')
ax.set_xlabel('D√©cada')
ax.legend(title='Continente', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)

plt.tight_layout()
st.pyplot(fig)
st.markdown("""Interpretaci√≥n:
- D√©cada del 90: el mapa de las emisiones est√° muy distribuido, no se observa una dominancia marcada por alg√∫n continente.
- D√©cada del 2000: Asia despega, aumenta el promedio anual en un 45% respecto a la d√©cada anterior (del 12 Gt a 18 Gt). Adem√°s, Am√©rica aumenta un 10% y Europa tiene una ca√≠da del 15%. Comienza el cambio a nivel mundial del mapa de emisiones, las mismas se trasladan hac√≠a el pac√≠fico.
- Decada del 2010: Asia acelera nuevamente aumentando otro 45% (de 18gt a 26gt) el promedio anual en la d√©cada. En esta d√©cada Asia tiene un promedio mayor al doble que Am√©rica. Europa contin√∫a con su descenso y √Åfrica aumenta su promedio en un 25% respecto a la d√©cada anterior.
- D√©cada del 2020: el promedio anual de Asia se ubica cerca de las 30Gt, triplicando a Am√©rica. Europa se estabiliza y Ocean√≠a mantiene su promedio anual < 1 Gt, al igual que en d√©cadas anteriores.""")

st.subheader("Comparativa de Emisiones por Continente y por componente (1990 - 2010 - 2022)")
st.markdown("""Para este an√°lisis se seleccionaron los siguientes componentes:

- Farm Gate: fermentaci√≥n ent√©rica, gesti√≥n de esti√©rcol, fertilizantes sint√©ticos, uso de energ√≠a en la finca, etc.
Es decir, es todo lo que ocurre dentro del establecimiento agropecuario.
- Cambios en el uso de la tierra: deforestaci√≥n, conversi√≥n neta de bosques, drenaje de suelos org√°nicos, incendios, etc.
- Pre y post-producci√≥n: procesado, envasado, transporte, venta y desperdicio de alimentos. Todo lo que sucede antes y despu√©s de la puerta de la finca

Estos componentes agrupados representan las Emisiones Totales incluyendo LULUCF. Al analizarlos por separado, podemos definir con precisi√≥n qu√© porci√≥n de las emisiones proviene de la finca, de la conversi√≥n de ecosistemas o de la cadena de suministro, lo cual es informaci√≥n importante para definir politicas eficaces en cada regi√≥n.
""")

# --- Par√°metros ---
continents = ['Am√©ricas', 'Asia', 'Europa', 'Ocean√≠a', '√Åfrica']
products = ['Farm gate', 'Cambios de uso de la tierra', 'Pre y\xa0post-producci√≥n']
gas = "Emisiones (CO2eq) (AR5)"
years = [1990, 2010, 2022]

# --- Filtro del DataFrame ---
df_products_continents = df_fao[
    (df_fao['Producto'].isin(products)) &
    (df_fao['√Årea'].isin(continents)) &
    (df_fao['A√±o'].isin(years)) &
    (df_fao['Elemento'] == gas)
].copy()

# --- Pivot ---
pivot = (
    df_products_continents
    .pivot_table(index=['A√±o', '√Årea'], columns='Producto', values='Valor_Gt', aggfunc='sum')
    .sort_index(level=1)
    .reset_index()
)

pivot = pivot.sort_values(['√Årea', 'A√±o'], ascending=[True, False]).reset_index(drop=True)

# --- Configuraci√≥n del gr√°fico ---
colors = ['#0066CC', '#0eca1c', '#ff5733']
bar_h = 0.8
gap = 1
offset = bar_h
n_y = len(years)
y_pos = []

# --- Posiciones verticales para barras por continente ---
for g in range(len(continents)):
    base = offset + g * (n_y * bar_h + gap)
    y_pos.extend(base + np.arange(n_y) * bar_h)

fig, ax = plt.subplots(figsize=(10, 7))
left = np.zeros(len(y_pos))

# --- Barras horizontales apiladas ---
for (col, color) in zip(products, colors):
    ax.barh(y_pos, pivot[col], left=left,
            height=bar_h, color=color, edgecolor='white', label=col)
    left += pivot[col].values

# --- Ejes Y principales (a√±os) ---
ax.set_yticks(y_pos)
ax.set_yticklabels(pivot['A√±o'])
ax.set_axisbelow(True)
ax.grid(axis='y')

# --- Eje Y secundario (continentes) ---
ax2 = ax.twinx()
mid_pos = [offset * 0.1 + g * (n_y * bar_h + gap) + (n_y * bar_h) - bar_h
           for g in range(len(continents))]
ax2.set_yticks(mid_pos)
ax2.set_yticklabels(continents, fontsize=15, weight='bold')
ax2.yaxis.set_ticks_position('left')
ax2.spines['left'].set_position(('outward', 70))
ax2.tick_params(axis='y', length=0)
ax.spines['left'].set_visible(False)
ax2.spines['right'].set_visible(False)
ax2.grid(False)

# --- T√≠tulos y leyenda ---
ax.set_xlabel('Gt CO‚ÇÇ-eq (AR5)')
ax.set_title('Total Emisiones CO‚ÇÇ-eq por componente 1990 ¬∑ 2010 ¬∑ 2022')
ax.legend(title='Producto',
          loc='upper right',
          frameon=True,
          framealpha=.9,
          borderpad=.6, fontsize=9)

plt.tight_layout()

# --- Mostrar en Streamlit ---
st.subheader("üìä Total Emisiones CO‚ÇÇ-eq por componente (1990, 2010, 2022)")
st.pyplot(fig)

st.markdown("""
---

### üßæ Interpretaci√≥n del gr√°fico

El gr√°fico muestra barras horizontales apiladas que cuantifican las emisiones agro-alimentarias de CO‚ÇÇ-equivalente (Gt CO‚ÇÇ-eq) para cada continente en tres cortes temporales: **1990**, **2010** y **2022**.

#### üîç Interpretaci√≥n por continente:

- **Asia**:
  - En 1990, las emisiones a causa de *Farm gate* son la porci√≥n m√°s grande.
  - Para 2022, el bloque rojo (*pre-/post-producci√≥n*) crece con rapidez (aumenta √ó‚ÄØ7 en 32‚ÄØa√±os), reflejando la industrializaci√≥n de la cadena alimentaria asi√°tica y el aumento del consumo urbano.
  - Las emisiones por *cambios en el uso de la tierra* se reducen moderadamente tras 2010 gracias al freno parcial de la deforestaci√≥n en el Sudeste Asi√°tico.

- **Am√©ricas**:
  - En 1990 se observa una dominancia de las emisiones por *cambios en el uso de la tierra*.
  - Para el a√±o 2022, el bloque verde disminuye notablemente, mientras las emisiones por *pre y post-producci√≥n* se multiplican. Esto significa que hubo una transici√≥n de deforestaci√≥n a cadena de suministro.
  - Al mismo tiempo, azul se mantiene estable y rojo se multiplica. Significa que la presi√≥n clim√°tica migra de la frontera agropecuaria hacia la log√≠stica y el consumo.

- **Europa**:
  - Desde 1990 a la actualidad, las emisiones por *cambios en el uso de la tierra* fueron marginales.
  - Se observa una disminuci√≥n de las emisiones por *farm gate* desde 1990 a 2010 y luego se mantienen estables hasta 2022.
  - El bloque rojo demuestra que la mayor parte del problema europeo reside hoy en las emisiones por *pre y post-producci√≥n*.

- **√Åfrica**:
  - Las emisiones por *farm gate* ganan peso d√©cada tras d√©cada.
  - En 1990, las emisiones por *cambios en el uso de la tierra* dominan con amplia ventaja.
  - En 2010, las emisiones por *farm gate* recortan distancia.
  - En 2022, el componente ligado a deforestaci√≥n e incendios sigue siendo la principal fuente de emisiones. Adem√°s, la franja roja (*pre y post-producci√≥n*) muestra que la cadena de valor ‚Äîprocesado, transporte, venta‚Äî est√° comenzando a pesar y puede acelerarse.

- **Ocean√≠a**: emisiones muy bajas y estables.

---

### üß† Conclusi√≥n

El problema clim√°tico del sistema agro‚Äëalimentario mundial se ha desplazado del **‚Äúd√≥nde sembramos‚Äù** (*deforestaci√≥n*) al **‚Äúc√≥mo producimos y consumimos‚Äù** (*industria y consumo*).

Las estrategias para reducir las emisiones de gases deben, por tanto, abarcar la **cadena completa**, con prioridades distintas seg√∫n la fase en que se encuentre cada regi√≥n.
""")

st.subheader("Top 10 Paises con mayores Emisiones (CO2eq) (AR5) (2022)")
st.markdown("""Para este an√°lisis se seleccion√≥ el elemento Emisiones (CO2eq) (AR5), ya que:
- Es una m√©trica que convierte todas las emisiones de gases de efecto invernadero (GEI) ‚Äîcomo di√≥xido de carbono (CO‚ÇÇ), metano (CH‚ÇÑ) y √≥xido nitroso (N‚ÇÇO)‚Äî en toneladas equivalentes de CO‚ÇÇ.
- Permite realizar an√°lisis agregados, consistentes y comparables entre pa√≠ses

""")
gas = 'Emisiones (CO2eq) (AR5)'
product_code = 6825 # Emisiones Totales incluyendo LULUCF

df_countries_2022 = df_fao[
    (~df_fao['√Årea'].isin(regiones)) &
    (df_fao['C√≥digo del producto'] == product_code) &
    (df_fao['Elemento'] == gas) &
    (df_fao['A√±o'] == 2022)
    ]

df_top_countries_emission = df_countries_2022.groupby(['√Årea'])['Valor'].sum().reset_index()
df_top_countries_emission.sort_values(by= 'Valor',ascending=False, inplace=True)
df_top_countries_emission = df_top_countries_emission.head(10)
df_top_countries_emission

total_global = df_fao[
    (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_fao['√Årea'] == 'Mundo') &
     (df_fao['A√±o'] == 2022) &
    (df_fao['C√≥digo del producto'] == product_code)
    ]['Valor'].sum()
total_top_10 = df_top_countries_emission['Valor'].sum()

pct_top_10 = (total_top_10 / total_global) * 100
pct_rest = 100 - pct_top_10

st.markdown(f"## **Top 10 pa√≠ses** representan el **{pct_top_10:.1f}%** del total global.")
st.markdown(f"## **Resto del mundo** representa el **{pct_rest:.1f}%**.")

# Espaciado visual
st.write("")  # una l√≠nea en blanco
st.write("")  # otra si se quiere m√°s espacio

fix = {
    "Estados Unidos de Am√©rica": "EEUU",
    "Ir√°n (Rep√∫blica Isl√°mica del)": 'Ir√°n',
    "Federaci√≥n de Rusia": "Rusia"
}
df_top_countries_emission['√Årea'] = df_top_countries_emission['√Årea'].replace(fix)

# Crear figura y subplots
fig, axs = plt.subplots(1, 2, figsize=(14, 6),gridspec_kw={'width_ratios': [1.2, 1]})

# --- Subplot 1: Gr√°fico de barras ---
sns.barplot(data=df_top_countries_emission, x='√Årea', y='Valor', hue='√Årea',
            palette='Greens_r', ax=axs[0], width=1.0)

# Quitar la leyenda manualmente (en lugar de usar legend=False que lanza error)
axs[0].legend_.remove()

axs[0].set_title(' Total Emisiones (CO2eq) (AR5)', fontsize=13)
axs[0].set_xlabel('Pa√≠s')
axs[0].set_ylabel('Emisiones Totales (kilotones)')
axs[0].tick_params(axis='x', rotation=45)

# --- Subplot 2: Gr√°fico de torta ---
labels = [f'Top 10 pa√≠ses ({pct_top_10:.1f}%)', f'Resto del mundo ({pct_rest:.1f}%)']
values = [pct_top_10, pct_rest]

axs[1].pie(
    x=values,
    labels=labels,
    colors=sns.color_palette('Greens_r', len(labels)),
    startangle=140,
    autopct=lambda p: f'{p:.1f}%'
)
axs[1].set_title('Participaci√≥n del Top 10 pa√≠ses emisores sobre el total global', fontsize=13)

# T√≠tulo global y ajuste de espacio
fig.suptitle('Top 10 Paises Emisiones (CO2eq) (AR5) (2022)', fontsize=16, y=1.05)
plt.tight_layout()
plt.subplots_adjust(wspace=0.4)

# Mostrar en Streamlit
st.pyplot(fig)

st.markdown("""Interpretaci√≥n:

- China	Con aproximadamente 14 millones de kt lidera con enorme ventaja ( 2,5 √ó EEUU).
- EE. UU: es el segundo pa√≠s con mas emisiones en el mundo pero, aun as√≠ emite menos de la mitad que China.
- India: se consolida en el tercer lugar, reflejando crecimiento poblacional.
- Rusia, Indonesia, Brasil, Jap√≥n, Ir√°n: tienen valores intermedios (0,6 ‚Äì 2 millones kt). Mezcla de grandes potencias agr√≠colas (Brasil, Indonesia) y econom√≠as industriales/energ√©ticas (Rusia, Ir√°n, Jap√≥n).
- Arabia Saudita y M√©xico	ocupan el puesto 9 y 10 el ranking. Sus emisiones son < 10 % de las chinas.

Se puede observar una desigualdad extrema: el primer pa√≠s (China) emite casi 75 veces m√°s que el d√©cimo.

Adem√°s, en el gr√°fico de la derecha podemos observar que, en la actualidad, dos tercios de todas las emisiones agro‚Äëalimentarias se concentran en solo diez pa√≠ses (63%). Por lo tanto, el resto de los paises (180 aprox) aportan el otro tercio.
El gr√°fico demuestra que las politicas de mitigaci√≥n global deben hacer foco en unas pocas jurisdicciones. Sin acciones contundentes en esos pa√≠ses, el resto del mundo dif√≠cilmente compensar√° el volumen de emisiones que ah√≠ se genera.""")

st.subheader('Emisiones 2022 ‚Äî Productos m√°s emisores por pa√≠s')
st.markdown("""En el pr√≥ximo Heatmap de productos x paises

cada celda nos muestra las Emisiones (CO2eq) (AR5) en el a√±o 2022 de cada producto en cada pa√≠s.
Esto nos permite ver que paises son m√°s emisores en cada proceso y ver los procesos cr√≠ticos de cada regi√≥n, lo cual permite priorizar acciones.

Para este an√°lisis, seleccionamos los 6 paises con m√°s emisiones en el a√±o 2022 (China, EEUU, India, Rusia, Indonesia y Brasil). Estos pa√≠ses representan el 56% del total de emisiones incluyendo LULUCF a nivel global en el a√±o 2022.')
""")

# Definir regiones de inter√©s
regions = ['China', 'Estados Unidos de Am√©rica', 'India', 'Indonesia', 'Brasil', 'Federaci√≥n de Rusia']

# Filtrar datos para 2022 excluyendo productos agregados
df_2022 = (
    df_fao[
        (df_fao['A√±o'] == 2022) &
        (df_fao['√Årea'].isin(regions)) &
        (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
        (~df_fao['C√≥digo del producto'].isin(codes_agg))
    ]
    .copy()
)

# Correcciones de nombres
fix = {
    "Eliminaci√≥n de desechos de sistemas agroalimentarios": "Eliminaci√≥n desechos sist. agro",
}
fix_countries = {
    'Estados Unidos de Am√©rica': 'EEUU',
    'Federaci√≥n de Rusia': 'Rusia',
}
df_2022['Producto'] = df_2022['Producto'].replace(fix)
df_2022['√Årea'] = df_2022['√Årea'].replace(fix_countries)

# Seleccionar los 15 productos m√°s emisores
top_products = (
    df_2022.groupby('Producto')['Valor_Mt'].sum()
           .nlargest(15).index
)

df_2022 = df_2022[df_2022['Producto'].isin(top_products)]

# Crear pivot para el heatmap
pivot = (
    df_2022
    .pivot_table(index='Producto', columns='√Årea',
                 values='Valor_Mt', aggfunc='sum')
    .fillna(0)
    .sort_values('China', ascending=False)
)

# Crear figura y heatmap
fig, ax = plt.subplots(figsize=(10, 6))
sns.heatmap(pivot, annot=True, fmt='.0f', cmap='Greens',
            linewidths=.5, linecolor='white', cbar_kws={'label': 'Mt CO‚ÇÇ-eq'}, ax=ax)

ax.set_title('Emisiones CO2 eq 2022 ‚Äî Productos m√°s emisores en el Top 6 Pa√≠ses')
ax.set_xlabel('Pa√≠s')
ax.set_ylabel('')
plt.tight_layout()

# Mostrar en Streamlit
st.subheader("üåç Emisiones CO‚ÇÇ-eq por producto y pa√≠s (2022)")
st.pyplot(fig)

st.markdown("""#### Conslusiones:
- China: el grueso de las emisiones no proviene del campo, sino de la cadena poscosecha y el consumo urbano (desechos y consumo de alimentos).
- EEUU: tiene valores medianos-altos en casi todas las filas. No tiene un pico, por lo tanto las medidas de acci√≥n deber√≠an ser aplicadas de manera multisectorial.
- India: las emisiones se encuentran diversificadas. Es el mayor emisor por fermentaci√≥n ent√©rica. Adem√°s, el consumo de energ√≠a dentro de la finca ya supera a la mayor√≠a de los procesos pos-cosecha.
- Indonesia: picos sobresalientes en suelos org√°nicos drenados y conversi√≥n neta de bosques. El drenaje y la quema de turberas  para palma aceitera liberan grandes cantidades de CO2.
https://rspo.org/es/the-challenges-of-growing-oil-palm-on-peatlands/
- Rusia: sin celdas mayores a 200 Mt, se destacan las emisiones por desechos y suelos org√°nicos. Tiene un perfil m√°s parecido al de Europa que al de Brasil/Indonesia.
- Brasil: el cambio en el uso del suelo es el motor de las emisiones. Otro pico alto es la fermentaci√≥n ent√©rica.


Conclusiones generales:
- No hay una √∫nica fuente de emisi√≥n que domine en todos los paises. Cada econom√≠a tiene su debilidad.
- China y EEUU tienen mayor contaminaci√≥n en procesos pos-producci√≥n (desechos, consumo), mientras Brasil e Indonesia tienen mayores problemas en el sector agr√≠cola.
- Cuatro de los seis paises tienen emisiones mayores a 150 mt por fermentaci√≥n ent√©rica, esto indica que la ganader√≠a es un motor de contaminaci√≥n a nivel global.""")


st.subheader("Am√©rica (Actualidad)")
anio = 2022
countries = ['Estados Unidos de Am√©rica', 'Brasil', 'Argentina', 'M√©xico', 'Colombia', 'Canad√°', 'Per√∫']
product_code = 6825 # Emisiones totales incluyendo LULUCF
gas = 'Emisiones (CO2eq) (AR5)'

df_most_population_america = df_fao[
    (df_fao['√Årea'].isin(countries)) &
    (df_fao['A√±o'] == anio) &
    (df_fao['Elemento'] == gas) &
    (df_fao['C√≥digo del producto'] == product_code)]

df_top_countries_emission = df_most_population_america.groupby(['√Årea'])['Valor_Mt'].sum().reset_index()
df_top_countries_emission.sort_values(by= 'Valor_Mt',ascending=False, inplace=True)

total_america = df_fao[
    (df_fao['√Årea'] == 'Am√©ricas') &
    (df_fao['A√±o'] == anio) &
     (df_fao['Elemento'] == gas) &
    (df_fao['C√≥digo del producto'] == product_code)
    ]['Valor_Mt'].sum()

rest_of_america = total_america - df_top_countries_emission['Valor_Mt'].sum()
st.write("")
st.write("")
st.markdown(f"### **Resto de Am√©rica** representa  **{rest_of_america:.1f}%**.")
st.write("")
st.write("")


df_plot = (pd.concat(
    [df_top_countries_emission ,
     pd.DataFrame({'√Årea': ['Resto de Am√©rica'], 'Valor_Mt': [rest_of_america]})
     ], ignore_index=True)
)

df_plot['Share'] = (df_plot['Valor_Mt'] / df_plot['Valor_Mt'].sum()) * 100
df_plot.sort_values('Valor_Mt', ascending=False, inplace=True)

sns.set_style('whitegrid')
plt.figure(figsize=(12,6))
sns.barplot(data=df_plot, y='√Årea', x='Share', hue='√Årea',
            palette='Greens_r', edgecolor='black')

for i, row in df_plot.iterrows():
    plt.text(row['Share']+5, i,
             f"{row['Valor_Mt']:,.0f} Mt", va='center')

plt.title(f'Emisiones Totales incluyendo LULUCF CO‚ÇÇ-eq en Am√©rica ({anio})')
plt.xlabel('% del total continental'); plt.ylabel('')
plt.xlim(0, 100)
plt.tight_layout(); st.pyplot(plt)

st.write("")
st.write("")
st.markdown("""### An√°lisis por Tipo de Gas y Continente""")

gases = ['Emisiones (CO2)', 'Emisiones (N2O)', 'Emisiones (CH4)']

df_continents_gas = df_fao[
    (df_fao['√Årea'].isin(continents)) &
    (df_fao['Elemento'].isin(gases)) &
    (df_fao['Producto'] == 'Emisiones totales incluyendo LULUCF')
    ].copy()

df_continents_gas_by_year = df_continents_gas.groupby(['√Årea', 'Elemento', 'A√±o'])['Valor_Mt'].sum().reset_index()
df_continents_gas_by_year = df_continents_gas_by_year[df_continents_gas_by_year['√Årea'] != 'Mundo']
df_continents_gas_by_year.sort_values(by='Valor_Mt', ascending=False, inplace=True)

fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=False)
axs = axs.ravel()

palette = sns.color_palette('Set2', len(continents) - 1)

# Dibujar cada gas en un eje
for i, gas in enumerate(gases):
    ax = axs[i]
    sns.lineplot(data=df_continents_gas_by_year[df_continents_gas_by_year['Elemento'] == gas],
                 x='A√±o', y='Valor_Mt', hue='√Årea',
                 marker='o', palette=palette, ax=ax)

    ax.set_title(gas, fontsize=11)
    ax.set_xlabel('')
    ax.set_ylabel('Mt CO‚ÇÇ-eq')
    ax.grid(ls='--', alpha=.4)
    if i == 0:
        ax.set_ylabel('Mt CO‚ÇÇ-eq')
    else:
        ax.set_ylabel('')
fig.suptitle('Evoluci√≥n anual de emisiones por continente (1990-2022)',
             fontsize=15, weight='bold', y=0.96)
plt.tight_layout(rect=[0, 0, 1, 0.95])
st.pyplot(plt)

st.write("")
st.write("")

st.markdown("""Asia: es el motor del alza mundial de los tres gases. La pendiente apenas se modera a partir de 2015. Las emisiones de CO2 crecen de de 6 mil Mt a casi 23 mil Mt.

Am√©rica: las emisiones de CO2 crecen hasta 2005 y luego hay una meseta-descenso a 8000 mt. Las emisiones de NO2 tienen un crecimiento suave de 2 mil Mt a casi 3mil Mt. Mientras que las emisiones de CH4, se mantienen estables.

Europa: es el √∫nico continente donde se observa una ca√≠da en las emisiones de los tres gases.

√Åfrica: el salto porcentual es grande (sobretodo en CH4 y N2O), pero la magnitud absoluta sigue muy por debajo de Asia o Am√©rica. Las emisiones de CO2 crecen muy lentamente.

Ocean√≠a: impacto global muy bajo. Las variaciones anuales est√°n relacionadas a incendios o sequ√≠as.


Conclusiones generales:
- N2O es el gas con la pendiente proporcional m√°s alta en √Åfrica y Asia: es la l√≠nea que mas r√°pido crece en ambos continentes.
- CH4 presenta tendencia ascendente suave excepto en Europa que hay un descenso.
-CO‚ÇÇ es, con mucha diferencia, el gas dominante en todas las regiones.""")

st.markdown("""### An√°lisis de Productos Desagregados y su relaci√≥n con los diferentes tipos de Gas
Para este an√°lisis vamos a tener en cuenta los productos desagregados""")

gases = ['Emisiones (CO2)', 'Emisiones (N2O)', 'Emisiones (CH4)']
anio = 2022
codes_agg = [6518, 6516, 6517, 6996, 6995, 5084, 5085,
             6825, 6829, 6824, 67292, 67291, 69921, 6821, 6817, 6820, 1707, 1711]

df_non_agg_products = df_fao[
    (~df_fao['C√≥digo del producto'].isin(codes_agg)) &
    (df_fao['A√±o'] == anio) &
    (df_fao['Elemento'].isin(gases))
    ]

df_products_top_emissions = df_non_agg_products.groupby(['Producto', 'Elemento'])['Valor_Mt'].sum().reset_index()

top_n = 10
lista_top = []
for g in gases:
    top_g = (df_non_agg_products[df_non_agg_products['Elemento'] == g]
                .groupby('Producto')['Valor_Mt']
                .sum()
                .sort_values(ascending=False)
                .head(top_n)
                .reset_index())
    top_g['Gas'] = g
    lista_top.append(top_g)

df_top_gases = pd.concat(lista_top, ignore_index=True)

df_top_gases = (df_top_gases.set_index(['Gas','Producto'])
                              .sort_index(level='Gas'))

df_top_gases = df_top_gases.rename(
    index={'Eliminaci√≥n de desechos de sistemas agroalimentarios':
           'Eliminaci√≥n de desechos de S. Agro.'},
    level='Producto'
)

sns.set_style('whitegrid')
base_palette = sns.color_palette('Greens_r', top_n)
fig, axes = plt.subplots(3, 1, figsize=(10,10), sharex=False)

for ax, g in zip(axes, gases):
    sub = df_top_gases.loc[g].sort_values('Valor_Mt')
    colors = base_palette
    sub.plot.barh(ax=ax, color=colors, edgecolor='black')
    ax.set_title(f'{g.split()[1]}')
    ax.set_xlabel('Mt'); ax.set_ylabel('')
    ax.grid(axis='x', ls='--', alpha=.4)
    ax.get_legend().remove()

fig.suptitle('Top 10 Productos m√°s emisores por gas ‚Äì A√±o 2022', y=1.02, fontsize=13)
plt.tight_layout()
st.pyplot(plt)

years = [1990, 2022]
df_crec_prod = df_fao[
    (df_fao['A√±o'].isin(years)) &
    (df_fao['√Årea'] == 'Mundo') &
    (~df_fao['C√≥digo del producto'].isin(codes_agg)) &
    (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)')
    ].copy()

totals_by_year = df_crec_prod.groupby(['A√±o', 'Producto'])['Valor_Mt'].sum().unstack('A√±o').reset_index()

st.markdown("### Evoluci√≥n de emisiones por producto (1990 vs 2022)")

totals_by_year["Crecimiento absoluto"] = totals_by_year[2022] - totals_by_year[1990]
totals_by_year = totals_by_year.sort_values("Crecimiento absoluto", ascending=False)
st.dataframe(totals_by_year, use_container_width=True)

st.markdown("# **Modelo Predictivo**")
st.markdown("## Utilizando ARIMA:")
st.markdown("#### El siguiente modelo estima las emisiones totales incluyendo LULUCF (Uso de la Tierra, Cambio de Uso de la Tierra y Silvicultura) para cada continente. Se utilizan los datos desde 1990 a 2022 para proyectar como van a evolucionar esas emisiones en los proximos a√±os.")

serie = df_fao[
    (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_fao['C√≥digo del producto'] == 6825)
  ].copy()

serie_america = serie[serie['√Årea'] == 'Am√©ricas']
serie_asia = serie[serie['√Årea'] == 'Asia']
serie_europa = serie[serie['√Årea'] == 'Europa']
serie_oceania = serie[serie['√Årea'] == 'Ocean√≠a']
serie_africa = serie[serie['√Årea'] == '√Åfrica']

st.markdown("### üìä Curva de emisiones en kilotoneladas a lo largo de los a√±os para los distintos continentes. "
            "Evoluci√≥n de las emisiones agroalimentarias en cada continente a lo largo del tiempo")

st.markdown("""
---
### Cada gr√°fico representa la evoluci√≥n de las **emisiones agroalimentarias totales** (en kilotoneladas de CO‚ÇÇ-eq, metodolog√≠a AR5) desde el a√±o 1990 hasta 2022 en cada continente. A continuaci√≥n se presentan algunas observaciones generales:

- **Am√©rica**:
  - Muestra una tendencia creciente con ciertas oscilaciones.
  - Se destacan picos asociados a deforestaci√≥n y uso intensivo de fertilizantes en d√©cadas recientes.

- **Asia**:
  - Presenta un **crecimiento sostenido y fuerte**.
  - La industrializaci√≥n y el aumento del consumo urbano explican buena parte del incremento.

- **Europa**:
  - Se observa una **tendencia a la estabilizaci√≥n o incluso leve reducci√≥n**.
  - Las pol√≠ticas ambientales y agr√≠colas parecen estar moderando las emisiones.

- **Ocean√≠a**:
  - Tiene niveles **bajos y relativamente estables**.
  - La menor poblaci√≥n y menor superficie cultivable influyen en estos valores.

- **√Åfrica**:
  - Las emisiones han crecido de forma progresiva.
  - El aumento se debe al avance de la frontera agropecuaria y la presi√≥n sobre ecosistemas.

---

### üß† Conclusi√≥n general

Estos gr√°ficos permiten **visualizar patrones hist√≥ricos** que sirven como base para aplicar modelos predictivos (por ejemplo, regresiones o modelos ARIMA) y anticipar el impacto futuro de las pol√≠ticas agr√≠colas y alimentarias en cada regi√≥n.
""")



# Crear figura y subplots
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

# Graficar cada continente
sns.lineplot(data=serie_america, x='A√±o', y='Valor', ax=axes[0])
axes[0].set_title('Am√©rica')

sns.lineplot(data=serie_asia, x='A√±o', y='Valor', ax=axes[1])
axes[1].set_title('Asia')

sns.lineplot(data=serie_europa, x='A√±o', y='Valor', ax=axes[2])
axes[2].set_title('Europa')

sns.lineplot(data=serie_oceania, x='A√±o', y='Valor', ax=axes[3])
axes[3].set_title('Ocean√≠a')

sns.lineplot(data=serie_africa, x='A√±o', y='Valor', ax=axes[4])
axes[4].set_title('√Åfrica')

# Eliminar el subplot vac√≠o
fig.delaxes(axes[5])

# Ajustar dise√±o y mostrar en Streamlit
plt.tight_layout()
st.subheader("üìà Evoluci√≥n anual de emisiones por continente")
st.pyplot(fig)


st.markdown("""## An√°lisis de ACF y PACF por continente

En este bloque realizamos un an√°lisis de series temporales sobre las emisiones de CO‚ÇÇ-eq para cada continente, utilizando dos herramientas estad√≠sticas fundamentales:

### üîÅ Funci√≥n de autocorrelaci√≥n (ACF)
- La **ACF (Autocorrelation Function)** mide la correlaci√≥n de la serie con sus propios retardos (lags).
- Permite detectar patrones de repetici√≥n o dependencia temporal.
- Si hay autocorrelaci√≥n significativa en ciertos lags, es se√±al de que el pasado influye sobre el futuro.

### üìà Funci√≥n de autocorrelaci√≥n parcial (PACF)
- La **PACF (Partial Autocorrelation Function)** mide la correlaci√≥n entre una observaci√≥n y sus lags, **controlando por las correlaciones intermedias**.
- Es √∫til para identificar el orden AR (autoregresivo) en modelos ARIMA.
- Ayuda a decidir cu√°ntos t√©rminos autoregresivos incluir (cu√°ntos lags tienen efecto directo).

### ‚ö†Ô∏è Filtro de calidad de datos
- Si una serie tiene menos de 10 observaciones no nulas, **no se grafica** ACF/PACF por falta de datos para un an√°lisis confiable.

### üìå Aplicaci√≥n
Este an√°lisis se realiza de forma individual para cada continente (Am√©rica, Asia, Europa, Ocean√≠a y √Åfrica) y se muestra un gr√°fico con dos subplots: ACF y PACF con hasta 15 lags.

Esto es fundamental para modelar emisiones futuras, detectar estacionalidad o dependencia, y elegir modelos estad√≠sticos adecuados.
""")
series = [
    ('Am√©rica', serie_america),
    ('Asia', serie_asia),
    ('Europa', serie_europa),
    ('Ocean√≠a', serie_oceania),
    ('√Åfrica', serie_africa)
]

for (nombre, df) in series:
    serie = df['Valor'].dropna()

    if len(serie) < 10:
        st.warning(f"‚ö†Ô∏è Muy pocos datos para mostrar ACF/PACF confiables para **{nombre}**")
        continue

    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    fig.suptitle(f'ACF y PACF - {nombre}', fontsize=14)

    plot_acf(serie, lags=15, ax=ax[0])
    plot_pacf(serie, lags=15, ax=ax[1])

    ax[0].set_title('ACF')
    ax[1].set_title('PACF')

    plt.tight_layout()
    st.subheader(f"üìä ACF y PACF ‚Äî {nombre}")
    st.pyplot(fig)

st.markdown("""Conclusiones:

ACF: mide cu√°nta memoria tiene la serie. En los gr√°ficos se puede ver que las barras bajan de a poco, esto quiere decir que lo que pas√≥ a√±os anteriores todav√≠a pesa hoy. Es una caracter√≠stica de series no estacionarias.

PACF: muestra las influencias directas. Ejemplo: Cu√°nto empuja 2019 a 2020 directamente, sin contar con la ayuda de 2018, 2017‚Ä¶? En los gr√°ficos se observa una barra alta en el lag 1 y 2 que luego caen.

""")



st.markdown("""
---

### üîÑ Componente estacional de las emisiones por continente

Estos gr√°ficos muestran la **variaci√≥n estacional** de las emisiones agroalimentarias en cada continente, obtenida mediante un modelo de descomposici√≥n STL (Seasonal-Trend decomposition using Loess). A diferencia del gr√°fico anterior que muestra la tendencia global, este a√≠sla **los patrones c√≠clicos o repetitivos** presentes en las emisiones a lo largo del tiempo.

#### üß© ¬øQu√© representa la curva en cada gr√°fico?
- El eje X representa los a√±os.
- El eje Y representa la **fluctuaci√≥n estacional** de las emisiones (desvinculada de la tendencia general).
- Valores positivos o negativos indican cu√°nto se desv√≠a la serie por efecto estacional en distintos momentos.

#### üîç Observaciones clave:

- **Am√©rica y Asia** muestran oscilaciones c√≠clicas claras, lo que sugiere que hay factores repetitivos (como campa√±as agr√≠colas o pol√≠ticas energ√©ticas) que influyen peri√≥dicamente.
- **Europa** presenta una componente estacional m√°s tenue, reflejo de pol√≠ticas m√°s estables y menor variabilidad estructural.
- **√Åfrica y Ocean√≠a** tienen variaciones m√°s irregulares o menos pronunciadas, posiblemente asociadas a factores clim√°ticos o econ√≥micos puntuales.

---

### üìå Conclusi√≥n

El an√°lisis estacional es fundamental para detectar **patrones ocultos** que se repiten en el tiempo. Estos insights permiten afinar los modelos predictivos, entender la influencia del calendario agr√≠cola, y anticipar picos o ca√≠das sistem√°ticas en las emisiones.
""")


fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

# Lista de series y t√≠tulos
series = [
    ('Am√©rica', serie_america['Valor']),
    ('Asia', serie_asia['Valor']),
    ('Europa', serie_europa['Valor']),
    ('Ocean√≠a', serie_oceania['Valor']),
    ('√Åfrica', serie_africa['Valor'])
]

# Graficar componente 'seasonal' de cada STL
for i, (titulo, serie) in enumerate(series):
    stl = STL(serie, period=5).fit()
    axes[i].plot(serie.index, stl.seasonal)
    axes[i].set_title(f'Tendencia - {titulo}')
    axes[i].set_xlabel('A√±o')
    axes[i].set_ylabel('Valor')

# Eliminar el subplot vac√≠o (el sexto)
fig.delaxes(axes[5])

plt.tight_layout()
st.pyplot(plt)

st.markdown("### üìä Proporci√≥n de varianza explicada por la estacionalidad")

# Lista de pares (nombre, serie)
series = [
    ('Am√©rica', serie_america['Valor']),
    ('Asia', serie_asia['Valor']),
    ('Europa', serie_europa['Valor']),
    ('Ocean√≠a', serie_oceania['Valor']),
    ('√Åfrica', serie_africa['Valor'])
]

# Calcular proporci√≥n varianza estacional / total
resultados = []
for nombre, serie in series:
    stl = STL(serie, period=5).fit()
    proporci√≥n = stl.seasonal.var() / serie.var()
    resultados.append((nombre, round(proporci√≥n, 3)))

# Mostrar en tabla
df_var = pd.DataFrame(resultados, columns=["Regi√≥n", "Var(seasonal) / Var(total)"])
st.dataframe(df_var, use_container_width=True)

st.markdown("""La varianza explicada por la componente estacional en todas las regiones se encuentra entre el **0.1% y el 2.8%** de la varianza total. Esto indica que **no existe un patr√≥n estacional fuerte** en ninguna de las series.

En particular:

- Asia, √Åfrica y Am√©rica muestran una **estacionalidad muy d√©bil** (‚â§ 1.5%).
- Europa, aunque algo mayor, tambi√©n se mantiene por debajo del 3%.
- En Ocean√≠a no se pudo calcular por falta de variabilidad o datos incompletos.

### üß† Conclusi√≥n:
Dado que la **contribuci√≥n estacional es insignificante**, tratamos las series como **no estacionales**, y podemos modelarlas directamente con un modelo **ARIMA convencional** (o un SARIMA con `s = 1`, que equivale a lo mismo). Solo es necesario diferenciar la serie para eliminar la tendencia.
""")

st.markdown("""### Pruebas de estacionaridad""")
st.markdown("""# üìâ Prueba ADF (Augmented Dickey-Fuller)

La **prueba ADF (Augmented Dickey-Fuller)** es una prueba estad√≠stica fundamental en el an√°lisis de series temporales. Se utiliza para determinar si una serie es **estacionaria**, es decir, si sus propiedades estad√≠sticas (como la media, la varianza y la autocorrelaci√≥n) **se mantienen constantes en el tiempo**.

---

## üîç ¬øPor qu√© es importante la estacionariedad?

Muchos modelos de series temporales ‚Äîcomo **ARIMA**, **SARIMA**, etc.‚Äî requieren que la serie sea estacionaria para funcionar correctamente. Si una serie no es estacionaria (por ejemplo, tiene una tendencia o estacionalidad no corregida), los modelos pueden producir **predicciones sesgadas o err√°ticas**.

---

## üìê Fundamento de la prueba ADF

La prueba ADF es una extensi√≥n de la **prueba de Dickey-Fuller**, que incluye **t√©rminos adicionales de rezago (lags)** de la variable dependiente para capturar autocorrelaci√≥n residual y mejorar la robustez del test.

La forma general de la regresi√≥n que se estima es:

\[
\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \sum_{i=1}^{p} \delta_i \Delta y_{t-i} + \varepsilon_t
\]

Donde:

- \( y_t \) es la serie original.
- \( \Delta y_t = y_t - y_{t-1} \) representa la primera diferencia.
- \( t \) es una tendencia determinista (opcional).
- \( \gamma \) es el par√°metro clave que se analiza.
- \( \varepsilon_t \) es el error aleatorio.
- \( p \) es el n√∫mero de rezagos incluidos.

---

## üéØ Hip√≥tesis de la prueba ADF

| Hip√≥tesis nula \( H_0 \)            | Hip√≥tesis alternativa \( H_1 \)         |
|-------------------------------------|-----------------------------------------|
| La serie tiene una ra√≠z unitaria ‚Üí no es estacionaria. | La serie es estacionaria (no tiene ra√≠z unitaria). |

---

## üß™ Interpretaci√≥n de resultados

- **Si el valor p es menor que un nivel de significancia (por ejemplo, 0.05):**
  - Se **rechaza la hip√≥tesis nula**.
  - Concluimos que la serie **es estacionaria**.

- **Si el valor p es mayor que 0.05:**
  - **No se puede rechazar** la hip√≥tesis nula.
  - La serie **no es estacionaria**.

Tambi√©n puede compararse el **estad√≠stico ADF** con los **valores cr√≠ticos** (critical values) al 1%, 5% y 10%.

---
""")
st.markdown("### üìâ Test de Estacionariedad ADF por continente")

series_continentales = {
    'Am√©rica': serie_america['Valor'],
    'Asia': serie_asia['Valor'],
    'Europa': serie_europa['Valor'],
    'Ocean√≠a': serie_oceania['Valor'],
    '√Åfrica': serie_africa['Valor'],
}

# Para tabla resumen
resumen_adf = []

# Evaluar ADF
for nombre, serie in series_continentales.items():
    st.markdown(f"#### üåç {nombre}")
    serie_sin_na = serie.dropna()

    if len(serie_sin_na) < 3:
        st.warning("Serie vac√≠a o con muy pocos datos, se omite.")
        resumen_adf.append({
            "Regi√≥n": nombre,
            "ADF Statistic": "N/A",
            "p-value": "N/A",
            "Estacionaria": "No evaluada"
        })
        continue

    try:
        result = adfuller(serie_sin_na)
        adf_stat = result[0]
        p_value = result[1]
        critical_values = result[4]

        st.markdown(f"- **ADF Statistic**: `{adf_stat:.4f}`")
        st.markdown(f"- **p-value**: `{p_value:.4f}`")
        st.markdown("- **Valores cr√≠ticos:**")
        for key, value in critical_values.items():
            st.markdown(f"  - {key}: `{value:.4f}`")

        if p_value < 0.05:
            st.success("‚úÖ La serie **es estacionaria** (se rechaza H0)")
            conclusion = "‚úÖ S√≠"
        else:
            st.error("üö´ La serie **NO es estacionaria** (no se rechaza H0)")
            conclusion = "üö´ No"

        resumen_adf.append({
            "Regi√≥n": nombre,
            "ADF Statistic": round(adf_stat, 4),
            "p-value": round(p_value, 4),
            "Estacionaria": conclusion
        })

    except Exception as e:
        st.error(f"‚ö†Ô∏è Error al procesar la serie: {e}")
        resumen_adf.append({
            "Regi√≥n": nombre,
            "ADF Statistic": "Error",
            "p-value": "Error",
            "Estacionaria": "Error"
        })

# Mostrar tabla resumen
st.markdown("### üìã Resumen del test ADF")
df_resumen_adf = pd.DataFrame(resumen_adf)
st.dataframe(df_resumen_adf, use_container_width=True)

st.write("")
st.write("")

st.markdown("""# üìä Prueba KPSS (Kwiatkowski‚ÄìPhillips‚ÄìSchmidt‚ÄìShin)

La **prueba KPSS** es una herramienta estad√≠stica que se utiliza para verificar la **estacionariedad** de una serie temporal. A diferencia de la prueba ADF (Augmented Dickey-Fuller), la prueba KPSS parte de una hip√≥tesis **opuesta**.

---

## üß† ¬øPor qu√© KPSS?

Mientras que la prueba ADF eval√∫a si una serie tiene **una ra√≠z unitaria** (es decir, si **no es estacionaria**), la prueba KPSS eval√∫a si la serie es **estacionaria en nivel o tendencia**.

---

## ‚öñÔ∏è Hip√≥tesis de la prueba KPSS

| Hip√≥tesis nula \( H_0 \)                    | Hip√≥tesis alternativa \( H_1 \)                      |
|---------------------------------------------|------------------------------------------------------|
| La serie **es estacionaria** (en nivel o tendencia). | La serie **no es estacionaria** (tiene ra√≠z unitaria). |

> ‚ö†Ô∏è ¬°Esto es exactamente lo contrario de la prueba ADF!

---

## üìê Formulaci√≥n

La prueba se basa en la descomposici√≥n de una serie temporal como:

\[
y_t = r_t + \beta t + \varepsilon_t
\]

Donde:
- \( r_t \): componente estacionaria (o aleatoria).
- \( \beta t \): tendencia determinista.
- \( \varepsilon_t \): error aleatorio.

Se calcula un estad√≠stico de prueba que mide la varianza acumulada de los residuos de una regresi√≥n de \( y_t \) sobre \( t \), y se compara contra valores cr√≠ticos.

---

## üß™ Interpretaci√≥n de resultados

- Si el **p-valor es bajo (p < 0.05)**:
  - Se **rechaza la hip√≥tesis nula**.
  - Concluimos que la serie **no es estacionaria**.
  
- Si el **p-valor es alto (p ‚â• 0.05)**:
  - **No se rechaza** la hip√≥tesis nula.
  - Se considera que la serie **es estacionaria**.

""")

st.markdown("### üìâ Test de Estacionariedad KPSS por continente")


### ‚úÖ 2. Versi√≥n en **Streamlit** del c√≥digo que ejecuta la prueba KPSS para cada serie continental

alpha = 0.05  # nivel de significancia

for nombre, serie in series_continentales.items():
    st.subheader(f"üåç {nombre}")

    serie = serie.dropna()

    if len(serie) < 3:
        st.warning("‚ö†Ô∏è Serie vac√≠a o muy corta, se omite.")
        continue

    try:
        stat, p, lags, crit = kpss(serie, regression='ct')
        st.write(f"**Estad√≠stico KPSS:** {stat:.3f}")
        st.write(f"**p-valor:** {p:.3f}")
        st.write(f"**N√∫mero de rezagos:** {lags}")

        if p < alpha:
            st.error("‚ùå **NO estacionaria** (se rechaza H‚ÇÄ)")
        else:
            st.success("‚úÖ Sin evidencia contra la estacionaridad (no se rechaza H‚ÇÄ)")

        # Mostrar los valores cr√≠ticos como tabla
        st.markdown("**Valores cr√≠ticos:**")
        st.table(pd.DataFrame(crit.items(), columns=["Nivel", "Valor cr√≠tico"]))

    except Exception as e:
        st.warning(f"‚ö†Ô∏è Error al procesar {nombre}: {e}")



st.markdown("""### Resultados de las Pruebas de Estacionariedad:

- Am√©rica: tanto la prueba ADF como KPSS coinciden en que la serie no es estacionaria. Tratamiento: vamos a realizar una diferenciaci√≥n (d = 1).
- Asia: existe un conflicto leve entre las pruebas. ADF rechaza la estacionariedad, mientras KPSS no la rechaza. Tratamiento: vamos a partir de una primera diferenciaci√≥n y hacer pruebas.
- Europa: conflicto. KPSS indica que no hay estacionariedad mientras ADF rechaza la H0, indicando lo contrario. Tratamiento: vamos a hacer pruebas luego de una primera diferenciaci√≥n.
- Ocean√≠a: las pruebas se contradicen. Tratamiento: d = 1.
- √Åfrica: ADF concluye que la serie no es estacionaria y KPSS no tiene evidencia contra la estacionariedad. Tratamiento: primera diferenciaci√≥n.""")

st.markdown("### üîç Estacionariedad y diferenciaci√≥n para modelado ARIMA")
st.markdown("""## üìâ Diferenciaci√≥n

### ¬øPara qu√© sirve?

La **diferenciaci√≥n** es la operaci√≥n m√°s sencilla y com√∫n para "arreglar" una serie temporal que **no es estacionaria**.

Consiste en restar cada valor de la serie con su valor inmediatamente anterior:

\[
\Delta y_t = y_t - y_{t-1}
\]

Esta operaci√≥n elimina tendencias lineales o estructuras de crecimiento acumulativo, haciendo que la serie tenga **media y varianza m√°s estables en el tiempo**.

Es una herramienta clave en el modelado con ARIMA, donde el par√°metro \( d \) indica cu√°ntas veces se debe diferenciar la serie para volverla estacionaria.
""")

alpha = 0.05  # Nivel de significancia

# Diccionario de series por continente
differenced_series = {
    'Am√©rica': serie_america,
    'Asia': serie_asia,
    'Europa': serie_europa,
    'Ocean√≠a': serie_oceania,
    '√Åfrica': serie_africa,
}

# Lista para resumen final
resultados_adf_kpss = []

# Funci√≥n auxiliar
def test_adf(serie):
    result = adfuller(serie.dropna())
    adf_stat, p_value, _, _, critical_values, _ = result
    return adf_stat, p_value, critical_values

for nombre, df in differenced_series.items():
    st.markdown(f"#### üåç {nombre}")

    df = df.copy()
    df['Valor_diff'] = df['Valor'].diff()
    df.dropna(subset=['Valor_diff'], inplace=True)
    serie_diff = df['Valor_diff']

    if serie_diff.size < 3:
        st.warning("‚ö†Ô∏è No hay suficientes datos para testear la serie diferenciada.")
        resultados_adf_kpss.append({
            "Regi√≥n": nombre,
            "ADF diferenciada": "‚Äì",
            "p-valor ADF": "‚Äì",
            "Estacionaria ADF": "No evaluada",
            "KPSS diferenciada": "‚Äì",
            "p-valor KPSS": "‚Äì",
            "Estacionaria KPSS": "No evaluada",
        })
        continue

    # --- ADF ---
    adf_stat, pval_adf, crit_adf = test_adf(serie_diff)
    est_adf = "S√≠" if pval_adf < alpha else "No"
    st.markdown(f"- **ADF:** estad√≠stico = `{adf_stat:.4f}`, p-valor = `{pval_adf:.4f}` ‚Üí Estacionaria: **{'‚úÖ S√≠' if est_adf == 'S√≠' else 'üö´ No'}**")

    # --- KPSS ---
    try:
        kpss_stat, pval_kpss, lags_kpss, crit_kpss = kpss(serie_diff, regression='ct')
        est_kpss = "No" if pval_kpss < alpha else "S√≠"
        st.markdown(f"- **KPSS:** estad√≠stico = `{kpss_stat:.4f}`, p-valor = `{pval_kpss:.4f}` ‚Üí Estacionaria: **{'‚úÖ S√≠' if est_kpss == 'S√≠' else 'üö´ No'}**")
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Error en prueba KPSS para {nombre}: {e}")
        kpss_stat = pval_kpss = est_kpss = "‚Äì"

    # Guardar en resumen
    resultados_adf_kpss.append({
        "Regi√≥n": nombre,
        "ADF diferenciada": round(adf_stat, 4),
        "p-valor ADF": round(pval_adf, 4),
        "Estacionaria ADF": est_adf,
        "KPSS diferenciada": round(kpss_stat, 4) if isinstance(kpss_stat, float) else kpss_stat,
        "p-valor KPSS": round(pval_kpss, 4) if isinstance(pval_kpss, float) else pval_kpss,
        "Estacionaria KPSS": est_kpss
    })

# --- Mostrar resumen final ---
st.markdown("### üìã Resumen de pruebas ADF y KPSS sobre la serie diferenciada")
df_diff_resumen = pd.DataFrame(resultados_adf_kpss)
st.dataframe(df_diff_resumen, use_container_width=True)




st.markdown("""
---
## üìå Conclusiones luego de testear la estacionariedad en las series diferenciadas

- **Am√©rica:** ambos tests concuerdan. Serie **estacionaria**.
- **Asia:** resultado **mixto**. ADF afirma que es estacionaria, mientras KPSS indica que **no lo es**.
- **Europa:** los tests coinciden. Serie **estacionaria**.
- **Ocean√≠a:** los tests coinciden. Serie **estacionaria**.
- **√Åfrica:** los tests coinciden. Serie **estacionaria**.

---

## ‚öôÔ∏è Tratamientos propuestos

Se modelar√° cada serie con una **primera diferenciaci√≥n** (`d=1`). Luego, se evaluar√° el comportamiento de los **residuos del modelo**:

- Si los residuos se comportan como **ruido blanco** (sin autocorrelaci√≥n),
- entonces se considerar√° que la elecci√≥n de `d=1` fue **adecuada**,
- **independientemente** de que un test (ADF o KPSS) aislado sugiera lo contrario.
""")
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

series_diff = [
    ('Am√©rica', serie_america),
    ('Asia', serie_asia),
    ('Europa', serie_europa),
    ('Ocean√≠a', serie_oceania),
    ('√Åfrica', serie_africa),
]

for i, (nombre, df) in enumerate(series_diff):
    df = df.sort_values('A√±o')  # <-- Asegura que el eje X est√© bien ordenado

    if 'Valor_diff' in df and df['Valor_diff'].dropna().size >= 3:
        sns.lineplot(x=df['A√±o'], y=df['Valor_diff'], ax=axes[i])
        axes[i].set_title(f'{nombre} - Valor diferenciado')
        axes[i].set_ylabel('Œî Valor')
    elif 'Valor' in df and df['Valor'].dropna().size >= 3:
        sns.lineplot(x=df['A√±o'], y=df['Valor'], ax=axes[i])
        axes[i].set_title(f'{nombre} - Serie original (estacionaria)')
        axes[i].set_ylabel('Valor')
    else:
        axes[i].set_title(f'{nombre} - Sin datos')
        axes[i].axis('off')

    axes[i].set_xlabel('A√±o')

fig.delaxes(axes[5])
plt.tight_layout()
st.subheader("üìâ Visualizaci√≥n de series diferenciadas u originales por continente")
st.pyplot(fig)

st.markdown("""## üìä ACF y PACF en series temporales

### üîÑ ¬øQu√© es la ACF (Autocorrelation Function)?

La **Funci√≥n de Autocorrelaci√≥n (ACF)** mide la correlaci√≥n lineal entre una serie temporal y **sus propios rezagos** (valores pasados).

- **ACF(k)** indica cu√°nto se correlaciona la serie consigo misma desplazada `k` pasos.
- Se representa con un gr√°fico que muestra los coeficientes de correlaci√≥n para distintos rezagos.
- Incluye tanto los efectos **directos como indirectos** (es decir, puede verse afectada por rezagos intermedios).

#### üìå ¬øPara qu√© se usa?

- Para identificar la presencia de **dependencia temporal**.
- Para ayudar a definir el orden `q` en modelos **ARIMA** (componente MA: media m√≥vil).
- Para detectar patrones de estacionalidad o ciclos.

---

### üîÅ ¬øQu√© es la PACF (Partial Autocorrelation Function)?

La **Funci√≥n de Autocorrelaci√≥n Parcial (PACF)** mide la correlaci√≥n entre la serie y sus rezagos, **controlando los efectos de los rezagos intermedios**.

- PACF(k) muestra la relaci√≥n entre `X_t` y `X_{t-k}` *una vez eliminada* la influencia de los rezagos `1` hasta `k-1`.
- A√≠sla la contribuci√≥n directa de cada rezago.

#### üìå ¬øPara qu√© se usa?

- Para estimar el orden `p` en un modelo **ARIMA** (componente AR: autorregresivo).
- Permite entender **cu√°l es el n√∫mero m√≠nimo de rezagos necesarios** para explicar la dependencia.

---

### üìà ¬øC√≥mo se interpretan los gr√°ficos?

Ambas funciones se grafican con l√≠neas verticales por cada rezago, junto a un intervalo de confianza (por ejemplo, 95%).

- Si un valor **supera el l√≠mite de confianza**, se considera **estad√≠sticamente significativo**.
- Una **ca√≠da brusca** en ACF o PACF sugiere el orden adecuado para `q` o `p` respectivamente.

---

### üß† En resumen

| Funci√≥n | Eval√∫a...                        | Ayuda a definir... | Considera efectos indirectos |
|---------|----------------------------------|---------------------|------------------------------|
| **ACF** | Correlaci√≥n con rezagos          | `q` en ARIMA        | ‚úÖ S√≠                         |
| **PACF**| Correlaci√≥n parcial (solo directa)| `p` en ARIMA        | ‚ùå No                         |
""")

# 1. Diferenciar primero
for nombre, df in series_diff:
    if 'Valor' in df and 'Valor_diff' not in df:
        df['Valor_diff'] = df['Valor'].diff()
        df.dropna(inplace=True)

# 2. Luego graficar
for nombre, df in series_diff:
    st.markdown(f"### üåé {nombre}")

    if 'Valor_diff' not in df:
        st.warning("‚ö†Ô∏è No tiene columna `Valor_diff`, se omite.")
        continue

    serie = df['Valor_diff'].dropna()

    if len(serie) < 10:
        st.warning("‚ö†Ô∏è Muy pocos datos para mostrar ACF/PACF confiables.")
        continue

    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    fig.suptitle(f'ACF y PACF - {nombre} (Valor diferenciado)', fontsize=14)

    plot_acf(serie, lags=15, ax=ax[0])
    plot_pacf(serie, lags=15, ax=ax[1])

    ax[0].set_title('ACF')
    ax[1].set_title('PACF')

    st.pyplot(fig)




st.markdown("""## ‚úÖ Estacionariedad lograda con primera diferencia

La **primera diferencia** logr√≥ que las series sean estacionarias:

- Las **colas largas** en la funci√≥n de autocorrelaci√≥n (ACF) desaparecieron.
- La mayor√≠a de las barras est√°n dentro de la **franja de confianza**.
- Todas las series cumplen con el requisito de **varianza y media constantes**.

Por lo tanto, ya podemos aplicar un modelo **ARIMA** a cada una.

---

## üîç Selecci√≥n del mejor modelo ARIMA

Luego de lograr la estacionariedad, vamos a buscar el **mejor modelo ARIMA** para cada serie.

El siguiente procedimiento permite comparar m√∫ltiples modelos con:

- `d = 1` (primera diferencia fija),
- `p` y `q` variando entre 0 y 3.

Se presentan los **3 mejores modelos** seg√∫n:

1. **Precisi√≥n** del pron√≥stico (*MAPE*),
2. **Simplicidad** del modelo (*AIC*),
3. **Validez estad√≠stica** del ajuste (residuos como **ruido blanco**).
""")


# Ignorar warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=ValueWarning)
warnings.filterwarnings("ignore")

# Diccionario de series originales (ya diferenciadas previamente si corresponde)
series = {
    'Am√©rica': serie_america['Valor'].astype(float),
    'Asia':    serie_asia['Valor'].astype(float),
    'Europa':  serie_europa['Valor'].astype(float),
    'Ocean√≠a': serie_oceania['Valor'].astype(float),
    '√Åfrica':  serie_africa['Valor'].astype(float)
}

# Hiperpar√°metros de test y diferenciaci√≥n
h_test = 5
d = 1

# Funci√≥n para buscar los mejores modelos ARIMA
def grid_search_arima(y_train, y_test, p_max=3, q_max=3, top_k=3, lb_lags=10):
    resultados = []
    for p, q in itertools.product(range(p_max + 1), range(q_max + 1)):
        try:
            modelo = SARIMAX(y_train, order=(p, d, q),
                             enforce_stationarity=False,
                             enforce_invertibility=False).fit(disp=False)

            forecast = modelo.get_forecast(steps=len(y_test)).predicted_mean
            mape = mean_absolute_percentage_error(y_test, forecast) * 100

            lb_p = acorr_ljungbox(modelo.resid, lags=[lb_lags],
                                  return_df=True)['lb_pvalue'].iloc[-1]

            resultados.append({
                'order': (p, d, q),
                'aic': modelo.aic,
                'mape': mape,
                'lb_p': lb_p,
                'ok': lb_p > 0.05,
                'mod': modelo
            })
        except Exception:
            continue

    resultados = sorted(resultados, key=lambda x: (x['mape'], x['aic']))
    return resultados[:top_k]

# T√≠tulo principal en Streamlit
st.title("üìä Comparaci√≥n de modelos ARIMA")

# Loop sobre todas las series
resultados = {}
for nombre, serie in series.items():
    st.markdown(f"## üåé {nombre}")

    y_train, y_test = serie.iloc[:-h_test], serie.iloc[-h_test:]
    top_modelos = grid_search_arima(y_train, y_test)

    resultados[nombre] = top_modelos

    for i, modelo in enumerate(top_modelos, 1):
        st.markdown(f"""
        **{i}. ARIMA{modelo['order']}**  
        ‚Ä¢ üìâ AIC = `{modelo['aic']:.2f}`  
        ‚Ä¢ üéØ MAPE (test) = `{modelo['mape']:.2f}%`  
        ‚Ä¢ üß™ Ljung‚ÄëBox p-valor = `{modelo['lb_p']:.3f}` ‚Üí {'‚úÖ OK' if modelo['ok'] else '‚ùå NO'}
        """)
st.markdown("""Se exploraron modelos **ARIMA (p,1,q)** con `p` y `q` entre 0 y 3.  
Para cada continente se muestran los **3 modelos con menor error de pron√≥stico** sin sobreajustar la serie (medido mediante el **AIC**).  
Adem√°s, se evalu√≥ que los residuales **no presenten autocorrelaci√≥n** mediante el test de **Ljung-Box**.

##### üìå Modelos Seleccionados:

- **Am√©rica**: ARIMA(0,1,3)  
- **Asia**: ARIMA(1,1,1)  
- **Europa**: ARIMA(1,1,3)  
- **Ocean√≠a**: ARIMA(2,1,3)  
- **√Åfrica**: ARIMA(2,1,3)
""")

import streamlit as st
import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Par√°metros por continente
parametros_arima = {
    'Am√©rica': (0, 1, 3),
    'Asia': (1, 1, 1),
    'Europa': (1, 1, 3),
    'Ocean√≠a': (2, 1, 3),
    '√Åfrica': (2, 1, 3)
}

# Series de tiempo
series_dict = {
    'Am√©rica': serie_america,
    'Asia': serie_asia,
    'Europa': serie_europa,
    'Ocean√≠a': serie_oceania,
    '√Åfrica': serie_africa
}

h_test = 5

for nombre, df in series_dict.items():
    st.markdown(f"### üåç {nombre}")

    if 'Valor' not in df.columns:
        st.warning("‚ö†Ô∏è No tiene columna `Valor`, se omite.")
        continue

    y = df['Valor'].dropna()
    y_train, y_test = y.iloc[:-h_test], y.iloc[-h_test:]

    if len(y_train) < 10:
        st.warning("‚ö†Ô∏è Muy pocos datos para ajustar el modelo.")
        continue

    try:
        p, d, q = parametros_arima[nombre]
        model = SARIMAX(
            y_train,
            order=(p, d, q),
            enforce_stationarity=False,
            enforce_invertibility=False
        )
        res = model.fit(disp=False)

        # Mostrar resumen como texto en bloque
        st.code(res.summary().as_text(), language='text')

        # Diagn√≥stico gr√°fico
        fig = res.plot_diagnostics(figsize=(10, 5))
        plt.suptitle(f'Diagn√≥stico del modelo ARIMA para {nombre}', fontsize=14)
        st.pyplot(fig)

    except Exception as e:
        st.error(f"‚ùå Error al ajustar modelo para {nombre}: {e}")
st.markdown("""## An√°lisis de los Residuales del Modelo ARIMA

- **L√≠nea de Residuales:**  
  Podemos observar que, en los gr√°ficos de l√≠nea de residuales, los errores del modelo a√±o a a√±o oscilan alrededor de cero, salvo alg√∫n pico aislado en *Am√©rica*.

- **Histograma:**  
  En el histograma se aprecia la distribuci√≥n de los errores.  
  - En *√Åfrica* y *Asia*, la distribuci√≥n coincide bastante con la l√≠nea verde que representa una distribuci√≥n normal.  
  - En *Am√©rica* y *Europa*, se observan colas un poco m√°s anchas, indicando cierta desviaci√≥n de la normalidad.  
  - *Ocean√≠a* presenta el mejor ajuste, con una distribuci√≥n muy cercana a la normal.

- **Q-Q Plot:**  
  El gr√°fico Q-Q compara los errores reales con los que tendr√≠a una distribuci√≥n normal perfecta.  
  - La mayor√≠a de los puntos siguen la l√≠nea roja, lo que indica normalidad en los residuos.  
  - Se observan leves desv√≠os en algunos casos, pero no son significativos.

- **Correlograma de Residuales (ACF):**  
  Permite observar si hay autocorrelaci√≥n en los errores.  
  - En todos los gr√°ficos, las barras se encuentran dentro de la franja azul de confianza, lo que sugiere que **los residuos se comportan como ruido blanco**, sin memoria temporal significativa.
""")

st.markdown("""
### üîÆ Predicciones

En el caso de **√Åfrica** y **Asia**, luego de la primera diferenciaci√≥n observamos que los **cambios anuales son casi siempre positivos**, es decir, cada a√±o se emite un poco m√°s de gases de efecto invernadero.

Por este motivo, se a√±ade el par√°metro `trend='t'` al modelo ARIMA, lo cual le permite **proyectar una tendencia creciente** teniendo en cuenta la din√°mica reciente de la serie.

> üí° **Alternativa:**  
> Otra opci√≥n ser√≠a aplicar una **segunda diferenciaci√≥n** (`d=2`), aunque esto podr√≠a introducir m√°s ruido y hacer que el modelo pierda informaci√≥n relevante sobre la tendencia subyacente.
""")
series_dict = {
    'Am√©rica': serie_america,
    'Asia': serie_asia,
    'Europa': serie_europa,
    'Ocean√≠a': serie_oceania,
    '√Åfrica': serie_africa
}

modelos_config = {
    'Am√©rica':  {'order': (0, 1, 3)},
    'Asia':     {'order': (1, 1, 1), 'trend': 't'},
    'Europa':   {'order': (1, 1, 3)},
    'Ocean√≠a':  {'order': (2, 1, 3)},
    '√Åfrica':   {'order': (2, 1, 3), 'trend': 't'}
}

h_test, h_future = 5, 5

fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for i, (nombre, df) in enumerate(series_dict.items()):
    serie = df.set_index('A√±o')['Valor'].sort_index().dropna().astype(float)
    serie.index = pd.PeriodIndex(serie.index, freq='Y')

    y_train, y_test = serie.iloc[:-h_test], serie.iloc[-h_test:]
    cfg = modelos_config[nombre]
    trend = cfg.get('trend', 'n')

    res = SARIMAX(
        y_train,
        order=cfg['order'],
        trend=trend,
        enforce_stationarity=False,
        enforce_invertibility=False
    ).fit(disp=False)

    fitted = res.fittedvalues
    fc_test = res.get_forecast(h_test)
    pred_test = fc_test.predicted_mean
    ci_test = fc_test.conf_int()

    fc_fut = res.get_forecast(h_future)
    pred_fut = fc_fut.predicted_mean
    ci_fut = fc_fut.conf_int()

    pred_test.index = pd.period_range(y_train.index[-1] + 1, periods=h_test, freq='Y')
    pred_fut.index = pd.period_range(pred_test.index[-1] + 1, periods=h_future, freq='Y')
    ci_test.index, ci_fut.index = pred_test.index, pred_fut.index

    pred_full = pd.concat([fitted, pred_test, pred_fut])
    mape = mean_absolute_percentage_error(y_test, pred_test) * 100

    ax = axes[i]
    ax.plot(serie.index.to_timestamp(), serie, label='Observado', color='steelblue', alpha=.6)
    ax.plot(pred_full.index.to_timestamp(), pred_full, color='firebrick', lw=2, label='Modelo ARIMA')
    ax.fill_between(pred_test.index.to_timestamp(), ci_test.iloc[:, 0], ci_test.iloc[:, 1],
                    color='firebrick', alpha=.25, label='IC 95 % (test)')
    ax.fill_between(pred_fut.index.to_timestamp(), ci_fut.iloc[:, 0], ci_fut.iloc[:, 1],
                    color='darkorange', alpha=.20, label='IC 95 % (futuro)')

    ax.axvline(y_train.index[-1].to_timestamp(), color='grey', ls='--')
    ax.axvline(y_test.index[-1].to_timestamp(), color='grey', ls='--')

    ax.set(title=f'{nombre} (MAPE: {mape:.2f}%)',
           xlabel='A√±o', ylabel='kt CO‚ÇÇ-eq')
    ax.legend()
    ax.grid(ls='--', alpha=.3)

# Si hay menos de 6 gr√°ficos, eliminar ejes sobrantes
if len(series_dict) < len(axes):
    for j in range(len(series_dict), len(axes)):
        fig.delaxes(axes[j])

plt.tight_layout()
st.pyplot(fig)


st.markdown("""
### üåä Caso Ocean√≠a

En la serie de Ocean√≠a hab√≠amos observado que la **varianza explicada por un ciclo de 5 a√±os supera el 38%**.  
Sin embargo, luego de aplicar una primera diferenciaci√≥n, observamos en los gr√°ficos **ACF** y **PACF** que los *lags* 4, 5 y 10 **caen dentro de la franja azul**, lo que indica que **la estacionalidad ya est√° explicada**.

Aplicar un modelo **SARIMA** implicar√≠a agregar m√°s par√°metros para representar solo **6 ciclos observados (30 a√±os)**, lo cual podr√≠a llevar a un **sobreajuste** por la escasez de datos.

Adem√°s, los resultados obtenidos con el modelo **ARIMA simple** muestran un **ajuste adecuado** y consistente, por lo tanto **no se justifica complejizar el modelo** con un componente estacional.
""")


st.markdown("""## Utilizando Prophet""")

st.markdown("""
### üîÆ ¬øQu√© es Prophet?

**Prophet** es una herramienta de pron√≥stico de series temporales desarrollada por **Facebook (Meta)**. Est√° pensada para:

- Modelar **tendencias no lineales**.
- Capturar **cambios de r√©gimen** o inflexiones en la evoluci√≥n hist√≥rica.
- Incluir opcionalmente **estacionalidades** (diarias, semanales, anuales).
- Ser **f√°cil de usar** para analistas sin conocimientos avanzados en estad√≠stica.

---

### üßÆ Prophet descompone la serie temporal de la siguiente forma:

- y(t) = g(t) + s(t) + h(t) + Œµ_t            

Donde:

- **g(t)** ‚Üí Tendencia (puede ser lineal o log√≠stica, con posibles "cambios de pendiente").
- **s(t)** ‚Üí Estacionalidad (opcional, puede ser anual, semanal, diaria).
- **h(t)** ‚Üí Efectos por fechas especiales (festivos, eventos).
- **Œµ_t** ‚Üí Ruido aleatorio (residuo no explicado).

---

### ‚úÖ Beneficios clave frente a ARIMA

| Beneficio clave                       | ¬øPor qu√© importa en tu dataset?                                                                                                 |
| ------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
|  Captura **cambios de tendencia**     | Las emisiones no evolucionan linealmente. Prophet detecta **cambios de pendiente autom√°ticamente**, lo que ARIMA no hace bien.  |
|  No requiere **estacionariedad**      | Prophet **no exige diferenciar** ni transformar la serie. SARIMA s√≠, y esto puede distorsionar el significado del pron√≥stico.   |
|  Funciona bien con **datos anuales**  | Las series son anuales. Prophet acepta f√°cilmente series con cualquier frecuencia sin reconfigurar nada.                        |
|  Maneja bien la **incertidumbre**     | Prophet devuelve autom√°ticamente **intervalos de confianza del 95%**, facilitando la comunicaci√≥n de riesgo/incertidumbre.      |
|  Automatizable por regi√≥n             | Se puede aplicar el mismo modelo a cada continente sin tunear manualmente los par√°metros. Ideal para **automatizaci√≥n**.        |
|  Interpretabilidad de componentes     | Prophet permite ver **la tendencia sola**, algo √∫til para an√°lisis visual y argumentaci√≥n.                                      |
""")

h_test = 5
h_future = 5
resultados = {}

fig, axes = plt.subplots(2, 3, figsize=(22, 10))
axes = axes.flatten()

for idx, (nombre, df) in enumerate(series_dict.items()):
    # Preprocesamiento
    serie = df[['A√±o', 'Valor']].dropna().copy()
    serie = serie.sort_values('A√±o')
    serie['A√±o'] = serie['A√±o'].astype(int)
    serie = serie.rename(columns={'A√±o': 'ds', 'Valor': 'y'})
    serie['ds'] = pd.to_datetime(serie['ds'], format='%Y')

    y_train = serie.iloc[:-h_test]
    y_test = serie.iloc[-h_test:]

    # Modelo Prophet
    model = Prophet(
        yearly_seasonality=False,
        changepoint_range=0.9,
        n_changepoints=5
    )
    model.add_seasonality(name='quinquenal', period=5, fourier_order=2)
    model.fit(y_train)

    future_test = model.make_future_dataframe(periods=h_test, freq='Y', include_history=False)
    forecast_test = model.predict(future_test)

    future_total = model.make_future_dataframe(periods=h_test + h_future, freq='Y')
    forecast_total = model.predict(future_total)

    pred_test = forecast_test.set_index('ds')['yhat']
    pred_future = forecast_total.set_index('ds')['yhat'].iloc[-h_future:]
    ci_test = forecast_test.set_index('ds')[['yhat_lower', 'yhat_upper']]
    ci_future = forecast_total.set_index('ds')[['yhat_lower', 'yhat_upper']].iloc[-h_future:]

    mape = mean_absolute_percentage_error(y_test['y'].values, pred_test.values) * 100

    # Gr√°fico
    ax = axes[idx]
    ax.plot(y_train['ds'], y_train['y'], label='Hist√≥rico (train)', color='steelblue')
    ax.plot(y_test['ds'],  y_test['y'], label='Real (test)', color='black', lw=2)
    ax.plot(pred_test.index, pred_test.values, label='Pron√≥stico test', color='firebrick')
    ax.fill_between(pred_test.index, ci_test['yhat_lower'], ci_test['yhat_upper'],
                    color='firebrick', alpha=.25)
    ax.plot(pred_future.index, pred_future.values, label='Proyecci√≥n 8 a√±os', color='orange')
    ax.fill_between(pred_future.index, ci_future['yhat_lower'], ci_future['yhat_upper'],
                    color='orange', alpha=.20)
    ax.axvline(y_train['ds'].iloc[-1], color='grey', ls='--', lw=1)
    ax.axvline(y_test['ds'].iloc[-1],  color='grey', ls='--', lw=1)
    ax.set(title=f'{nombre} (MAPE={mape:.2f}%)', xlabel='A√±o', ylabel='Kt CO‚ÇÇ‚Äëeq')
    ax.grid(ls='--', alpha=.4)

    resultados[nombre] = {
        'modelo': model,
        'pred_test': pred_test,
        'ci_test': ci_test,
        'pred_future': pred_future,
        'ci_future': ci_future,
        'mape': mape
    }

# Ocultar ejes sobrantes si hay menos de 6
if len(series_dict) < 6:
    for j in range(len(series_dict), 6):
        fig.delaxes(axes[j])

fig.tight_layout()
st.pyplot(fig)


st.markdown("""
### ‚úÖ Conclusiones

Aplicando **Prophet** con una tendencia quinquenal, observamos que en la mayor√≠a de los casos el **üìâ MAPE es mayor** que en ARIMA, salvo en Asia donde es casi similar.

üîç En este caso, **preferimos mantener el modelo ARIMA**, ya que Prophet es m√°s confiable en series con:

- ‚è±Ô∏è **Mayor frecuencia temporal** (diaria, mensual),
- üìà **M√°s observaciones hist√≥ricas**.

> ‚ö†Ô∏è Con solo ~30 observaciones por serie, **Prophet tiende a sobreajustarse**, interpretando como patrones reales lo que probablemente es solo ruido.

---

Con **datos anuales** y sin estacionalidades dentro del a√±o:

‚ùå **Prophet se ajusta de m√°s** y comete m√°s errores.  
‚úÖ **ARIMA**, en cambio:

- ‚úîÔ∏è Es m√°s **sencillo**,
- ‚úîÔ∏è Usa menos **supuestos**,
- ‚úîÔ∏è Y ofrece **mejores pron√≥sticos** para este tipo de series.

üéØ Por estas razones, **ARIMA es el modelo m√°s adecuado** en este contexto.
""")
