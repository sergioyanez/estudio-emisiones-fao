import streamlit as st
import gdown
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import zipfile
import random
import numpy as np
import plotly.express as px
import pycountry
import geopandas as gpd
import plotly.graph_objects as go
import statsmodels.api as sm
import itertools
import time
import warnings
import logging

from statsmodels.tsa.statespace.sarimax import SARIMAX
from prophet import Prophet
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.seasonal import STL
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import acf
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tools.sm_exceptions import ValueWarning
from sklearn.metrics import mean_absolute_percentage_error
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_absolute_percentage_error
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.stats.diagnostic import acorr_ljungbox
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.stats import norm
# Opcional: desactiva warnings excesivos
import warnings
warnings.filterwarnings("ignore")

st.set_page_config(
    page_title="TP Final - Ciencia de Datos",
    layout="wide"
)

st.title("üåç TP Final - Ciencia de Datos")
st.subheader("An√°lisis interactivo de emisiones de gases de efecto invernadero")
st.caption("Dataset FAOSTAT (1961‚Äì2021) ‚Ä¢ Visualizaci√≥n din√°mica ‚Ä¢ Comparaci√≥n por pa√≠s y fuente de emisi√≥n ‚Ä¢ Predicci√≥n a futuro")


def download_and_extract_zip_from_google_drive(file_id, output_dir, zip_name):
    URL = "https://docs.google.com/uc?export=download"
    session = requests.Session()
    response = session.get(URL, params={'id': file_id}, stream=True)
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            response = session.get(URL, params={'id': file_id, 'confirm': value}, stream=True)
            break
    os.makedirs(output_dir, exist_ok=True)
    zip_path = os.path.join(output_dir, zip_name)
    with open(zip_path, 'wb') as f:
        for chunk in response.iter_content(32768):
            f.write(chunk)
    with ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(output_dir)
    os.remove(zip_path)

csv_path = "data/raw/excercise/Emisiones_Totales_S_Todos_los_Datos_(Normalizado).csv"
if not os.path.exists(csv_path):
    st.info("Descargando dataset desde Google Drive...")
    download_and_extract_zip_from_google_drive(
        file_id="1hDcwMcaajRkoaO8trMqqc8DWObGkZl8v",
        output_dir="data/raw/excercise",
        zip_name="Emisiones_Totales_S_Todos_los_Datos_(Normalizado).zip"
    )

df = pd.read_csv(csv_path)
df = df[df['Valor'].notna()]
df['Valor_Mt'] = df['Valor'] / 1e3           # megatoneladas
df['Valor_Gt'] = df['Valor'] / 1e6           # gigatoneladas
df['A√±o'] = pd.to_datetime(df['A√±o'], format='%Y')

# KPIs
# C√°lculos
total_emisiones = df['Valor_Mt'].sum()
anio_min = df['A√±o'].dt.year.min()
anio_max = df['A√±o'].dt.year.max()
total_paises = df['√Årea'].nunique()

# Dise√±o con columnas
col1, col2, col3 = st.columns(3)

col1.metric("üåç Total emisiones (Mt)", f"{total_emisiones:,.2f}")
col2.metric("üìÖ A√±os cubiertos", f"{anio_min} ‚Äì {anio_max}")
col3.metric("üó∫Ô∏è Pa√≠ses √∫nicos", total_paises)


# Mostrar rango temporal
anio_min = df['A√±o'].min().strftime('%Y')
anio_max = df['A√±o'].max().strftime('%Y')

st.subheader(f'üìÜ Rango temporal de los datos: {anio_min}  a  {anio_max}')


# Evoluci√≥n por a√±o
df_anual = df.groupby(df['A√±o'].dt.year).size().reset_index(name='Cantidad')
fig_anual = px.bar(df_anual, x='A√±o', y='Cantidad', title="Cantidad de registros por a√±o")
st.plotly_chart(fig_anual, use_container_width=True)

df_cleaned = df.drop(columns=['Nota','C√≥digo del √°rea', 'C√≥digo del √°rea (M49)', 'C√≥digo del elemento', 'C√≥digo del a√±o', 'C√≥digo fuente']).copy()


regiones = [
    'Mundo', 'Pa√≠ses Anexo I', 'Pa√≠ses No-Anexo I', 'Uni√≥n Europea (27)', 'Uni√≥n Europea (28)',
    '√Åfrica', 'Am√©ricas', 'Europa', 'Asia', 'Ocean√≠a',
    '√Åfrica occidental', '√Åfrica central', '√Åfrica oriental', '√Åfrica meridional', '√Åfrica septentrional',
    'Am√©rica central', 'Am√©rica del Sur', 'Am√©rica septentrional',
    'Europa occidental', 'Europa oriental', 'Europa septentrional', 'Europa meridional',
    'Asia central', 'Asia oriental', 'Asia occidental', 'Asia sudoriental', 'Asia meridional',
    'Australia y Nueva Zelandia', 'El Caribe', 'Melanesia', 'Polinesia', 'Micronesia',
    'OECD', 'URSS', 'Checoslovaq', 'Yugoslav RFS',
    'Los pa√≠ses menos desarrollados', 'Pa√≠ses sin litoral en v√≠as de desarrollo',
    'Pa√≠ses de bajos ingresos y con d√©ficit de alim.', 'Peque√±as islas en v√≠as de Desarrollo',
    'Import netos alim en Des', 'Territorio de las Islas del Pac√≠fico', 'China, Continental'
    ]
df_regiones = df_cleaned[df_cleaned['√Årea'].isin(regiones)].copy()
df_countries = df_cleaned[~df_cleaned['√Årea'].isin(regiones)].copy()
st.subheader("Cantidad de pa√≠ses: " + str(df_countries['√Årea'].nunique()))
# Total original
total_original = len(df_cleaned)

# Total despu√©s de separar
total_regiones = len(df_regiones)
total_paises = len(df_countries)

# Verificar
col1, col2 = st.columns(2)

with col1:
    st.metric("üßÆ Total original", total_original)
    st.metric("üåç Total regiones", total_regiones)

with col2:
    st.metric("üåé Total pa√≠ses", total_paises)
    st.metric("‚ûï Suma regiones + pa√≠ses", total_regiones + total_paises)


countries = df_countries['√Årea'].unique()
fixes = {
    'Anguila': 'Anguilla',
    'Bahrein': 'Bahrain',
    'Bermudas': 'Bermuda',
    'Bhut√°n': 'Bhutan',
    'B√©lgica': 'Belgium',
    'Cabo Verde': 'Cape Verde',
    'Chequia': 'Czechia',
    'Chipre': 'Cyprus',
    'Comoras': 'Comoros',
    'Emiratos √Årabes Unidos': 'United Arab Emirates',
    'Gambia': 'The Gambia',
    'Granada': 'Grenada',
    'Guadalupe': 'Guadeloupe',
    'Guayana Francesa': 'French Guiana',
    'Isla Norfolk': 'Norfolk Island',
    'Isla de Man': 'Isle of Man',
    'Islas Anglonormandas': 'Channel Islands',
    'Islas Caim√°n': 'Cayman Islands',
    'Islas Cook': 'Cook Islands',
    'Islas Feroe': 'Faroe Islands',
    'Islas Marianas del Norte': 'Northern Mariana Islands',
    'Islas Marshall': 'Marshall Islands',
    'Islas Salom√≥n': 'Solomon Islands',
    'Islas Svalbard y Jan Mayen': 'Svalbard and Jan Mayen',
    'Islas Turcas y Caicos': 'Turks and Caicos Islands',
    'Islas V√≠rgenes Brit√°nicas': 'British Virgin Islands',
    'Islas V√≠rgenes de los Estados Unidos': 'United States Virgin Islands',
    'Islas Wallis y Futuna': 'Wallis and Futuna',
    'Martinica': 'Martinique',
    'M√≥naco': 'Monaco',
    'Nueva Caledonia': 'New Caledonia',
    'Palestina': 'Palestine',
    'Pa√≠ses Bajos (Reino de los)': 'Netherlands',
    'Polinesia Francesa': 'French Polynesia',
    'Rep√∫blica Democr√°tica del Congo': 'Democratic Republic of the Congo',
    'Rep√∫blica Democr√°tica Popular Lao': "Lao People's Democratic Republic",
    'Rep√∫blica Popular Democr√°tica de Corea': "Democratic People's Republic of Korea",
    'Reuni√≥n': 'R√©union',
    'Saint Kitts y Nevis': 'Saint Kitts and Nevis',
    'Samoa Americana': 'American Samoa',
    'San Pedro y Miquel√≥n': 'Saint Pierre and Miquelon',
    'Santa Elena, Ascensi√≥n y Trist√°n de Acu√±a': 'Saint Helena, Ascension and Tristan da Cunha',
    'Santa Sede': 'Holy See',
    'Sierra Leona': 'Sierra Leone',
    'Sud√°n (ex)': 'Sudan',
    'S√°hara Occidental': 'Western Sahara',
    'Timor-Leste': 'Timor-Leste',
    'Trinidad y Tabago': 'Trinidad and Tobago',
    'Yugoslav RFS': 'Yugoslavia',
    "Afganist√°n": "Afghanistan",
    "Albania": "Albania",
    "Alemania": "Germany",
    "Angola": "Angola",
    "Antigua y Barbuda": "Antigua and Barbuda",
    "Arabia Saudita": "Saudi Arabia",
    "Argelia": "Algeria",
    "Argentina": "Argentina",
    "Armenia": "Armenia",
    "Austria": "Austria",
    "Azerbaiy√°n": "Azerbaijan",
    "Banglad√©s": "Bangladesh",
    "Bar√©in": "Bahrain",
    "Belice": "Belize",
    "Belar√∫s": "Belarus",
    "Bolivia (Estado Plurinacional de)": "Bolivia",
    "Bosnia y Herzegovina": "Bosnia and Herzegovina",
    "Botsuana": "Botswana",
    "Brasil": "Brazil",
    "Brun√©i Darussalam": "Brunei",
    "Bulgaria": "Bulgaria",
    "Burkina Faso": "Burkina Faso",
    "Camboya": "Cambodia",
    "Camer√∫n": "Cameroon",
    "Canad√°": "Canada",
    "Chad": "Chad",
    "Chile": "Chile",
    "China": "China",
    "Colombia": "Colombia",
    "Corea, Rep√∫blica de": "South Korea",
    "Costa de Marfil": "Ivory Coast",
    "Croacia": "Croatia",
    "Cuba": "Cuba",
    "Dinamarca": "Denmark",
    "Ecuador": "Ecuador",
    "Egipto": "Egypt",
    "El Salvador": "El Salvador",
    "Eritrea": "Eritrea",
    "Eslovaquia": "Slovakia",
    "Eslovenia": "Slovenia",
    "Espa√±a": "Spain",
    "Estados Unidos de Am√©rica": "United States of America",
    "Estonia": "Estonia",
    "Esuatini": "Eswatini",
    "Etiop√≠a": "Ethiopia",
    "Filipinas": "Philippines",
    "Finlandia": "Finland",
    "Francia": "France",
    "Gab√≥n": "Gabon",
    "Georgia": "Georgia",
    "Ghana": "Ghana",
    "Grecia": "Greece",
    "Groenlandia": "Greenland",
    "Guatemala": "Guatemala",
    "Guinea": "Guinea",
    "Guinea-Bissau": "Guinea-Bissau",
    "Guinea Ecuatorial": "Equatorial Guinea",
    "Hait√≠": "Haiti",
    "Honduras": "Honduras",
    "Hungr√≠a": "Hungary",
    "India": "India",
    "Indonesia": "Indonesia",
    "Irak": "Iraq",
    "Ir√°n (Rep√∫blica Isl√°mica del)": "Iran",
    "Irlanda": "Ireland",
    "Islandia": "Iceland",
    "Israel": "Israel",
    "Italia": "Italy",
    "Jap√≥n": "Japan",
    "Jordania": "Jordan",
    "Kazajst√°n": "Kazakhstan",
    "Kenia": "Kenya",
    "Kirguist√°n": "Kyrgyzstan",
    "L√≠bano": "Lebanon",
    "Liberia": "Liberia",
    "Libia": "Libya",
    "Lesoto": "Lesotho",
    "Letonia": "Latvia",
    "Lituania": "Lithuania",
    "Luxemburgo": "Luxembourg",
    "Madagascar": "Madagascar",
    "Malasia": "Malaysia",
    "Malawi": "Malawi",
    "Maldivas": "Maldives",
    "Mal√≠": "Mali",
    "Malta": "Malta",
    "Marruecos": "Morocco",
    "Mauricio": "Mauritius",
    "Mauritania": "Mauritania",
    "M√©xico": "Mexico",
    "Micronesia (Estados Federados de)": "Federated States of Micronesia",
    "Mongolia": "Mongolia",
    "Montenegro": "Montenegro",
    "Mozambique": "Mozambique",
    "Namibia": "Namibia",
    "Nepal": "Nepal",
    "Nicaragua": "Nicaragua",
    "N√≠ger": "Niger",
    "Nigeria": "Nigeria",
    "Noruega": "Norway",
    "Nueva Zelandia": "New Zealand",
    "Om√°n": "Oman",
    "Pakist√°n": "Pakistan",
    "Panam√°": "Panama",
    "Papua Nueva Guinea": "Papua New Guinea",
    "Paraguay": "Paraguay",
    "Per√∫": "Peru",
    "Polonia": "Poland",
    "Portugal": "Portugal",
    "Qatar": "Qatar",
    "Reino Unido de Gran Breta√±a e Irlanda del Norte": "United Kingdom",
    "Rep√∫blica √Årabe Siria": "Syria",
    "Rep√∫blica Centroafricana": "Central African Republic",
    "Rep√∫blica Checa": "Czech Republic",
    "Rep√∫blica de Corea": "South Korea",
    "Rep√∫blica de Moldova": "Moldova",
    "Rep√∫blica Dominicana": "Dominican Republic",
    'Rep√∫blica Unida de Tanzan√≠a': 'Tanzania',
    "RDP Lao": "Laos",
    "Ruman√≠a": "Romania",
    "Federaci√≥n de Rusia": "Russian Federation",
    "San Crist√≥bal y Nieves": "Saint Kitts and Nevis",
    "Santa Luc√≠a": "Saint Lucia",
    "San Vicente y las Granadinas": "Saint Vincent and the Grenadines",
    "Santo Tom√© y Pr√≠ncipe": "Sao Tome and Principe",
    "Samoa": "Samoa",
    "Senegal": "Senegal",
    "Serbia": "Serbia",
    "Seychelles": "Seychelles",
    "Singapur": "Singapore",
    "Sri Lanka": "Sri Lanka",
    "Sud√°frica": "South Africa",
    "Sud√°n": "Sudan",
    "Sud√°n del Sur": "South Sudan",
    "Suecia": "Sweden",
    "Suiza": "Switzerland",
    "Suriname": "Suriname",
    "Tailandia": "Thailand",
    "Tanzania, Rep√∫blica Unida de": "Tanzania",
    "Tayikist√°n": "Tajikistan",
    "Timor-Leste": "East Timor",
    "Tonga": "Tonga",
    "Trinidad y Tobago": "Trinidad and Tobago",
    "T√∫nez": "Tunisia",
    "Turkmenist√°n": "Turkmenistan",
    "Turqu√≠a": "T√ºrkiye",
    "Ucrania": "Ukraine",
    "Uruguay": "Uruguay",
    "Uzbekist√°n": "Uzbekistan",
    "Venezuela (Rep√∫blica Bolivariana de)": "Venezuela",
    "Viet Nam": "Vietnam",
    "Yemen": "Yemen",
    "Zambia": "Zambia",
    "Zimbabue": "Zimbabwe",
    "Estado de Palestina": "Palestine",
    "Macedonia del Norte": "North Macedonia",
    'Rep√∫blica del Congo': 'Congo',
}

# Aplicar correcciones
fixed_countries = [fixes.get(p, p) for p in countries]

# Obtener c√≥digo ISO-3 para cada pa√≠s
def get_iso3(name):
    '''
    Esta funci√≥n busca cada nombre en la base de datos oficial de pycountry:

    Si encuentra el pa√≠s  devuelve el c√≥digo ISO-3 (ARG para Argentina, BRA para Brasil, etc.).

    Si falla (nombre raro, no existe)  devuelve None
    '''
    try:
        return pycountry.countries.lookup(name).alpha_3
    except:
        return None

iso_codes = [get_iso3(p) for p in fixed_countries] #  obtiene una lista de c√≥digos ISO-3 o None si fall√≥
df_map = pd.DataFrame({'country': countries, 'iso_alpha': iso_codes}) # Crea un nuevo DataFrame con dos columnas:'country' ‚Üí nombre original (sin correcci√≥n), 'iso_alpha' ‚Üí c√≥digo ISO-3 resultante (de la versi√≥n corregida)
df_map = df_map.dropna()  # Elimina las filas donde iso_alpha es None.

# A√±adir una columna "coverage" para indicar cobertura
df_map['coverage'] = 1  # 1 = incluido en el dataset

st.subheader("Cobertura geogr√°fica del dataset FAOSTAT")
fig = px.choropleth(
    df_map,
    locations='iso_alpha',
    color='coverage',
    hover_name='country',
    color_continuous_scale=[[0, 'lightgrey'], [1, 'green']],
    title='Cobertura FAOSTAT'
)
fig.update_geos(bgcolor='lightblue',showcountries=True, showcoastlines=True, showland=True, fitbounds="locations")
fig.update_layout(coloraxis_showscale=False, margin={"r":10,"t":40,"l":10,"b":10})
st.plotly_chart(fig, use_container_width=True)



st.subheader("Registros por pa√≠s por a√±o:")
st.markdown("Expansi√≥n en la cobertura de pa√≠ses a partir de 1990*  \n"
            "A partir del a√±o 1990 se observa un incremento significativo en la cantidad de pa√≠ses con datos disponibles. Este cambio no necesariamente implica un aumento real en las emisiones,"
            " sino una mejora en la cobertura geogr√°fica del dataset.  \n"
            "En total, se incorporan 52 nuevos pa√≠ses/regiones despu√©s de 1990, lo que puede influir en los an√°lisis agregados si no se controla adecuadamente.*  \n"
            "Para evitar conclusiones err√≥neas, este notebook incluye filtros y comparaciones que tienen en cuenta este cambio estructural en la base de datos.*")


#Agrupar por pa√≠s y a√±o
df_anual = df_countries.groupby(['√Årea', 'A√±o']).size().reset_index(name='records')
df_group = df_countries.groupby('√Årea').agg({'Valor_Mt': 'sum'}).reset_index()

#Aplicar equivalencias de nombres
df_anual['country'] = df_anual['√Årea'].replace(fixes)
df_anual['iso_alpha'] = df_anual['country'].apply(get_iso3)
df_anual = df_anual[df_anual['iso_alpha'].notnull()]


#Crear mapa animado
fig = px.choropleth(
    df_anual,
    locations='iso_alpha',
    color='records',
    hover_name='country',
    color_continuous_scale='Viridis',
    animation_frame='A√±o',
    title='Evoluci√≥n anual de registros por pa√≠s'
)

fig.update_geos(showcountries=True, showcoastlines=True, showland=True, fitbounds="locations")
fig.update_layout(margin={"r":0,"t":50,"l":0,"b":0})
st.plotly_chart(fig, use_container_width=True)


# Selector de pa√≠s
st.subheader("Evoluci√≥n temporal por pa√≠s")
pais_sel = st.selectbox("Seleccionar pa√≠s", sorted(df['√Årea'].unique()))
df_pais = df[df['√Årea'] == pais_sel]
df_serie = df_pais.groupby(df_pais['A√±o'].dt.year)['Valor_Mt'].sum().reset_index()
fig_pais = px.line(df_serie, x='A√±o', y='Valor_Mt', title=f"Evoluci√≥n de emisiones en {pais_sel}")
st.plotly_chart(fig_pais, use_container_width=True)

# Top pa√≠ses
st.subheader("Top 10 pa√≠ses con m√°s emisiones")
df_top = df_group.sort_values("Valor_Mt", ascending=False).head(10)
fig_top = px.bar(df_top, x='√Årea', y='Valor_Mt', title="Top 10 pa√≠ses con m√°s emisiones")
st.plotly_chart(fig_top, use_container_width=True)

st.subheader("Consideraciones sobre Productos Reportados")
st.markdown("El n√∫mero de productos reportados cambia significativamente con el tiempo:  \n"
            "- **Antes de 1990**: solo 16 productos reportados.  \n"
            "- **Despu√©s de 1990**: m√°s de 40 productos.  \n"
            "Este cambio refleja una expansi√≥n en el nivel de detalle del inventario de emisiones, tanto en cobertura tem√°tica como en precisi√≥n metodol√≥gica. "
            "Sin embargo, tambi√©n introduce un **sesgo estructural** en los an√°lisis temporales agregados.")

products_before_1990 = set(df_cleaned[df_cleaned['A√±o'] < '1990']['Producto'].unique())
products_after_1990 = set(df_cleaned[df_cleaned['A√±o'] >= '1990']['Producto'].unique())

products = products_before_1990 & products_after_1990
new_products = products_after_1990 - products_before_1990

st.subheader("Comparaci√≥n de productos por per√≠odo")

st.write(f"üì¶ Productos antes de 1990: {len(products_before_1990)}")
st.write(f"üì¶ Productos despu√©s de 1990: {len(products_after_1990)}")
st.write(f"üîÅ Productos comunes: {len(products)}")
st.write(f"üÜï Productos nuevos desde 1990: {len(new_products)}")



st.markdown("### Delimitaci√≥n temporal del an√°lisis  \n"
            "Debido a los cambios estructurales observados en la cobertura geogr√°fica y tem√°tica del dataset, se ha decidido restringir el an√°lisis a los datos disponibles **a partir del a√±o 1990**."
            "Esta decisi√≥n responde a dos razones principales:  \n"
            "- **Mayor cobertura geogr√°fica**: a partir de 1990 se incorporan 52 nuevos pa√≠ses, alcanzando un total de 238. Esto garantiza que los an√°lisis comparativos entre regiones y pa√≠ses no est√©n sesgados por datos ausentes en d√©cadas anteriores.  \n"
            "- **Mayor cobertura tem√°tica**: el n√∫mero de productos reportados aumenta de 16 (antes de 1990) a m√°s de 40 (despu√©s), lo que introduce una mejora en el detalle metodol√≥gico, pero tambi√©n limita la comparabilidad hist√≥rica.  \n"
            "### Justificaci√≥n  \n"
            "Trabajar con el subconjunto de datos posterior a 1990 permite realizar an√°lisis **m√°s consistentes, representativos y comparables** reduciendo el riesgo de conclusiones err√≥neas causadas por diferencias de cobertura y disponibilidad de informaci√≥n."
            "En consecuencia, **todas las visualizaciones y estad√≠sticas agregadas en este informe se basar√°n en datos desde 1990 a 2025, por lo cual no vamos a tener en cuenta estimaciones futuras**."
)

df_completed = df_cleaned.copy()
df_01 = df_cleaned[(df_cleaned['A√±o'] >= '1990') & (df_cleaned['A√±o'] <= '2025')].copy()

st.markdown("## Variables de Emisi√≥n  \n"
            "El conjunto de datos original incluye m√∫ltiples tipos de elementos relacionados con las emisiones de gases, entre ellos: ")

elementos = df_01['Elemento'].unique()
st.markdown("### Tipos de emisiones registradas:")
for elem in elementos:
    st.markdown(f"- {elem}")
st.subheader("")
st.markdown("## Comparaci√≥n de Cobertura por Fuente (FAO vs UNFCCC)")


# Ver pa√≠ses √∫nicos por fuente
fao_data = set(df_01[df_01['Fuente'] == 'FAO TIER 1']['√Årea'].unique())
unfccc_data = set(df_01[df_01['Fuente'] == 'UNFCCC']['√Årea'].unique())

st.subheader("Comparaci√≥n de cobertura por fuente de datos")
st.write(f"üåæ Pa√≠ses y regiones con datos **FAO TIER 1**: {len(fao_data)}")
st.write(f"üåç Pa√≠ses y regiones con datos **UNFCCC**: {len(unfccc_data)}")
st.write(f"‚úÖ Pa√≠ses y regiones en **ambas fuentes**: {len(fao_data & unfccc_data)}")
st.write(f"üü¢ Solo en **FAO TIER 1**: {len(fao_data - unfccc_data)}")
st.write(f"üîµ Solo en **UNFCCC**: {len(unfccc_data - fao_data)}")

st.markdown("""
### üìö Sobre las fuentes de datos

El conjunto de datos incluye emisiones reportadas por dos fuentes distintas: **FAO TIER 1** y **UNFCCC**. Estas fuentes utilizan metodolog√≠as diferentes:

- **FAO TIER 1**: Estimaciones generadas por la FAO usando metodolog√≠as estandarizadas (*IPCC Tier 1*). Ofrece cobertura global y permite analizar series temporales largas de manera consistente, aunque con menor precisi√≥n pa√≠s-espec√≠fica.

- **UNFCCC**: Datos reportados directamente por los pa√≠ses miembros del Convenio Marco de las Naciones Unidas sobre el Cambio Clim√°tico. Son m√°s precisos pero no est√°n disponibles para todos los pa√≠ses ni todos los a√±os.

Para garantizar la **consistencia del an√°lisis exploratorio** y evitar duplicidades (m√∫ltiples registros para un mismo pa√≠s, a√±o y tipo de emisi√≥n), separamos los datos por fuente.  
En este an√°lisis general utilizaremos principalmente los datos provenientes de **FAO TIER 1**, ya que brindan una cobertura m√°s amplia y continua en el tiempo.

üìå En secciones posteriores, se podr√° comparar con los datos de **UNFCCC** para identificar posibles diferencias metodol√≥gicas o validar tendencias observadas.
""")

df_fao = df_01[df_01['Fuente'] == 'FAO TIER 1'].copy()

st.markdown("""
## üßæ Descripci√≥n de los indicadores

### 1. Emisiones directas (N‚ÇÇO)
Emisiones de √≥xido nitroso (**N‚ÇÇO**) que se liberan directamente al aire desde su fuente, por ejemplo:

- Aplicaci√≥n de fertilizantes nitrogenados al suelo.

---

### 2. Emisiones indirectas (N‚ÇÇO)
Emisiones de **N‚ÇÇO** que ocurren despu√©s de procesos intermedios, como:

- Lixiviaci√≥n de nitr√≥geno al agua.  
- Volatilizaci√≥n (evaporaci√≥n y deposici√≥n posterior).

Estas emisiones ocurren fuera del punto de aplicaci√≥n pero son atribuibles a pr√°cticas agr√≠colas.

---

### 3. Emisiones (N‚ÇÇO)
Suma total de **Emisiones directas + Emisiones indirectas** de N‚ÇÇO.  
Representa la emisi√≥n completa de N‚ÇÇO atribuible a la agricultura/ganader√≠a.

---

### 4. Emisiones (CO‚ÇÇeq) proveniente de N‚ÇÇO (AR5)
Las emisiones de N‚ÇÇO convertidas a **CO‚ÇÇ equivalente** usando el factor del 5¬∫ Informe del IPCC (AR5):  

- N‚ÇÇO tiene un GWP (Global Warming Potential) de **265**.  
- Ejemplo: 1 kt de N‚ÇÇO ‚Üí 265 kt de CO‚ÇÇeq.

Esto permite comparar gases con diferente efecto clim√°tico.

---

### 5. Emisiones (CO‚ÇÇeq) (AR5)
Este es el indicador total combinado, ya convertido a **CO‚ÇÇeq (seg√∫n AR5)**.  
Incluye:

- CO‚ÇÇ  
- CH‚ÇÑ convertido a CO‚ÇÇeq  
- N‚ÇÇO convertido a CO‚ÇÇeq  
- F-gases  

Es la m√©trica recomendada para **comparaciones globales** de impacto clim√°tico.

---

### 6. Emisiones (CH‚ÇÑ)
Emisiones directas de metano (**CH‚ÇÑ**), especialmente desde:

- Fermentaci√≥n ent√©rica en ganado.  
- Cultivo de arroz.

üìè Unidad: kilotoneladas de CH‚ÇÑ.

---

### 7. Emisiones (CO‚ÇÇeq) proveniente de CH‚ÇÑ (AR5)
CH‚ÇÑ convertido a **CO‚ÇÇeq** usando GWP del AR5:

- CH‚ÇÑ tiene un GWP de **28**.  
- 1 kt de CH‚ÇÑ ‚Üí 28 kt de CO‚ÇÇeq.

Permite estimar el efecto clim√°tico del metano en t√©rminos comparables.

---

### 8. Emisiones (CO‚ÇÇ)
Emisiones directas de di√≥xido de carbono (**CO‚ÇÇ**).  
Pueden provenir de maquinaria agr√≠cola, quema de residuos, etc.

üìè Unidad: kilotoneladas de CO‚ÇÇ.

---

### 9. Emisiones (CO‚ÇÇeq) proveniente de F-gases (AR5)
Gases fluorados (**HFCs, PFCs, SF‚ÇÜ**) convertidos a CO‚ÇÇeq.  
Aunque no provienen t√≠picamente de agricultura, pueden aparecer si se incluyen procesos industriales vinculados.

üí• Tienen alt√≠simos GWP (hasta miles de veces el del CO‚ÇÇ).
""")


st.markdown("# An√°lisis Exploratorio de Datos (EDA)  \n")
with st.expander("üåç An√°lisis Global y Comparativo por Continente de Emisiones Totales incluyendo LULUCF"):
    st.markdown("""
Para este an√°lisis vamos a tomar en cuenta el indicador **CO‚ÇÇeq (AR5)**, que es la suma estimada de los tres gases principales, ya convertidos por su impacto clim√°tico.

Adem√°s, vamos a utilizar el agregado **"Emisiones Totales incluyendo LULUCF"**. Este agregado es la suma de todas las fuentes de gases de efecto invernadero del sistema agroalimentario (farm gate + cambio de uso del suelo + procesos pre- y pos-producci√≥n) m√°s el resto de sectores **IPCC**.

**¬øQu√© significa LULUCF?**  
Land Use, Land-Use Change and Forestry.

Es el sector que captura o emite **CO‚ÇÇ (u otros gases)** cuando se utiliza la tierra (pasturas, cultivos), se cambia el uso de la tierra (deforestaci√≥n, expansi√≥n urbana) y silvicultura (tala y repoblaci√≥n forestal, incendios forestales).
""")

gas = 'Emisiones (CO2eq) (AR5)'
continents = [
    'Am√©ricas',
    '√Åfrica',
    'Europa',
    'Asia',
    'Ocean√≠a',
    'Mundo'
]
product_code = 6825 # Emisiones Totales incluyendo LULUCF

df_continents = df_fao[
    (df_fao['√Årea'].isin(continents)) &
    (df_fao['Elemento'] == gas) &
    (df_fao['C√≥digo del producto'] == product_code)
    ].copy()

df_emissions_by_continent_year = df_continents.groupby(['√Årea', 'Elemento', 'A√±o'])['Valor_Gt'].sum().reset_index()
df_emissions_by_continent_year.sort_values(by='Valor_Gt', ascending=False, inplace=True)

df_emissions_by_continent = df_continents.groupby(['√Årea'])['Valor_Gt'].sum().reset_index()
df_emissions_by_continent = df_emissions_by_continent.drop(df_emissions_by_continent[df_emissions_by_continent['√Årea'] == 'Mundo'].index)

st.subheader("Primeras filas del DataFrame de emisiones por continente")
st.dataframe(df_emissions_by_continent.head())



# Crear paleta
palette = sns.color_palette('Set2', len(continents))

# Copiar datos para graficar
df_plot = df_emissions_by_continent_year.copy()

# Estilo y figura
sns.set_style("whitegrid")
fig, (ax_line, ax_pie) = plt.subplots(1, 2, figsize=(14, 5),
                                      gridspec_kw={"width_ratios":[2, 1]})

# Gr√°fico de l√≠neas por continente
for idx, cont in enumerate(continents):
    sub = df_plot[df_plot['√Årea'] == cont].sort_values('A√±o')
    ax_line.plot(sub['A√±o'], sub['Valor_Gt'], marker='o', linewidth=1.4,
                 label=cont, color=palette[idx])

ax_line.set_title('CO‚ÇÇ-eq (AR5) ‚Äî serie temporal')
ax_line.set_ylabel('Gt CO‚ÇÇ-eq')
ax_line.set_xlabel('')
ax_line.grid(ls='--', alpha=.4)
ax_line.legend(title='Continente', ncol=3, fontsize=8)

# Gr√°fico de torta
ax_pie.pie(df_emissions_by_continent['Valor_Gt'],
           labels=df_emissions_by_continent['√Årea'],
           autopct='%1.1f%%',
           startangle=90,
           colors=palette)
ax_pie.set_title('Porcentaje de emisiones (CO‚ÇÇeq AR5) por continente')
ax_pie.axis('equal')

# T√≠tulo general
plt.suptitle('Emisiones Totales incluyendo LULUCF ‚Äî CO‚ÇÇ-eq 1990 - 2022',
             fontsize=14, y=1.03)
plt.tight_layout()

# ‚úÖ Mostrar en Streamlit
st.pyplot(fig)


st.markdown("""
### üß† Interpretaci√≥n y conclusiones del gr√°fico

**Interpretaci√≥n:**

En el gr√°fico de la izquierda, podemos observar c√≥mo fueron evolucionando las emisiones totales de **CO‚ÇÇeq (AR5)** en cada continente desde **1990 a 2022**.  
Cada l√≠nea representa las emisiones en gigatoneladas por continente.  
En el gr√°fico de torta, se visualiza el **aporte proporcional de cada continente** a la suma total de emisiones de CO‚ÇÇeq (AR5) en el mismo per√≠odo.

---

**Conclusiones:**

- **üåè Asia**  
  - Aporta el **46%** del total mundial y contin√∫a en crecimiento.  
  - Su curva crece de forma continua, pasando de **10 Gt en 1990 a 30 Gt en 2022**.

- **üåé Am√©rica**  
  - Aporta el **26%** del total mundial.  
  - Presenta un ligero crecimiento hasta 2005 (~12 Gt), luego una meseta, y a partir de 2010, un descenso.

- **üåç Europa**  
  - Muestra una **disminuci√≥n sostenida** desde 1990 hasta la actualidad.

- **üåç √Åfrica**  
  - Representa el **9%** del total de emisiones.  
  - Tiene un crecimiento sostenido de aproximadamente **3 Gt a 5 Gt** (un aumento del 60%).  
  - Sin embargo, la aceleraci√≥n es mucho menor comparada con Asia.

- **üåè Ocean√≠a**  
  - Es el continente con **menos emisiones**.  
  - Su l√≠nea permanece pr√°cticamente **plana** desde 1990 hasta hoy.

---

üìå **Resumen general:**  
**Asia y Am√©rica representan el 72%** del total de emisiones desde 1990 a 2022.  
**Europa** mantiene una tendencia de **reducci√≥n constante** en sus emisiones.
""")


df_covid = df_fao[
    (df_fao['√Årea'].isin(continents)) &
    (df_fao['A√±o'].between('2017', '2022')) &
    (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_fao['Producto'].isin(['Emisiones totales incluyendo LULUCF',
                              'Pre y\xa0post-producci√≥n',
                              'Farm gate',
                              'Cambios de uso de la tierra']))
].copy()

df_pct = (
    df_covid
    .groupby(['√Årea','Producto','A√±o'])['Valor_Mt'].sum()
    .unstack('A√±o')
    .pipe(lambda d: d.pct_change(axis=1)*100)
    [['2019','2020', '2021','2022']]            # columnas de inter√©s
    .reset_index()
)
# T√≠tulo y descripci√≥n
st.subheader("Variaci√≥n porcentual anual de emisiones CO‚ÇÇeq (AR5)")
st.caption("Comparaci√≥n a√±o a a√±o (2019-2022) por continente y tipo de producto.")

# Asegurarse que los nombres de columnas num√©ricas sean strings
df_pct.columns = [str(col.year) if isinstance(col, pd.Timestamp) else str(col) for col in df_pct.columns]

# Detectar columnas num√©ricas por su nombre (a√±os en string)
cols_numericas = [col for col in df_pct.columns if col.isdigit()]

# Estilo zebra + formato num√©rico
styled_df = (
    df_pct.style
    .format({col: "{:.2f}" for col in cols_numericas})
    .set_properties(**{'background-color': '#f9f9f9'}, subset=pd.IndexSlice[::2, :])
)

st.dataframe(styled_df, use_container_width=True)

st.subheader("Distribuci√≥n porcentual anual de emisiones por continente.")

world = df_emissions_by_continent_year[df_emissions_by_continent_year['√Årea'] == 'Mundo']
conts = df_emissions_by_continent_year[df_emissions_by_continent_year['√Årea'] != 'Mundo']
df_share = conts.merge(world, on='A√±o', suffixes=('_cont', '_world'))
df_share['share'] = df_share['Valor_Gt_cont'] / df_share['Valor_Gt_world'] * 100
pivot = (
    df_share.pivot(index='A√±o', columns='√Årea_cont', values='share')
            .loc[:, ['Asia','Am√©ricas','Europa','√Åfrica','Ocean√≠a']]
            .fillna(0)
)

# Saca las horas, minutos y segundo, s√≥lo deja el a√±o
pivot = pivot.rename_axis('A√±o').reset_index()
pivot['A√±o'] = pivot['A√±o'].dt.year
pivot.set_index('A√±o', inplace=True)


# Estilo y paleta
sns.set_style('whitegrid')
palette = sns.color_palette('Set2', len(pivot.columns))

# Crear figura y eje
fig, ax = plt.subplots(figsize=(12, 6))

# Gr√°fico de barras apiladas
pivot.plot(kind='bar', stacked=True, color=palette, width=0.9, ax=ax)

# T√≠tulos y formato
ax.set_title('Distribuci√≥n porcentual de emisiones agroalimentarias por continente (1990-2025)')
ax.set_ylabel('% del total global')
ax.set_xlabel('A√±o')
ax.set_ylim(0, 100)
ax.legend(title='Continente', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)
plt.tight_layout()

# Mostrar en Streamlit
st.pyplot(fig)

# Texto interpretativo
st.markdown("""
### Interpretaci√≥n:
- Cada barra del gr√°fico representa el **100‚ÄØ% del total global de emisiones**. Los colores muestran el porcentaje que ocupa cada continente en ese a√±o.

### Conclusiones:
- **Asia**: pasa de representar un 30‚ÄØ% en 1990 a aproximadamente un 55‚ÄØ% en la actualidad.
- **Am√©rica**: mantiene aproximadamente un 30‚ÄØ% en toda la d√©cada del 90, luego cae al 23‚ÄØ% en 2010 y se estabiliza.
- **Europa**: pasa de 29‚ÄØ% en 1990 a menos del 15‚ÄØ% en 2022. La franja azul confirma la eficacia de sus pol√≠ticas contra la emisi√≥n de gases de efecto invernadero.
- **√Åfrica**: crece muy lentamente, del 8‚ÄØ% al 9‚ÄØ%.
- **Ocean√≠a**: en 32 a√±os (1990 - 2022) nunca super√≥ el 2‚ÄØ%.

Como se puede observar en el gr√°fico, **el eje de las emisiones se desplaz√≥ del Atl√°ntico (Europa - Am√©rica) al √çndico - Pac√≠fico**.  
**Asia es hoy el principal emisor absoluto y relativo. Adem√°s, es el motor del crecimiento de las emisiones a nivel global.**
""")

df_dec = df_emissions_by_continent_year.copy()

# Convertir 'A√±o' a datetime si no lo est√°
if not pd.api.types.is_datetime64_any_dtype(df_dec['A√±o']):
    df_dec['A√±o'] = pd.to_datetime(df_dec['A√±o'], errors='coerce')

# Extraer d√©cada como n√∫mero
df_dec['D√©cada'] = df_dec['A√±o'].dt.year // 10 * 10

# Excluir 'Mundo'
df_dec = df_dec[df_dec['√Årea'] != 'Mundo']

# Agrupar
pivot_dec = (
    df_dec.groupby(['D√©cada','√Årea'])['Valor_Gt']
          .mean()
          .reset_index()
)

# Estilo
sns.set_style('whitegrid')
fig, ax = plt.subplots(figsize=(10, 5))

sns.barplot(data=pivot_dec,
            x='D√©cada', y='Valor_Gt', hue='√Årea', palette='Set2', ax=ax)

ax.set_title('Promedio anual de CO‚ÇÇ-eq por d√©cada y continente')
ax.set_ylabel('Gt CO‚ÇÇ-eq')
ax.set_xlabel('D√©cada')
ax.legend(title='Continente', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=8)

plt.tight_layout()
st.pyplot(fig)
st.markdown("""Interpretaci√≥n:
- D√©cada del 90: el mapa de las emisiones est√° muy distribuido, no se observa una dominancia marcada por alg√∫n continente.
- D√©cada del 2000: Asia despega, aumenta el promedio anual en un 45% respecto a la d√©cada anterior (del 12 Gt a 18 Gt). Adem√°s, Am√©rica aumenta un 10% y Europa tiene una ca√≠da del 15%. Comienza el cambio a nivel mundial del mapa de emisiones, las mismas se trasladan hac√≠a el pac√≠fico.
- Decada del 2010: Asia acelera nuevamente aumentando otro 45% (de 18gt a 26gt) el promedio anual en la d√©cada. En esta d√©cada Asia tiene un promedio mayor al doble que Am√©rica. Europa contin√∫a con su descenso y √Åfrica aumenta su promedio en un 25% respecto a la d√©cada anterior.
- D√©cada del 2020: el promedio anual de Asia se ubica cerca de las 30Gt, triplicando a Am√©rica. Europa se estabiliza y Ocean√≠a mantiene su promedio anual < 1 Gt, al igual que en d√©cadas anteriores.""")

st.subheader("Comparativa de Emisiones por Continente y por componente (1990 - 2010 - 2022)")
st.markdown("""Para este an√°lisis se seleccionaron los siguientes componentes:

- Farm Gate: fermentaci√≥n ent√©rica, gesti√≥n de esti√©rcol, fertilizantes sint√©ticos, uso de energ√≠a en la finca, etc.
Es decir, es todo lo que ocurre dentro del establecimiento agropecuario.
- Cambios en el uso de la tierra: deforestaci√≥n, conversi√≥n neta de bosques, drenaje de suelos org√°nicos, incendios, etc.
- Pre y post-producci√≥n: procesado, envasado, transporte, venta y desperdicio de alimentos. Todo lo que sucede antes y despu√©s de la puerta de la finca

Estos componentes agrupados representan las Emisiones Totales incluyendo LULUCF. Al analizarlos por separado, podemos definir con precisi√≥n qu√©‚ÄØporci√≥n de las emisiones proviene de la finca, de la conversi√≥n de ecosistemas o de la cadena de suministro, lo cual es informaci√≥n importante para definir politicas eficaces en cada regi√≥n.
""")



# ---------- CONVERSI√ìN DE DATOS ----------
df_fao['A√±o'] = pd.to_datetime(df_fao['A√±o'], errors='coerce').dt.year
df_fao['Elemento'] = df_fao['Elemento'].astype(str)

# ---------- PAR√ÅMETROS ----------
regions = ['Am√©ricas', 'Asia', 'Europa', 'Ocean√≠a', '√Åfrica']
products = ["Farm gate", "Cambios de uso de la tierra", "Pre y\xa0post-producci√≥n"]
gas = "CO2eq"
years = [1990, 2010, 2022]

# ---------- FILTRADO ----------
df_products_continents = df_fao[
    df_fao['Producto'].isin(products) &
    df_fao['√Årea'].isin(regions) &
    df_fao['A√±o'].isin(years) &
    df_fao['Elemento'].str.contains(gas, case=False, na=False)
].copy()

# ---------- PIVOTEO ----------
pivot = (
    df_products_continents
    .pivot_table(index=['A√±o', '√Årea'],
                 columns='Producto',
                 values='Valor_Gt',
                 aggfunc='sum')
    .sort_index(level=1)
    .reset_index()
    .sort_values(['√Årea', 'A√±o'], ascending=[True, False])
    .reset_index(drop=True)
)

if pivot.empty:
    st.warning("No hay datos disponibles con los filtros actuales.")
else:
    colors = ['#0066CC', '#0eca1c', '#ff5733']
    bar_h = 0.8
    gap = 1
    offset = bar_h
    n_y = len(years)
    y_pos = []
    for g in range(len(regions)):
        base = offset + g*(n_y*bar_h + gap)
        y_pos.extend(base + np.arange(n_y)*bar_h)

    fig, ax = plt.subplots(figsize=(10, 7))
    left = np.zeros(len(y_pos))

    for (col, color) in zip(products, colors):
        if col in pivot.columns:
            ax.barh(y_pos, pivot[col], left=left,
                    height=bar_h, color=color, edgecolor='white', label=col)
            left += pivot[col].fillna(0).values
        else:
            st.warning(f"'{col}' no est√° presente en los datos filtrados.")

    ax.set_yticks(y_pos)
    ax.set_yticklabels(pivot['A√±o'])
    ax.set_axisbelow(True)
    ax.grid(axis='y')

    ax2 = ax.twinx()
    mid_pos = [offset*0.1 + g*(n_y*bar_h + gap) + (n_y*bar_h) - bar_h
               for g in range(len(regions))]
    ax2.set_yticks(mid_pos)
    ax2.set_yticklabels(regions, fontsize=15, weight='bold')

    ax2.yaxis.set_ticks_position('left')
    ax2.spines['left'].set_position(('outward', 70))
    ax2.tick_params(axis='y', length=0)
    ax.spines['left'].set_visible(False)
    ax2.spines['right'].set_visible(False)
    ax2.grid(False)

    ax.set_xlabel('Gt CO‚ÇÇ-eq (AR5)')
    ax.set_title('Total Emisiones incluyendo LULUCF CO‚ÇÇ-eq por componente 1990 ¬∑ 2010 ¬∑ 2022')
    ax.legend(title='Producto',
              loc='upper right',
              frameon=True,
              framealpha=.9,
              borderpad=.6, fontsize=9)
    plt.tight_layout()
    st.pyplot(fig)

st.markdown("""
---

### üßæ Interpretaci√≥n del gr√°fico

El gr√°fico muestra barras horizontales apiladas que cuantifican las emisiones agro-alimentarias de CO‚ÇÇ-equivalente (Gt CO‚ÇÇ-eq) para cada continente en tres cortes temporales: **1990**, **2010** y **2022**.

#### üîç Interpretaci√≥n por continente:

- **Asia**:
  - En 1990, las emisiones a causa de *Farm gate* son la porci√≥n m√°s grande.
  - Para 2022, el bloque rojo (*pre-/post-producci√≥n*) crece con rapidez (aumenta √ó‚ÄØ7 en 32‚ÄØa√±os), reflejando la industrializaci√≥n de la cadena alimentaria asi√°tica y el aumento del consumo urbano.
  - Las emisiones por *cambios en el uso de la tierra* se reducen moderadamente tras 2010 gracias al freno parcial de la deforestaci√≥n en el Sudeste Asi√°tico.

- **Am√©ricas**:
  - En 1990 se observa una dominancia de las emisiones por *cambios en el uso de la tierra*.
  - Para el a√±o 2022, el bloque verde disminuye notablemente, mientras las emisiones por *pre y post-producci√≥n* se multiplican. Esto significa que hubo una transici√≥n de deforestaci√≥n a cadena de suministro.
  - Al mismo tiempo, azul se mantiene estable y rojo se multiplica. Significa que la presi√≥n clim√°tica migra de la frontera agropecuaria hacia la log√≠stica y el consumo.

- **Europa**:
  - Desde 1990 a la actualidad, las emisiones por *cambios en el uso de la tierra* fueron marginales.
  - Se observa una disminuci√≥n de las emisiones por *farm gate* desde 1990 a 2010 y luego se mantienen estables hasta 2022.
  - El bloque rojo demuestra que la mayor parte del problema europeo reside hoy en las emisiones por *pre y post-producci√≥n*.

- **√Åfrica**:
  - Las emisiones por *farm gate* ganan peso d√©cada tras d√©cada.
  - En 1990, las emisiones por *cambios en el uso de la tierra* dominan con amplia ventaja.
  - En 2010, las emisiones por *farm gate* recortan distancia.
  - En 2022, el componente ligado a deforestaci√≥n e incendios sigue siendo la principal fuente de emisiones. Adem√°s, la franja roja (*pre y post-producci√≥n*) muestra que la cadena de valor ‚Äîprocesado, transporte, venta‚Äî est√° comenzando a pesar y puede acelerarse.

- **Ocean√≠a**: emisiones muy bajas y estables.

---

### üß† Conclusi√≥n

El problema clim√°tico del sistema agro‚Äëalimentario mundial se ha desplazado del **‚Äúd√≥nde sembramos‚Äù** (*deforestaci√≥n*) al **‚Äúc√≥mo producimos y consumimos‚Äù** (*industria y consumo*).

Las estrategias para reducir las emisiones de gases deben, por tanto, abarcar la **cadena completa**, con prioridades distintas seg√∫n la fase en que se encuentre cada regi√≥n.
""")

st.subheader("Top 10 Paises con mayores Emisiones (CO2eq) (AR5) (2022)")
st.markdown("""Para este an√°lisis se seleccion√≥ el elemento Emisiones (CO2eq) (AR5), ya que:
- Es una m√©trica que convierte todas las emisiones de gases de efecto invernadero (GEI) ‚Äîcomo di√≥xido de carbono (CO‚ÇÇ), metano (CH‚ÇÑ) y √≥xido nitroso (N‚ÇÇO)‚Äî en toneladas equivalentes de CO‚ÇÇ.
- Permite realizar an√°lisis agregados, consistentes y comparables entre pa√≠ses

""")
gas = 'Emisiones (CO2eq) (AR5)'
product_code = 6825 # Emisiones Totales incluyendo LULUCF

df_countries_2022 = df_fao[
    (~df_fao['√Årea'].isin(regiones)) &
    (df_fao['C√≥digo del producto'] == product_code) &
    (df_fao['Elemento'] == gas) &
    (df_fao['A√±o'] == 2022)
    ]

df_top_countries_emission = df_countries_2022.groupby(['√Årea'])['Valor'].sum().reset_index()
df_top_countries_emission.sort_values(by= 'Valor',ascending=False, inplace=True)
df_top_countries_emission = df_top_countries_emission.head(10)
df_top_countries_emission

total_global = df_fao[
    (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_fao['√Årea'] == 'Mundo') &
     (df_fao['A√±o'] == 2022) &
    (df_fao['C√≥digo del producto'] == product_code)
    ]['Valor'].sum()
total_top_10 = df_top_countries_emission['Valor'].sum()

pct_top_10 = (total_top_10 / total_global) * 100
pct_rest = 100 - pct_top_10

st.markdown(f"## **Top 10 pa√≠ses** representan el **{pct_top_10:.1f}%** del total global.")
st.markdown(f"## **Resto del mundo** representa el **{pct_rest:.1f}%**.")

# Espaciado visual
st.write("")  # una l√≠nea en blanco
st.write("")  # otra si se quiere m√°s espacio

fix = {
    "Estados Unidos de Am√©rica": "EEUU",
    "Ir√°n (Rep√∫blica Isl√°mica del)": 'Ir√°n',
    "Federaci√≥n de Rusia": "Rusia"
}
df_top_countries_emission['√Årea'] = df_top_countries_emission['√Årea'].replace(fix)

# Crear figura y subplots
fig, axs = plt.subplots(1, 2, figsize=(14, 6),gridspec_kw={'width_ratios': [1.2, 1]})

# --- Subplot 1: Gr√°fico de barras ---
sns.barplot(data=df_top_countries_emission,x='√Årea', y='Valor', hue='√Årea',
            palette='Greens_r', ax=axs[0], legend=False)
axs[0].set_title(' Total Emisiones (CO2eq) (AR5)', fontsize=13)
axs[0].set_xlabel('Pa√≠s')
axs[0].set_ylabel('Emisiones Totales (kilotones)')
axs[0].tick_params(axis='x', rotation=45)

# --- Subplot 2: Gr√°fico de torta ---
labels = [f'Top 10 pa√≠ses ({pct_top_10:.1f}%)', f'Resto del mundo ({pct_rest:.1f}%)']
values = [pct_top_10, pct_rest]

axs[1].pie(
    x=values,
    labels=labels,
    colors=sns.color_palette('Greens_r', len(labels)),
    startangle=140,
    autopct=lambda p: f'{p:.1f}%'
)
axs[1].set_title('Participaci√≥n del Top 10 pa√≠ses emisores sobre el total global', fontsize=13)

fig.suptitle('Top 10 Paises Emisiones (CO2eq) (AR5) (2022)', fontsize=16, y=1.05)
st.pyplot(fig)
st.markdown("""Interpretaci√≥n:

- China	Con aproximadamente 14‚ÄØmillones de kt lidera con enorme ventaja (‚ÄØ2,5‚ÄØ√ó EEUU).
- EE.‚ÄØUU: es el segundo pa√≠s con mas emisiones en el mundo pero, aun as√≠ emite menos de la mitad que China.
- India: se consolida en el tercer lugar, reflejando crecimiento poblacional.
- Rusia, Indonesia, Brasil, Jap√≥n, Ir√°n: tienen valores intermedios (0,6‚ÄØ‚Äì‚ÄØ2‚ÄØmillones‚ÄØkt). Mezcla de grandes potencias agr√≠colas (Brasil, Indonesia) y econom√≠as industriales/energ√©ticas (Rusia, Ir√°n, Jap√≥n).
- Arabia‚ÄØSaudita y M√©xico	ocupan el puesto 9 y 10 el ranking. Sus emisiones son <10‚ÄØ% de las chinas.

Se puede observar una desigualdad extrema: el primer pa√≠s (China) emite casi 75 veces m√°s que el d√©cimo.

Adem√°s, en el gr√°fico de la derecha podemos observar que, en la actualidad, dos tercios de todas las emisiones agro‚Äëalimentarias se concentran en solo diez pa√≠ses (63%). Por lo tanto, el resto de los paises (180 aprox) aportan el otro tercio.
El gr√°fico demuestra que las politicas de mitigaci√≥n global deben hacer foco en unas pocas jurisdicciones. Sin acciones contundentes en esos pa√≠ses, el resto del mundo dif√≠cilmente compensar√° el volumen de emisiones que ah√≠ se genera.""")


st.subheader("Am√©rica (Actualidad)")
anio = 2022
countries = ['Estados Unidos de Am√©rica', 'Brasil', 'Argentina', 'M√©xico', 'Colombia', 'Canad√°', 'Per√∫']
product_code = 6825 # Emisiones totales incluyendo LULUCF
gas = 'Emisiones (CO2eq) (AR5)'

df_most_population_america = df_fao[
    (df_fao['√Årea'].isin(countries)) &
    (df_fao['A√±o'] == anio) &
    (df_fao['Elemento'] == gas) &
    (df_fao['C√≥digo del producto'] == product_code)]

df_top_countries_emission = df_most_population_america.groupby(['√Årea'])['Valor_Mt'].sum().reset_index()
df_top_countries_emission.sort_values(by= 'Valor_Mt',ascending=False, inplace=True)

total_america = df_fao[
    (df_fao['√Årea'] == 'Am√©ricas') &
    (df_fao['A√±o'] == anio) &
     (df_fao['Elemento'] == gas) &
    (df_fao['C√≥digo del producto'] == product_code)
    ]['Valor_Mt'].sum()

rest_of_america = total_america - df_top_countries_emission['Valor_Mt'].sum()
st.write("")
st.write("")
st.markdown(f"### **Resto de Am√©rica** representa  **{rest_of_america:.1f}%**.")
st.write("")
st.write("")


df_plot = (pd.concat(
    [df_top_countries_emission ,
     pd.DataFrame({'√Årea': ['Resto de Am√©rica'], 'Valor_Mt': [rest_of_america]})
     ], ignore_index=True)
)

df_plot['Share'] = (df_plot['Valor_Mt'] / df_plot['Valor_Mt'].sum()) * 100
df_plot.sort_values('Valor_Mt', ascending=False, inplace=True)

sns.set_style('whitegrid')
plt.figure(figsize=(12,6))
sns.barplot(data=df_plot, y='√Årea', x='Share', hue='√Årea',
            palette='Greens_r', edgecolor='black')

for i, row in df_plot.iterrows():
    plt.text(row['Share']+5, i,
             f"{row['Valor_Mt']:,.0f} Mt", va='center')

plt.title(f'Emisiones Totales incluyendo LULUCF CO‚ÇÇ-eq en Am√©rica ({anio})')
plt.xlabel('% del total continental'); plt.ylabel('')
plt.xlim(0, 100)
plt.tight_layout(); st.pyplot(plt)

st.write("")
st.write("")
st.markdown("""### An√°lisis por Tipo de Gas y Continente""")

gases = ['Emisiones (CO2)', 'Emisiones (N2O)', 'Emisiones (CH4)']

df_continents_gas = df_fao[
    (df_fao['√Årea'].isin(continents)) &
    (df_fao['Elemento'].isin(gases)) &
    (df_fao['Producto'] == 'Emisiones totales incluyendo LULUCF')
    ].copy()

df_continents_gas_by_year = df_continents_gas.groupby(['√Årea', 'Elemento', 'A√±o'])['Valor_Mt'].sum().reset_index()
df_continents_gas_by_year = df_continents_gas_by_year[df_continents_gas_by_year['√Årea'] != 'Mundo']
df_continents_gas_by_year.sort_values(by='Valor_Mt', ascending=False, inplace=True)

fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=False)
axs = axs.ravel()

palette = sns.color_palette('Set2', len(continents) - 1)

# Dibujar cada gas en un eje
for i, gas in enumerate(gases):
    ax = axs[i]
    sns.lineplot(data=df_continents_gas_by_year[df_continents_gas_by_year['Elemento'] == gas],
                 x='A√±o', y='Valor_Mt', hue='√Årea',
                 marker='o', palette=palette, ax=ax)

    ax.set_title(gas, fontsize=11)
    ax.set_xlabel('')
    ax.set_ylabel('Mt CO‚ÇÇ-eq')
    ax.grid(ls='--', alpha=.4)
    if i == 0:
        ax.set_ylabel('Mt CO‚ÇÇ-eq')
    else:
        ax.set_ylabel('')
fig.suptitle('Evoluci√≥n anual de emisiones por continente (1990-2022)',
             fontsize=15, weight='bold', y=0.96)
plt.tight_layout(rect=[0, 0, 1, 0.95])
st.pyplot(plt)

st.write("")
st.write("")

st.markdown("""Asia: es el motor del alza mundial de los tres gases. La pendiente apenas se modera a partir de 2015. Las emisiones de CO2 crecen de de 6 mil Mt a casi 23 mil Mt.

Am√©rica: las emisiones de CO2 crecen hasta 2005 y luego hay una meseta-descenso a 8000 mt. Las emisiones de NO2 tienen un crecimiento suave de 2 mil Mt a casi 3mil Mt. Mientras que las emisiones de CH4, se mantienen estables.

Europa: es el √∫nico continente donde se observa una ca√≠da en las emisiones de los tres gases.

√Åfrica: el salto porcentual es grande (sobretodo en CH4 y N2O), pero la magnitud absoluta sigue muy por debajo de Asia o Am√©rica. Las emisiones de CO2 crecen muy lentamente.

Ocean√≠a: impacto global muy bajo. Las variaciones anuales est√°n relacionadas a incendios o sequ√≠as.


Conclusiones generales:
- N2O es el gas con la pendiente proporcional m√°s alta en √Åfrica y Asia: es la l√≠nea que mas r√°pido crece en ambos continentes.
- CH4 presenta tendencia ascendente suave excepto en Europa que hay un descenso.
-CO‚ÇÇ es, con mucha diferencia, el gas dominante en todas las regiones.""")

st.markdown("""### An√°lisis de Productos Desagregados y su relaci√≥n con los diferentes tipos de Gas
Para este an√°lisis vamos a tener en cuenta los productos desagregados""")

gases = ['Emisiones (CO2)', 'Emisiones (N2O)', 'Emisiones (CH4)']
anio = 2022
codes_agg = [6518, 6516, 6517, 6996, 6995, 5084, 5085,
             6825, 6829, 6824, 67292, 67291, 69921, 6821, 6817, 6820, 1707, 1711]

df_non_agg_products = df_fao[
    (~df_fao['C√≥digo del producto'].isin(codes_agg)) &
    (df_fao['A√±o'] == anio) &
    (df_fao['Elemento'].isin(gases))
    ]

df_products_top_emissions = df_non_agg_products.groupby(['Producto', 'Elemento'])['Valor_Mt'].sum().reset_index()

top_n = 10
lista_top = []
for g in gases:
    top_g = (df_non_agg_products[df_non_agg_products['Elemento'] == g]
                .groupby('Producto')['Valor_Mt']
                .sum()
                .sort_values(ascending=False)
                .head(top_n)
                .reset_index())
    top_g['Gas'] = g
    lista_top.append(top_g)

df_top_gases = pd.concat(lista_top, ignore_index=True)

df_top_gases = (df_top_gases.set_index(['Gas','Producto'])
                              .sort_index(level='Gas'))

df_top_gases = df_top_gases.rename(
    index={'Eliminaci√≥n de desechos de sistemas agroalimentarios':
           'Eliminaci√≥n de desechos de S. Agro.'},
    level='Producto'
)

sns.set_style('whitegrid')
base_palette = sns.color_palette('Greens_r', top_n)
fig, axes = plt.subplots(3, 1, figsize=(10,10), sharex=False)

for ax, g in zip(axes, gases):
    sub = df_top_gases.loc[g].sort_values('Valor_Mt')
    colors = base_palette
    sub.plot.barh(ax=ax, color=colors, edgecolor='black')
    ax.set_title(f'{g.split()[1]}')
    ax.set_xlabel('Mt'); ax.set_ylabel('')
    ax.grid(axis='x', ls='--', alpha=.4)
    ax.get_legend().remove()

fig.suptitle('Top 10 Productos m√°s emisores por gas ‚Äì A√±o 2022', y=1.02, fontsize=13)
plt.tight_layout()
st.pyplot(plt)

years = [1990, 2022]
df_crec_prod = df_fao[
    (df_fao['A√±o'].isin(years)) &
    (df_fao['√Årea'] == 'Mundo') &
    (~df_fao['C√≥digo del producto'].isin(codes_agg)) &
    (df_fao['Elemento'] == 'Emisiones (CO2eq) (AR5)')
    ].copy()

totals_by_year = df_crec_prod.groupby(['A√±o', 'Producto'])['Valor_Mt'].sum().unstack('A√±o').reset_index()

st.markdown("### Evoluci√≥n de emisiones por producto (1990 vs 2022)")

totals_by_year["Crecimiento absoluto"] = totals_by_year[2022] - totals_by_year[1990]
totals_by_year = totals_by_year.sort_values("Crecimiento absoluto", ascending=False)
st.dataframe(totals_by_year, use_container_width=True)

st.markdown("# **Modelo Predictivo**")
st.markdown("## Utilizando ARIMA:")
st.markdown("## Paso 1: Vemos si las series son estacionales o no y si son estacionarias o no")

serie_america = df_cleaned[
    (df_cleaned['√Årea'] == 'Am√©ricas') &
    (df_cleaned['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_cleaned['C√≥digo del producto'] == 6825)
    ]
serie_asia = df_cleaned[
    (df_cleaned['√Årea'] == 'Asia') &
    (df_cleaned['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_cleaned['C√≥digo del producto'] == 6825)
    ]

serie_europa = df_cleaned[
    (df_cleaned['√Årea'] == 'Europa') &
    (df_cleaned['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_cleaned['C√≥digo del producto'] == 6825)
    ]
serie_oceania = df_cleaned[
    (df_cleaned['√Årea'] == 'Oceania') &
    (df_cleaned['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_cleaned['C√≥digo del producto'] == 6825)
    ]

serie_africa = df_cleaned[
    (df_cleaned['√Årea'] == '√Åfrica') &
    (df_cleaned['Elemento'] == 'Emisiones (CO2eq) (AR5)') &
    (df_cleaned['C√≥digo del producto'] == 6825)
    ]

st.markdown("### üìä Curva de emisiones en kilotoneladas a lo largo de los a√±os para los distintos continentes. "
            "Evoluci√≥n de las emisiones agroalimentarias en cada continente a lo largo del tiempo")

st.markdown("""
---
### Cada gr√°fico representa la evoluci√≥n de las **emisiones agroalimentarias totales** (en kilotoneladas de CO‚ÇÇ-eq, metodolog√≠a AR5) desde el a√±o 1990 hasta 2022 en cada continente. A continuaci√≥n se presentan algunas observaciones generales:

- **Am√©rica**:
  - Muestra una tendencia creciente con ciertas oscilaciones.
  - Se destacan picos asociados a deforestaci√≥n y uso intensivo de fertilizantes en d√©cadas recientes.

- **Asia**:
  - Presenta un **crecimiento sostenido y fuerte**.
  - La industrializaci√≥n y el aumento del consumo urbano explican buena parte del incremento.

- **Europa**:
  - Se observa una **tendencia a la estabilizaci√≥n o incluso leve reducci√≥n**.
  - Las pol√≠ticas ambientales y agr√≠colas parecen estar moderando las emisiones.

- **Ocean√≠a**:
  - Tiene niveles **bajos y relativamente estables**.
  - La menor poblaci√≥n y menor superficie cultivable influyen en estos valores.

- **√Åfrica**:
  - Las emisiones han crecido de forma progresiva.
  - El aumento se debe al avance de la frontera agropecuaria y la presi√≥n sobre ecosistemas.

---

### üß† Conclusi√≥n general

Estos gr√°ficos permiten **visualizar patrones hist√≥ricos** que sirven como base para aplicar modelos predictivos (por ejemplo, regresiones o modelos ARIMA) y anticipar el impacto futuro de las pol√≠ticas agr√≠colas y alimentarias en cada regi√≥n.
""")


fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()  # Aplanar para acceder con √≠ndice simple

sns.lineplot(data=serie_america, x='A√±o', y='Valor', ax=axes[0])
axes[0].set_title('Am√©rica')

sns.lineplot(data=serie_asia, x='A√±o', y='Valor', ax=axes[1])
axes[1].set_title('Asia')

sns.lineplot(data=serie_europa, x='A√±o', y='Valor', ax=axes[2])
axes[2].set_title('Europa')

sns.lineplot(data=serie_oceania, x='A√±o', y='Valor', ax=axes[3])
axes[3].set_title('Ocean√≠a')

sns.lineplot(data=serie_africa, x='A√±o', y='Valor', ax=axes[4])
axes[4].set_title('√Åfrica')

# Eliminar el sexto subplot (vac√≠o)
fig.delaxes(axes[5])

plt.tight_layout()
st.pyplot(plt)

st.markdown("""
---

### üîÑ Componente estacional de las emisiones por continente

Estos gr√°ficos muestran la **variaci√≥n estacional** de las emisiones agroalimentarias en cada continente, obtenida mediante un modelo de descomposici√≥n STL (Seasonal-Trend decomposition using Loess). A diferencia del gr√°fico anterior que muestra la tendencia global, este a√≠sla **los patrones c√≠clicos o repetitivos** presentes en las emisiones a lo largo del tiempo.

#### üß© ¬øQu√© representa la curva en cada gr√°fico?
- El eje X representa los a√±os.
- El eje Y representa la **fluctuaci√≥n estacional** de las emisiones (desvinculada de la tendencia general).
- Valores positivos o negativos indican cu√°nto se desv√≠a la serie por efecto estacional en distintos momentos.

#### üîç Observaciones clave:

- **Am√©rica y Asia** muestran oscilaciones c√≠clicas claras, lo que sugiere que hay factores repetitivos (como campa√±as agr√≠colas o pol√≠ticas energ√©ticas) que influyen peri√≥dicamente.
- **Europa** presenta una componente estacional m√°s tenue, reflejo de pol√≠ticas m√°s estables y menor variabilidad estructural.
- **√Åfrica y Ocean√≠a** tienen variaciones m√°s irregulares o menos pronunciadas, posiblemente asociadas a factores clim√°ticos o econ√≥micos puntuales.

---

### üìå Conclusi√≥n

El an√°lisis estacional es fundamental para detectar **patrones ocultos** que se repiten en el tiempo. Estos insights permiten afinar los modelos predictivos, entender la influencia del calendario agr√≠cola, y anticipar picos o ca√≠das sistem√°ticas en las emisiones.
""")


fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

# Lista de series y t√≠tulos
series = [
    ('Am√©rica', serie_america['Valor']),
    ('Asia', serie_asia['Valor']),
    ('Europa', serie_europa['Valor']),
    ('Ocean√≠a', serie_oceania['Valor']),
    ('√Åfrica', serie_africa['Valor'])
]

# Graficar componente 'seasonal' de cada STL
for i, (titulo, serie) in enumerate(series):
    stl = STL(serie, period=5).fit()
    axes[i].plot(serie.index, stl.seasonal)
    axes[i].set_title(f'Tendencia - {titulo}')
    axes[i].set_xlabel('A√±o')
    axes[i].set_ylabel('Valor')

# Eliminar el subplot vac√≠o (el sexto)
fig.delaxes(axes[5])

plt.tight_layout()
st.pyplot(plt)

st.markdown("### üìä Proporci√≥n de varianza explicada por la estacionalidad")

# Lista de pares (nombre, serie)
series = [
    ('Am√©rica', serie_america['Valor']),
    ('Asia', serie_asia['Valor']),
    ('Europa', serie_europa['Valor']),
    ('Ocean√≠a', serie_oceania['Valor']),
    ('√Åfrica', serie_africa['Valor'])
]

# Calcular proporci√≥n varianza estacional / total
resultados = []
for nombre, serie in series:
    stl = STL(serie, period=5).fit()
    proporci√≥n = stl.seasonal.var() / serie.var()
    resultados.append((nombre, round(proporci√≥n, 3)))

# Mostrar en tabla
df_var = pd.DataFrame(resultados, columns=["Regi√≥n", "Var(seasonal) / Var(total)"])
st.dataframe(df_var, use_container_width=True)

st.markdown("""La varianza explicada por la componente estacional en todas las regiones se encuentra entre el **0.1% y el 2.8%** de la varianza total. Esto indica que **no existe un patr√≥n estacional fuerte** en ninguna de las series.

En particular:

- Asia, √Åfrica y Am√©rica muestran una **estacionalidad muy d√©bil** (‚â§ 1.5%).
- Europa, aunque algo mayor, tambi√©n se mantiene por debajo del 3%.
- En Ocean√≠a no se pudo calcular por falta de variabilidad o datos incompletos.

### üß† Conclusi√≥n:
Dado que la **contribuci√≥n estacional es insignificante**, tratamos las series como **no estacionales**, y podemos modelarlas directamente con un modelo **ARIMA convencional** (o un SARIMA con `s = 1`, que equivale a lo mismo). Solo es necesario diferenciar la serie para eliminar la tendencia.
""")

st.markdown("""### Pruebas de estacionaridad""")

st.markdown("### üìâ Test de Estacionariedad ADF por continente")

series_continentales = {
    'Am√©rica': serie_america['Valor'],
    'Asia': serie_asia['Valor'],
    'Europa': serie_europa['Valor'],
    'Ocean√≠a': serie_oceania['Valor'],
    '√Åfrica': serie_africa['Valor'],
}

# Para tabla resumen
resumen_adf = []

# Evaluar ADF
for nombre, serie in series_continentales.items():
    st.markdown(f"#### üåç {nombre}")
    serie_sin_na = serie.dropna()

    if len(serie_sin_na) < 3:
        st.warning("Serie vac√≠a o con muy pocos datos, se omite.")
        resumen_adf.append({
            "Regi√≥n": nombre,
            "ADF Statistic": "N/A",
            "p-value": "N/A",
            "Estacionaria": "No evaluada"
        })
        continue

    try:
        result = adfuller(serie_sin_na)
        adf_stat = result[0]
        p_value = result[1]
        critical_values = result[4]

        st.markdown(f"- **ADF Statistic**: `{adf_stat:.4f}`")
        st.markdown(f"- **p-value**: `{p_value:.4f}`")
        st.markdown("- **Valores cr√≠ticos:**")
        for key, value in critical_values.items():
            st.markdown(f"  - {key}: `{value:.4f}`")

        if p_value < 0.05:
            st.success("‚úÖ La serie **es estacionaria** (se rechaza H0)")
            conclusion = "‚úÖ S√≠"
        else:
            st.error("üö´ La serie **NO es estacionaria** (no se rechaza H0)")
            conclusion = "üö´ No"

        resumen_adf.append({
            "Regi√≥n": nombre,
            "ADF Statistic": round(adf_stat, 4),
            "p-value": round(p_value, 4),
            "Estacionaria": conclusion
        })

    except Exception as e:
        st.error(f"‚ö†Ô∏è Error al procesar la serie: {e}")
        resumen_adf.append({
            "Regi√≥n": nombre,
            "ADF Statistic": "Error",
            "p-value": "Error",
            "Estacionaria": "Error"
        })

# Mostrar tabla resumen
st.markdown("### üìã Resumen del test ADF")
df_resumen_adf = pd.DataFrame(resumen_adf)
st.dataframe(df_resumen_adf, use_container_width=True)

st.write("")
st.write("")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Supongamos que estas series ya est√°n definidas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Asegurate de definirlas antes de correr esta app
series_continentales = {
    'Am√©rica': serie_america['Valor'],
    'Asia': serie_asia['Valor'],
    'Europa': serie_europa['Valor'],
    'Ocean√≠a': serie_oceania['Valor'],
    '√Åfrica': serie_africa['Valor'],
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Interfaz ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.title("Test KPSS de Estacionaridad")
st.write("An√°lisis de estacionaridad con regresi√≥n lineal y t√©rmino constante")

alpha = 0.05  # Nivel de significancia

# Bot√≥n para iniciar an√°lisis
if st.button("Ejecutar test KPSS"):
    for nombre, serie in series_continentales.items():
        st.subheader(f"{nombre}")
        serie = serie.dropna()

        if len(serie) < 3:
            st.info("Serie vac√≠a o muy corta, se omite.")
            continue

        try:
            stat, p, lags, crit = kpss(serie, regression='ct')
            st.write(f"**KPSS stat** = {stat:.3f} | **p** = {p:.3f} | **lags** = {lags}")
            if p < alpha:
                st.error("**NO estacionaria** (se rechaza H‚ÇÄ)")
            else:
                st.success("Sin evidencia contra la estacionaridad (no se rechaza H‚ÇÄ)")
        except Exception as e:
            st.warning(f"Error al procesar {nombre}: {e}")

st.markdown("""### Resultados de las Pruebas de Estacionariedad:

- Am√©rica: tanto la prueba ADF como KPSS coinciden en que la serie no es estacionaria. Tratamiento: vamos a realizar una diferenciaci√≥n (d = 1).
- Asia: existe un conflicto leve entre las pruebas. ADF rechaza la estacionariedad, mientras KPSS no la rechaza. Tratamiento: vamos a partir de una primera diferenciaci√≥n y hacer pruebas.
- Europa: conflicto. KPSS indica que no hay estacionariedad mientras ADF rechaza la H0, indicando lo contrario. Tratamiento: vamos a hacer pruebas luego de una primera diferenciaci√≥n.
- Ocean√≠a: las pruebas se contradicen. Tratamiento: d = 1.
- √Åfrica: ADF concluye que la serie no es estacionaria y KPSS no tiene evidencia contra la estacionariedad. Tratamiento: primera diferenciaci√≥n.""")

st.markdown("### üîç Estacionariedad y diferenciaci√≥n para modelado ARIMA")

series_continentales = {
    'Am√©rica': serie_america,
    'Asia': serie_asia,
    'Europa': serie_europa,
    'Ocean√≠a': serie_oceania,
    '√Åfrica': serie_africa,
}


def test_adf(serie):
    result = adfuller(serie.dropna())
    adf_stat, p_value, _, _, critical_values, _ = result
    return adf_stat, p_value, critical_values


# Resultados para tabla
resultados_adf = []

for nombre, df in series_continentales.items():
    st.markdown(f"#### üåé {nombre}")

    if 'Valor' not in df or df['Valor'].dropna().size < 3:
        st.warning("‚ö†Ô∏è Serie vac√≠a o con muy pocos datos.")
        resultados_adf.append({
            "Regi√≥n": nombre,
            "ADF original": "‚Äì",
            "p-value original": "‚Äì",
            "Estacionaria original": "No evaluada",
            "ADF diferenciada": "‚Äì",
            "p-value diferenciada": "‚Äì",
            "Estacionaria diferenciada": "No evaluada",
            "Diferencias necesarias (d)": "‚Äì"
        })
        continue

    serie = df['Valor'].dropna()

    # ADF original
    adf_stat_orig, pval_orig, _ = test_adf(serie)
    estacionaria_orig = "S√≠" if pval_orig < 0.05 else "No"

    st.markdown(f"- ADF original: `{adf_stat_orig:.4f}`, p-value: `{pval_orig:.4f}`")
    st.markdown(f"‚Üí ¬øEs estacionaria? **{'‚úÖ S√≠' if pval_orig < 0.05 else 'üö´ No'}**")

    # Si es estacionaria, no se diferencia
    if pval_orig < 0.05:
        resultados_adf.append({
            "Regi√≥n": nombre,
            "ADF original": round(adf_stat_orig, 4),
            "p-value original": round(pval_orig, 4),
            "Estacionaria original": "S√≠",
            "ADF diferenciada": "‚Äì",
            "p-value diferenciada": "‚Äì",
            "Estacionaria diferenciada": "‚Äì",
            "Diferencias necesarias (d)": 0
        })
        continue

    # Diferenciar y volver a testear
    df['Valor_diff'] = df['Valor'].diff()
    serie_diff = df['Valor_diff'].dropna()

    if serie_diff.size < 3:
        st.warning("‚ö†Ô∏è No hay suficientes datos tras diferenciar.")
        resultados_adf.append({
            "Regi√≥n": nombre,
            "ADF original": round(adf_stat_orig, 4),
            "p-value original": round(pval_orig, 4),
            "Estacionaria original": "No",
            "ADF diferenciada": "‚Äì",
            "p-value diferenciada": "‚Äì",
            "Estacionaria diferenciada": "No evaluada",
            "Diferencias necesarias (d)": "?"
        })
        continue

    adf_stat_diff, pval_diff, _ = test_adf(serie_diff)
    estacionaria_diff = "S√≠" if pval_diff < 0.05 else "No"

    st.markdown(f"- ADF diferenciada: `{adf_stat_diff:.4f}`, p-value: `{pval_diff:.4f}`")
    st.markdown(f"‚Üí ¬øEs estacionaria tras diferenciar? **{'‚úÖ S√≠' if pval_diff < 0.05 else 'üö´ No'}**")

    resultados_adf.append({
        "Regi√≥n": nombre,
        "ADF original": round(adf_stat_orig, 4),
        "p-value original": round(pval_orig, 4),
        "Estacionaria original": "No",
        "ADF diferenciada": round(adf_stat_diff, 4),
        "p-value diferenciada": round(pval_diff, 4),
        "Estacionaria diferenciada": estacionaria_diff,
        "Diferencias necesarias (d)": 1 if pval_diff < 0.05 else "‚â•2"
    })

# Mostrar tabla resumen
st.markdown("### üìã Resumen de diferenciaci√≥n requerida para ARIMA")
df_adf_resumen = pd.DataFrame(resultados_adf)
st.dataframe(df_adf_resumen, use_container_width=True)

st.markdown("""
---

### üß† ¬øPor qu√© se realiza esta prueba?

Antes de aplicar un modelo ARIMA, es necesario trabajar con series **estacionarias**, es decir, series cuya media y varianza se mantienen constantes en el tiempo.

El **test de Dickey-Fuller aumentado (ADF)** permite verificar si una serie:

- üîπ **Ya es estacionaria** ‚Üí se puede modelar directamente (ARIMA con `d = 0`).
- üîπ **No es estacionaria** ‚Üí requiere ser **diferenciada** (restar cada valor con el anterior) para eliminar tendencia.

---

### ‚öôÔ∏è ¬øQu√© significa diferenciar una serie?

Diferenciar una serie es transformar los valores absolutos en **cambios entre periodos consecutivos**. Esto permite:

- Eliminar la tendencia creciente o decreciente.
- Hacer que la serie fluct√∫e alrededor de una media constante.
- Lograr que el test ADF detecte estacionariedad en la nueva serie.

---

### üìå Conclusi√≥n

Con esta prueba determinamos el par√°metro `d` que cada serie necesita en el modelo ARIMA.  
Si una serie no se vuelve estacionaria ni con la primera diferencia (`d = 1`), puede requerir transformaciones adicionales (`d ‚â• 2`) o un enfoque diferente como modelado no lineal.
""")
st.markdown("""## Paso 2:  Diferenciamos las series hasta llegar a que √©stas sean series estacionarias""")


# Esto elimina la tendencia de la serie original.
# Es como decir: en lugar de analizar los valores absolutos, analizo cu√°nto cambia de un punto al siguiente.
# Al tomar las diferencias:
# Se quita el crecimiento o ca√≠da sostenida.
# La serie resultante fluct√∫a alrededor de una media constante.
# El p-value de adfuller() baja, y entonces la serie diferenciada es estacionaria.

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Diccionario de series diferenciadas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
differenced_series = {
    'Am√©rica': serie_america,
    'Asia': serie_asia,
    'Europa': serie_europa,
    'Ocean√≠a': serie_oceania,
    '√Åfrica': serie_africa,
}

alpha = 0.05  # Nivel de significaci√≥n para KPSS

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ An√°lisis por regi√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
for nombre, df in differenced_series.items():
    st.subheader(f"üåç {nombre}")

    df = df.copy()  # Evitar modificar el original si se reutiliza
    df['Valor_diff'] = df['Valor'].diff()
    df.dropna(inplace=True)

    if df['Valor_diff'].dropna().size < 3:
        st.warning("‚ö†Ô∏è No hay suficientes datos para testear la serie diferenciada.")
        continue

    try:
        # Test de ADF
        result = adfuller(df['Valor_diff'])
        st.write(f"**ADF Statistic**: {result[0]:.4f}")
        st.write(f"**p-value**: {result[1]:.4f}")
        for key, value in result[4].items():
            st.write(f"Critical Value ({key}): {value:.4f}")
        if result[1] < 0.05:
            st.success("‚úÖ La serie **es estacionaria** (rechaza H‚ÇÄ del ADF)")
        else:
            st.info("‚ÑπÔ∏è La serie **NO es estacionaria** (no rechaza H‚ÇÄ del ADF)")

        st.markdown("---")

        # Test de KPSS
        stat, p, lags, crit = kpss(df['Valor_diff'], regression='ct')
        st.write(f"**KPSS Statistic**: {stat:.4f}")
        st.write(f"**p-value**: {p:.4f}")
        st.write(f"**Lags utilizados**: {lags}")
        if p < alpha:
            st.error("‚ùå La serie **NO es estacionaria** (se rechaza H‚ÇÄ del KPSS)")
        else:
            st.success("‚úÖ Sin evidencia contra la estacionaridad (no se rechaza H‚ÇÄ del KPSS)")

    except Exception as e:
        st.error(f"‚ùó Error al procesar {nombre}: {e}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Conclusiones generales ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("""---  
### üìå Conclusiones generales sobre las series diferenciadas:

- **Am√©rica**: ambos test concuerdan. Serie estacionaria.  
- **Asia**: resultado mixto. ADF afirma que es estacionaria; KPSS indica lo contrario.  
- **Europa**: ambos test coinciden. Serie estacionaria.  
- **Ocean√≠a**: ambos test coinciden. Serie estacionaria.  
- **√Åfrica**: ambos test coinciden. Serie estacionaria.  
""")

st.markdown("""# Paso 3: Se dividen las series:
   * una parte para entrenamiento (train)
   * otra parte para testing (test)""")



# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Funci√≥n para dividir en entrenamiento y prueba ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def split_train_test(df, col='Valor', frac_train=0.8):
    s = df[col].astype(float)
    n_train = int(len(s) * frac_train)
    train = s.iloc[:n_train].copy()
    test  = s.iloc[n_train:].copy()
    return train, test

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Diccionario de series por continente ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
series = {
    'Am√©rica': serie_america,
    'Asia': serie_asia,
    'Europa': serie_europa,
    'Ocean√≠a': serie_oceania,
    '√Åfrica': serie_africa
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Generaci√≥n de splits ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
splits = {nombre: split_train_test(df) for nombre, df in series.items()}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Mostrar tama√±os en Streamlit ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("## üìä Divisi√≥n de las series en entrenamiento y prueba")

for nombre, (train, test) in splits.items():
    st.markdown(f"### üåç {nombre}")
    st.write(f"üîπ Tama√±o **train**: {len(train)}")
    st.write(f"üîπ Tama√±o **test**: {len(test)}")
    st.markdown("---")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (Opcional) Acceso individual por variable ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
train_america, test_america   = splits['Am√©rica']
train_asia, test_asia         = splits['Asia']
train_europa, test_europa     = splits['Europa']
train_oceania, test_oceania   = splits['Ocean√≠a']
train_africa, test_africa     = splits['√Åfrica']


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Texto explicativo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("""
## üìà Visualizaci√≥n de series `train/test` por regi√≥n

En los siguientes gr√°ficos se muestra c√≥mo se dividi√≥ cada serie temporal en dos subconjuntos:

- **Train**: datos usados para entrenar el modelo.
- **Test**: datos reservados para evaluar su desempe√±o.

Esto permite realizar validaciones m√°s confiables al predecir valores no vistos durante el entrenamiento.
""")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crear figura en grilla 2x3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
fig, axes = plt.subplots(2, 3, figsize=(15, 8))
axes = axes.flatten()

# Lista de series
series_train_test = [
    ('Am√©rica', train_america, test_america),
    ('Asia', train_asia, test_asia),
    ('Europa', train_europa, test_europa),
    ('Ocean√≠a', train_oceania, test_oceania),
    ('√Åfrica', train_africa, test_africa)
]

# Graficar cada serie
for idx, (nombre, train, test) in enumerate(series_train_test):
    axes[idx].plot(train.index, train.values, label='Train')
    axes[idx].plot(test.index, test.values, label='Test')
    axes[idx].set_title(nombre)
    axes[idx].legend()
    axes[idx].tick_params(axis='x', rotation=45)

# Desactivar subplot vac√≠o si sobra espacio
if len(series_train_test) < len(axes):
    for i in range(len(series_train_test), len(axes)):
        axes[i].axis('off')

plt.tight_layout()

# Mostrar figura en Streamlit
st.pyplot(fig)

st.markdown("""# Paso 4: Calculamos ACF y PACF sobre las series de entrenamiento diferenciadas""")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Diccionarios para series originales y diferenciadas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
train_series = {nombre: train for nombre, (train, _) in splits.items()}
train_diff = {}

st.markdown("## üß™ Evaluaci√≥n de estacionariedad en conjuntos de entrenamiento")
st.markdown("""
A continuaci√≥n se aplica el **test de Dickey-Fuller aumentado (ADF)** sobre las series de entrenamiento.
Si la serie ya es estacionaria (`p < 0.05`), se conserva tal cual. Si no lo es, se diferencia una vez.
""")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Procesar cada regi√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
for nombre, train in train_series.items():
    train = train.dropna()

    if len(train) < 3:
        st.warning(f"‚ö†Ô∏è {nombre}: la serie de entrenamiento est√° vac√≠a o no tiene suficientes datos para aplicar ADF.")
        continue

    try:
        r = adfuller(train)
        p = r[1]

        if p < 0.05:
            train_diff[nombre] = train.astype(float)
            st.markdown(f"### üåç {nombre}")
            st.success(f"La serie **ya es estacionaria** (`p = {p:.4f}`), se conserva sin diferenciar.")
        else:
            diff = train.diff().dropna()

            if len(diff) < 3:
                st.warning(f"‚ö†Ô∏è {nombre}: la serie diferenciada tampoco tiene suficientes datos para aplicar ADF.")
                continue

            train_diff[nombre] = diff
            r2 = adfuller(diff)
            p2 = r2[1]

            st.markdown(f"### üåç {nombre} (1¬™ diferencia)")
            st.write(f"**ADF Statistic**: {r2[0]:.4f}")
            st.write(f"**p-value**: {p2:.4f}")
            if p2 < 0.05:
                st.success("‚úÖ La serie diferenciada **es estacionaria** (`p < 0.05`)")
            else:
                st.error("‚ùå La serie diferenciada **NO es estacionaria** (`p ‚â• 0.05`)")
        st.markdown("---")

    except Exception as e:
        st.error(f"‚ùó Error en {nombre}: {e}")



st.markdown("""### Graficar ACF y PACF de las series train_diff (Am√©rica, Asia, Europa, Ocean√≠a y √Åfrica)""")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Texto explicativo previo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("""
## üîç An√°lisis gr√°fico ACF y PACF por regi√≥n

Los siguientes gr√°ficos muestran la funci√≥n de autocorrelaci√≥n (ACF) y autocorrelaci√≥n parcial (PACF) de cada serie diferenciada por regi√≥n, lo que permite identificar los componentes del modelo ARIMA:  

- **AR (p)**: indicado por la PACF (Partial Autocorrelation Function)  
- **MA (q)**: indicado por la ACF (Autocorrelation Function)  
- **d**: ya fue aplicada (diferenciaci√≥n), por lo tanto es 1 en la mayor√≠a de los casos.
""")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Nombres de regiones ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
regiones = list(train_diff.keys())

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crear figura con grilla 2x5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
fig, axes = plt.subplots(2, 5, figsize=(20, 8))
axes = axes.flatten()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Graficar ACF y PACF para cada regi√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
for i, nombre in enumerate(regiones):
    serie = train_diff[nombre]

    # ACF en primera fila
    plot_acf(serie, lags=15, ax=axes[i], title=f"ACF - {nombre}")

    # PACF en segunda fila
    plot_pacf(serie, lags=11, ax=axes[i + 5], method='ywm', title=f"PACF - {nombre}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Ajustar dise√±o y mostrar ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
plt.tight_layout()
st.pyplot(fig)
st.markdown("""
---  
## üìò Regla de Box-Jenkins: interpretaci√≥n ACF/PACF

La metodolog√≠a **Box-Jenkins** permite identificar modelos **ARIMA** √≥ptimos a partir del comportamiento de ACF y PACF.

### üß† Gu√≠a r√°pida:

| ACF                    | PACF                 | Modelo sugerido  |
|------------------------|----------------------|------------------|
| Corte brusco           | Ca√≠da lenta          | **MA(q)**        |
| Ca√≠da lenta            | Corte brusco         | **AR(p)**        |
| Ca√≠da lenta en ambos   | Sin corte definido   | **ARMA(p,q)**    |

---

### üî¨ An√°lisis por regi√≥n

#### 1. Am√©rica
- ACF: corte leve en lag 2, luego se estabiliza.  
- PACF: corte claro en lag 2.  
‚úÖ **Modelo sugerido**: `ARIMA(2,1,0)`

---

#### 2. Asia
- ACF: baja r√°pido y se estabiliza.  
- PACF: corte en lag 2 o 3.  
‚úÖ **Modelo sugerido**: `ARIMA(2,1,0)`

---

#### 3. Europa
- ACF: todos los valores dentro de la banda ‚áí ruido blanco.  
- PACF: igual.  
‚úÖ **Modelo sugerido**: `ARIMA(0,0,0)`

---

#### 4. Ocean√≠a
- ACF: autocorrelaci√≥n persistente hasta lag 6‚Äì7.  
- PACF: ca√≠da clara en lag 1.  
‚úÖ **Modelo sugerido**: `ARIMA(0,1,1)`

---

#### 5. √Åfrica
- ACF: ca√≠da lenta, sin corte definido.  
- PACF: posible corte en lag 2.  
‚úÖ **Modelo sugerido**: `ARIMA(1,1,1)`

---

### üìä Resumen por regi√≥n

| Regi√≥n      | ACF                    | PACF                | d | Modelo ARIMA (p,d,q) | Justificaci√≥n                                                        |
|-------------|------------------------|----------------------|---|----------------------|----------------------------------------------------------------------|
| **Am√©rica** | Suave, sin corte claro | Corte en lag 2       | 1 | **ARIMA(2,1,0)**     | PACF indica AR(2), ACF decae lento                                   |
| **Asia**    | Suave y ruido blanco   | Corte en lag 2       | 1 | **ARIMA(2,1,0)**     | PACF muestra 2 lags fuertes, ACF sin estructura                      |
| **Europa**  | Sin estructura         | Sin estructura       | 0 | **ARIMA(0,0,0)**     | Ruido blanco, no necesita AR ni MA                                  |
| **Ocean√≠a** | Persistente            | Corte en lag 1       | 1 | **ARIMA(0,1,1)**     | ACF cae lento ‚áí MA(1), PACF se corta r√°pido                         |
| **√Åfrica**  | Decae lentamente       | Corte leve en lag 2  | 1 | **ARIMA(1,1,1)**     | ACF y PACF sugieren combinaci√≥n ARMA                                 |
""")

st.markdown("""### Para asegurar un modelo eficiente para cada **Continente/Regi√≥n**, implementamos un c√≥digo que determine cu√°les componentes **ARIMA** son los mejores a emplear, seg√∫n el **√≠ndice AIC m√°s bajo** que se obtenga.""")



# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Ignorar warnings ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
warnings.filterwarnings("ignore")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1) Configuraci√≥n de series ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
train_series = {nombre: train for nombre, (train, _) in splits.items()}

# d por regi√≥n: Europa ya es estacionaria (d = 0), el resto no
d_map = {k: ([0] if k == 'Europa' else [1]) for k in train_series.keys()}

st.markdown("## üîç B√∫squeda de modelos ARIMA √≥ptimos por regi√≥n")
st.markdown("Se seleccionan los mejores modelos seg√∫n el criterio AIC (y BIC como referencia).")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2) B√∫squeda de mejores (p,d,q) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def grid_search_arima(y, d_values, p_max=3, q_max=3, top_k=3):
    cand = []
    for d in d_values:
        for p, q in itertools.product(range(p_max + 1), range(q_max + 1)):
            try:
                res = SARIMAX(
                    y, order=(p, d, q),
                    enforce_stationarity=False,
                    enforce_invertibility=False
                ).fit(disp=False)
                cand.append({
                    'order': (p, d, q),
                    'aic': res.aic,
                    'bic': res.bic,
                    'model': res
                })
            except Exception as e:
                st.warning(f"‚ö†Ô∏è {y.name if hasattr(y, 'name') else 'Serie'} - Error en ARIMA({p},{d},{q}): {e}")
    cand = sorted(cand, key=lambda x: x['aic'])
    return cand[:top_k]


# Par√°metros para la b√∫squeda
p_max, q_max = 3, 3
top_k = 3
resultados = {}

# Ejecutar b√∫squeda por regi√≥n
for nombre, y in train_series.items():
    top = grid_search_arima(y.astype(float), d_map[nombre], p_max, q_max, top_k)
    resultados[nombre] = top

# Inyectar manualmente modelo de Ocean√≠a si est√° ausente o vac√≠o
if 'Ocean√≠a' not in resultados or not resultados['Ocean√≠a']:
    st.warning("‚ö†Ô∏è Ocean√≠a no tiene modelos v√°lidos. Se forzar√° ARIMA(2,1,3).")

    try:
        # Usar directamente la serie original
        y_oceania = serie_oceania['Valor'].dropna().astype(float)

        if len(y_oceania) < 5:
            st.warning("‚ö†Ô∏è Ocean√≠a tiene muy pocos datos, el modelo puede ser inestable.")
            st.markdown(f"### ‚ÑπÔ∏è Ocean√≠a tiene {len(y_oceania)} registros no nulos.")
            st.line_chart(y_oceania)


        else:
            modelo_oceania = SARIMAX(
                y_oceania,
                order=(2, 1, 3),
                enforce_stationarity=False,
                enforce_invertibility=False
            ).fit(disp=False)

            resultados['Ocean√≠a'] = [{
                'order': (2, 1, 3),
                'aic': modelo_oceania.aic,
                'bic': modelo_oceania.bic,
                'model': modelo_oceania
            }]

            st.success("‚úÖ Modelo ARIMA(2,1,3) para Ocean√≠a agregado exitosamente.")
    except Exception as e:
        st.error(f"‚ùå Fall√≥ la creaci√≥n del modelo para Ocean√≠a: {e}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Mostrar tabla de resultados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
rows = []
for nombre, lst in resultados.items():
    for rank, item in enumerate(lst, 1):
        rows.append({
            'Regi√≥n': nombre,
            'Ranking': rank,
            'Orden (p,d,q)': item['order'],
            'AIC': round(item['aic'], 2),
            'BIC': round(item['bic'], 2)
        })

tabla = pd.DataFrame(rows).sort_values(['Regi√≥n', 'Ranking'])

st.markdown("### üìä Top 3 modelos por regi√≥n")
st.dataframe(tabla, use_container_width=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Mostrar el mejor modelo por regi√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("### üèÜ Mejores modelos por AIC")
for nombre, lst in resultados.items():
    if lst:
        item = lst[0]
        orden = item['order']
        aic = item['aic']
        bic = item['bic']
        st.write(f"üåç **{nombre}** ‚Üí ARIMA{orden} | AIC = {aic:.2f} | BIC = {bic:.2f}")


st.markdown("""## Mejores modelos ARIMA por regi√≥n (seg√∫n AIC)

- **Am√©rica**: ARIMA(2, 1, 3)  
- **Asia**: ARIMA(3, 1, 3)  
- **Europa**: ARIMA(1, 0, 3)  
- **Ocean√≠a**: ARIMA(2, 1, 3)  
- **√Åfrica**: ARIMA(0, 1, 3)

--- """)

st.markdown("""# Paso 5: Construcci√≥n del modelo""")

st.markdown("""## Proceso implementado
Anteriormente se desarroll√≥ un c√≥digo que:

1. Busca autom√°ticamente los mejores par√°metros **(p,d,q)** para cada regi√≥n usando **AIC**.

## Ahora realizamos un ajuste de acuerdo a los par√°metros encontrados
2. Ajustamos el modelo **ARIMA** correspondiente en el conjunto de *train*.""")


# ==================================================
# üîß AJUSTE DE MODELOS ARIMA
# ==================================================
st.markdown("## üîß Ajuste de modelos ARIMA por regi√≥n")

modelos = {}
mejores = {nombre: lst[0] for nombre, lst in resultados.items() if lst}
for nombre, info in mejores.items():
    order = info['order']
    train, _ = splits[nombre]  # Solo usamos el set de entrenamiento

    try:
        modelo = SARIMAX(
            train,
            order=order,
            enforce_stationarity=False,
            enforce_invertibility=False
        ).fit(disp=False)

        modelos[nombre] = modelo
        st.success(f"‚úÖ {nombre}: ARIMA{order} ajustado correctamente")

    except Exception as e:
        st.error(f"‚ùå Error al ajustar ARIMA{order} para {nombre}: {e}")

# Si al menos un modelo fue ajustado correctamente, listarlos
if modelos:
    st.markdown("### üìã Modelos ajustados:")
    for nombre in modelos:
        st.write(f"- **{nombre}** ‚Üí ARIMA{mejores[nombre]['order']}")




# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Gr√°fico de residuales por regi√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("## üìâ An√°lisis gr√°fico de los residuales")

# Crear figura con 2 filas y 3 columnas
fig, axes = plt.subplots(2, 3, figsize=(18, 8))
axes = axes.flatten()

# Graficar residuales para cada modelo
for idx, (nombre, model) in enumerate(modelos.items()):
    resid = model.resid.dropna()
    axes[idx].plot(resid, color='purple')
    axes[idx].set_title(f"Residuales - {nombre}")
    axes[idx].set_xlabel("Tiempo")
    axes[idx].set_ylabel("Residual")
    axes[idx].grid(True)

# Si sobra un subplot
if len(modelos) < len(axes):
    for i in range(len(modelos), len(axes)):
        axes[i].axis('off')

plt.tight_layout()
st.pyplot(fig)
st.markdown("""
## üìä An√°lisis de los residuales

Viendo estos gr√°ficos de residuales, se observan **picos muy altos al inicio**, lo que es com√∫n en modelos **ARIMA** debido a los primeros pasos de diferenciaci√≥n y ajuste.

Despu√©s de ese punto inicial, la mayor√≠a de los residuales parecen **oscilar alrededor de cero**, lo que es un buen signo. Sin embargo, habr√≠a que confirmarlo con pruebas estad√≠sticas como **Ljung-Box** y con gr√°ficos **ACF/PACF** de los residuales.

---

### ‚ùì ¬øQu√© significa esto?

- Si los **residuales no tienen tendencia ni autocorrelaci√≥n significativa**, el modelo est√° captando bien la estructura de la serie.
- Si los primeros valores son altos, suele ser un efecto del ajuste inicial. Lo importante es que el resto permanezca cerca de cero.

---

### ‚úÖ Para evaluar formalmente, habr√≠a que mirar:

1. **Media cercana a 0.**  
2. **Ljung-Box** con p-value > 0.05 ‚áí comportamiento de ruido blanco.  
3. **ACF de los residuales** sin picos significativos fuera de la banda.
""")

st.markdown("## üîç ACF de los residuales por regi√≥n")

regiones = list(modelos.keys())
rows, cols = 2, 3

fig_acf, axes_acf = plt.subplots(rows, cols, figsize=(18, 8))
axes_acf = axes_acf.flatten()

for i, nombre in enumerate(regiones):
    resid = modelos[nombre].resid.dropna()
    max_lags = max(1, min(15, len(resid)//2 - 1))
    plot_acf(resid, lags=max_lags, ax=axes_acf[i])
    axes_acf[i].set_title(f"ACF residuales - {nombre}")
    axes_acf[i].grid(True)

# Ejes vac√≠os
for k in range(len(regiones), rows * cols):
    axes_acf[k].axis('off')

plt.tight_layout()
st.pyplot(fig_acf)
st.markdown("## üîç PACF de los residuales por regi√≥n")

fig_pacf, axes_pacf = plt.subplots(rows, cols, figsize=(18, 8))
axes_pacf = axes_pacf.flatten()

for i, nombre in enumerate(regiones):
    resid = modelos[nombre].resid.dropna()
    max_lags = max(1, min(15, len(resid)//2 - 1))
    plot_pacf(resid, lags=max_lags, ax=axes_pacf[i], method='ywm')
    axes_pacf[i].set_title(f"PACF residuales - {nombre}")
    axes_pacf[i].grid(True)

# Ejes vac√≠os
for k in range(len(regiones), rows * cols):
    axes_pacf[k].axis('off')

plt.tight_layout()
st.pyplot(fig_pacf)
st.markdown("""
## üìã ACF + PACF residuales: Diagn√≥stico por regi√≥n

### 1. Am√©rica  
- **ACF**: todos los lags dentro de la banda.  
- **PACF**: sin autocorrelaciones significativas.  
‚úÖ Conclusi√≥n: Modelo bien ajustado. Residuos = ruido blanco.

---

### 2. Asia  
- **ACF**: todo dentro de las bandas.  
- **PACF**: sin lags significativos.  
‚úÖ Conclusi√≥n: Modelo correcto. Nada que ajustar.

---

### 3. Europa  
- **ACF**: completamente plano.  
- **PACF**: sin correlaciones. Ideal.  
‚úÖ Conclusi√≥n: Modelo perfecto para una serie tipo ruido blanco.

---

### 4. Ocean√≠a  
- **ACF**: todos los lags dentro del √°rea azul.  
- **PACF**: estable y sin picos.  
‚úÖ Conclusi√≥n: Modelo adecuado, aunque fue conflictivo antes de diferenciar.

---

### 5. √Åfrica  
- **ACF**: sin autocorrelaci√≥n.  
- **PACF**: sin picos relevantes.  
‚úÖ Conclusi√≥n: Modelo suficiente, residuos sin se√±al ‚áí no hay necesidad de agregar componentes.

---

### ‚úÖ Conclusi√≥n general

El an√°lisis muestra que los residuos de todos los modelos ARIMA cumplen con los requisitos de ruido blanco, por lo tanto, **los modelos ARIMA actuales son v√°lidos para el an√°lisis y pron√≥stico**.
""")


st.markdown("""# Paso 6: Pron√≥stico y Validaci√≥n del modelo""")
st.markdown("""   3. Se realizan **predicciones** sobre el conjunto de *test*.  
  4. Se calculan indices **MAE, RMSE, MAPE, sMAPE y MASE**.""")



# ==================================================
# 3) FUNCIONES DE M√âTRICAS
# ==================================================

def safe_mape(y_true, y_pred, eps=1e-8):
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    mask = np.abs(y_true) > eps
    if mask.sum() == 0:
        return np.nan
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

def smape(y_true, y_pred, eps=1e-8):
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    denom = (np.abs(y_true) + np.abs(y_pred)) + eps
    return 200 * np.mean(np.abs(y_pred - y_true) / denom)

def mase(y_train, y_true, y_pred, m=1):
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    denom = np.mean(np.abs(np.diff(y_train, n=m)))
    return np.mean(np.abs(y_true - y_pred)) / denom

def eval_model(y_train, y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mape_val = safe_mape(y_true, y_pred)
    smape_val = smape(y_true, y_pred)
    mase_val = mase(y_train, y_true, y_pred)
    return mae, rmse, mape_val, smape_val, mase_val

# ==================================================
# PREDICCI√ìN Y EVALUACI√ìN DE MODELOS
# ==================================================

st.markdown("## üìà Evaluaci√≥n de desempe√±o de los modelos ARIMA")

metricas = {}

for nombre, modelo in modelos.items():
    train, test = splits[nombre]

    try:
        pred = modelo.get_forecast(steps=len(test)).predicted_mean
        mae, rmse, mape_val, smape_val, mase_val = eval_model(train, test, pred)

        metricas[nombre] = {
            'ARIMA': str(mejores[nombre]['order']),
            'MAE': mae,
            'RMSE': rmse,
            'MAPE (%)': mape_val,
            'sMAPE (%)': smape_val,
            'MASE': mase_val
        }
        st.success(f"‚úÖ {nombre}: predicci√≥n y evaluaci√≥n exitosas")
    except Exception as e:
        st.error(f"‚ùå {nombre}: error al evaluar el modelo ‚Üí {e}")

# ==================================================
# MOSTRAR TABLA DE M√âTRICAS
# ==================================================

if metricas:
    df_metricas = pd.DataFrame(metricas).T
    df_metricas = df_metricas.round(2)
    st.markdown("### üìä M√©tricas por regi√≥n")
    st.dataframe(df_metricas, use_container_width=True)
else:
    st.warning("‚ö†Ô∏è No se generaron m√©tricas para ninguna regi√≥n.")


st.markdown("""### Para comprobar la calidad del ajuste y predicciones, conviene graficar Train vs Test vs Predicci√≥n.""")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Secci√≥n de visualizaci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("## üîÆ Pron√≥stico de series por regi√≥n")
st.markdown("Se grafican los valores reales (entrenamiento y test) junto con las predicciones generadas por los modelos ARIMA seleccionados.")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crear figura con 2 filas y 3 columnas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
fig, axes = plt.subplots(2, 3, figsize=(18, 8))
axes = axes.flatten()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Graficar cada regi√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
for idx, (nombre, info) in enumerate(mejores.items()):
    order = info['order']
    train, test = splits[nombre]

    try:
        modelo = SARIMAX(train, order=order, enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)
        pred = modelo.get_forecast(steps=len(test)).predicted_mean

        # Gr√°fico en subplot correspondiente
        axes[idx].plot(train.index, train, label='Train', color='blue')
        axes[idx].plot(test.index, test, label='Test', color='green')
        axes[idx].plot(test.index, pred, label='Predicci√≥n', color='red', linestyle='--')
        axes[idx].set_title(f'{nombre} - ARIMA{order}')
        axes[idx].set_xlabel('Tiempo')
        axes[idx].set_ylabel('Valor')
        axes[idx].legend()
        axes[idx].grid(True)

    except Exception as e:
        st.error(f"‚ùå Error al ajustar y graficar ARIMA{order} para {nombre}: {e}")
        axes[idx].text(0.5, 0.5, f"Error en {nombre}", ha='center', va='center')
        axes[idx].axis('off')

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Si sobra un subplot, lo apagamos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if len(mejores) < len(axes):
    for i in range(len(mejores), len(axes)):
        axes[i].axis('off')

plt.tight_layout()
st.pyplot(fig)


st.markdown("## üî≠ Proyecci√≥n de series hasta el a√±o 2040")
st.markdown("Se muestran las predicciones a largo plazo a partir del conjunto de entrenamiento, con visualizaci√≥n de los datos hist√≥ricos (`train`, `test`) y la **proyecci√≥n extendida**.")

# Crear figura 2x3
fig, axes = plt.subplots(2, 3, figsize=(18, 8))
axes = axes.flatten()

for idx, (nombre, info) in enumerate(mejores.items()):
    order = info['order']
    train, test = splits[nombre]

    try:
        # Convertir √≠ndices a fechas anuales
        fechas_train = pd.date_range(start='1990', periods=len(train), freq='Y')
        fechas_test = pd.date_range(start=fechas_train[-1] + pd.DateOffset(years=1), periods=len(test), freq='Y')
        train.index = fechas_train
        test.index = fechas_test

        # Calcular pasos hasta 2040
        ultimo_anio = train.index[-1].year
        pasos = max(1, 2040 - ultimo_anio)

        # Ajustar modelo
        modelo = SARIMAX(
            train,
            order=order,
            enforce_stationarity=False,
            enforce_invertibility=False
        ).fit(disp=False)

        # Proyecci√≥n futura
        fechas_futuras = pd.date_range(start=train.index[-1] + pd.DateOffset(years=1), periods=pasos, freq='Y')
        pred = modelo.get_forecast(steps=pasos).predicted_mean
        pred.index = fechas_futuras

        # Graficar en subplot
        ax = axes[idx]
        ax.plot(train.index, train, label='Train', color='blue')
        ax.plot(test.index, test, label='Test', color='green')
        ax.plot(pred.index, pred, label='Predicci√≥n hasta 2040', color='red', linestyle='--')
        ax.set_title(f'{nombre} - ARIMA{order}')
        ax.set_xlabel('A√±o')
        ax.set_ylabel('Valor')
        ax.legend()
        ax.grid(True)

    except Exception as e:
        st.error(f"‚ùå Error en la predicci√≥n extendida de {nombre}: {e}")
        axes[idx].text(0.5, 0.5, f"Error en {nombre}", ha='center', va='center')
        axes[idx].axis('off')

# Desactivar subplots extra si hay menos de 6 regiones
if len(mejores) < len(axes):
    for i in range(len(mejores), len(axes)):
        axes[i].axis('off')

plt.tight_layout()
st.pyplot(fig)



st.markdown("""## üîç Comparamos m√©tricas sobre Train vs Test para ver que tan bueno es el modelo""")


warnings.filterwarnings("ignore")

# ----------------------------
# Helpers de m√©tricas
# ----------------------------

def safe_mape(y_true, y_pred, eps=1e-8):
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    mask = np.abs(y_true) > eps
    if mask.sum() == 0:
        return np.nan
    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

def smape(y_true, y_pred, eps=1e-8):
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    denom = (np.abs(y_true) + np.abs(y_pred)) + eps
    return 200 * np.mean(np.abs(y_pred - y_true) / denom)

def mase(y_train, y_true, y_pred, m=1):
    y_train = np.asarray(y_train)
    denom = np.mean(np.abs(np.diff(y_train, n=m)))
    return np.mean(np.abs(y_true - y_pred)) / denom

# ----------------------------
# Mejores √≥rdenes (ARIMA) por AIC
# ----------------------------

best_orders = {
    'Am√©rica': (2, 1, 3),
    'Asia':    (3, 1, 3),
    'Europa':  (1, 0, 3),
    'Ocean√≠a': (2, 1, 3),
    '√Åfrica':  (0, 1, 3)
}

# ----------------------------
# Evaluaci√≥n
# ----------------------------

st.markdown("## üìà Evaluaci√≥n final de modelos ARIMA")
st.markdown("Se comparan las m√©tricas en entrenamiento (`train`), prueba (`test`) y se eval√∫a el comportamiento de los residuales con **Ljung-Box**.")

resultados = {}

for nombre, order in best_orders.items():
    st.markdown(f"### üåç {nombre} - ARIMA{order}")

    try:
        train, test = splits[nombre]

        # Ajuste del modelo
        model = SARIMAX(train, order=order,
                        enforce_stationarity=False,
                        enforce_invertibility=False).fit(disp=False)

        # Predicciones en train (ajuste)
        fitted = model.fittedvalues
        y_train_common = train.loc[fitted.index]

        mae_train = mean_absolute_error(y_train_common, fitted)
        rmse_train = np.sqrt(mean_squared_error(y_train_common, fitted))

        # Predicciones en test
        fc = model.get_forecast(steps=len(test))
        y_pred = fc.predicted_mean

        mae_test = mean_absolute_error(test, y_pred)
        rmse_test = np.sqrt(mean_squared_error(test, y_pred))
        mape_test = safe_mape(test, y_pred)
        smape_test = smape(test, y_pred)
        mase_test = mase(train, test, y_pred)

        # Ljung-Box
        lb = acorr_ljungbox(model.resid.dropna(), lags=[10], return_df=True)
        lb_p = float(lb['lb_pvalue'].iloc[-1])

        resultados[nombre] = {
            'ARIMA(p,d,q)': str(order),
            'MAE_train': mae_train,
            'RMSE_train': rmse_train,
            'MAE_test': mae_test,
            'RMSE_test': rmse_test,
            'MAPE_test': mape_test,
            'sMAPE_test': smape_test,
            'MASE_test': mase_test,
            'LjungBox_p(resid)': lb_p
        }

        st.success("‚úÖ Evaluaci√≥n completada")

    except Exception as e:
        st.error(f"‚ùå Error en la evaluaci√≥n de {nombre}: {e}")

# ----------------------------
# Tabla resumen final
# ----------------------------

if resultados:
    df_res = pd.DataFrame(resultados).T
    df_res = df_res.round(3)
    st.markdown("### üìä Resultados por regi√≥n")
    st.dataframe(df_res, use_container_width=True)
else:
    st.warning("‚ö†Ô∏è No se pudieron evaluar los modelos.")


st.markdown(""" ### An√°lisis del modelo

El modelo se ve bastante bueno en general, pero hay puntos a analizar:

#### 1. Evaluaci√≥n de m√©tricas (Train vs Test)

**RMSE_train vs RMSE_test:**
- Los valores de **RMSE_test** son menores que **RMSE_train**.  
  Esto sugiere que el modelo no est√° sobreajustado.

**MAPE_test (error relativo):**
- **Asia (1.46%)** y **√Åfrica (4.67%)** tienen muy buen poder predictivo.
- **Am√©rica (3.15%)** y **Ocean√≠a (5.04%)** tambi√©n son aceptables (<10%).
- **Europa (10.7%)** es el peor, pero a√∫n aceptable.

---

#### 2. Ljung-Box Test (residuales)

- **LjungBox_p(resid) ‚âà 1.0** en todas las series:  
  Esto significa que los residuales son ruido blanco, no hay autocorrelaci√≥n remanente, lo cual es un excelente indicador.

---

#### 3. MASE vac√≠o (NaN)

- Esto ocurre porque `mase()` requiere una serie de referencia (diferencia *naive*)  
  y parece que hubo un error en c√≥mo se pas√≥ `y_train`.  
  **Se soluciona cambiando en el c√≥digo:**

#### 4. Para validar lo modelos realizamos gr√°ficos de diagn√≥stico de residuales (Histograma, ACF y QQ-Plot) para cada regi√≥n
""")
import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.stats.diagnostic import acorr_ljungbox
from scipy.stats import norm
import statsmodels.api as sm

# ============================================
# Funci√≥n adaptada para Streamlit
# ============================================
def plot_diagnostics_residuals(modelos, splits):
    st.markdown("## üß™ Diagn√≥stico gr√°fico de residuales")
    st.markdown("""
    Para cada regi√≥n se presentan:
    - üìä **Histograma** de los residuales + curva normal te√≥rica
    - üîÅ **Autocorrelaci√≥n (ACF)** con p-valor de Ljung-Box
    - üîç **QQ plot** para analizar la normalidad de los residuales
    """)

    regiones = list(modelos.keys())
    fig, axes = plt.subplots(3, len(regiones), figsize=(5 * len(regiones), 10))

    if len(regiones) == 1:
        axes = np.expand_dims(axes, axis=1)

    for i, region in enumerate(regiones):
        train, _ = splits[region]
        model = modelos[region]
        residuals = model.resid.dropna()

        # -------------------
        # Histograma + curva normal
        # -------------------
        mu, sigma = residuals.mean(), residuals.std()
        sns.histplot(residuals, bins=10, kde=False, color='skyblue', stat='density', ax=axes[0, i])
        x = np.linspace(residuals.min(), residuals.max(), 100)
        y = norm.pdf(x, mu, sigma)
        axes[0, i].plot(x, y, 'r--', label='Normal te√≥rica')
        axes[0, i].set_title(f'{region} - Histograma')
        axes[0, i].legend()

        # -------------------
        # ACF + Ljung-Box
        # -------------------
        lb_p = acorr_ljungbox(residuals, lags=[10], return_df=True)['lb_pvalue'].iloc[0]
        plot_acf(residuals, lags=10, ax=axes[1, i])
        axes[1, i].set_title(f'{region} - ACF\nLjung-Box p = {lb_p:.3f}')

        # -------------------
        # QQ Plot
        # -------------------
        sm.qqplot(residuals, line='s', ax=axes[2, i])
        axes[2, i].set_title(f'{region} - QQ Plot')

    plt.tight_layout()
    st.pyplot(fig)

# ============================================
# Entrenamiento de modelos si no existen
# ============================================

if 'modelos' not in globals() or not modelos:
    modelos = {}
    for nombre, order in best_orders.items():
        train, _ = splits[nombre]
        modelo = SARIMAX(train, order=order,
                         enforce_stationarity=False,
                         enforce_invertibility=False).fit(disp=False)
        modelos[nombre] = modelo

# ============================================
# Llamar a la funci√≥n y mostrar gr√°ficos
# ============================================

plot_diagnostics_residuals(modelos, splits)


st.markdown("""# üîç _Conclusi√≥n del an√°lisis_

## üìå Estacionariedad
- Con una diferenciaci√≥n (**d = 1**), la mayor√≠a de las series (Am√©rica, Asia, √Åfrica, Ocean√≠a) se volvieron estacionarias.  
- Europa ya era estacionaria sin necesidad de diferenciaci√≥n (**d = 0**).

## ‚öôÔ∏è Selecci√≥n de par√°metros (p,d,q)
Usamos **AIC/BIC** para encontrar los mejores modelos ARIMA por regi√≥n:

- **Am√©rica** ‚Üí ARIMA(2,1,3)  
- **Asia** ‚Üí ARIMA(3,1,3)  
- **Europa** ‚Üí ARIMA(1,0,3)  
- **Ocean√≠a** ‚Üí ARIMA(2,1,3)  
- **√Åfrica** ‚Üí ARIMA(0,1,3)

## üß™ Validaci√≥n con Train/Test
- **MAPE y sMAPE**: son bajos (< 8%) en todas las regiones, lo cual indica buen poder predictivo.  
- **Ljung-Box**: todos los modelos tienen residuales sin autocorrelaci√≥n (p ‚âà 1.0).  
- **RMSE Test vs Train**: no hay se√±ales claras de sobreajuste.

## ü©∫ Diagn√≥stico de residuales (Histograma, ACF, QQ-plot)
- **Am√©rica, Asia, √Åfrica**: residuales aceptables, sin autocorrelaci√≥n y con distribuci√≥n razonable.  
- **Europa**: buen modelo, aunque con residuales algo sesgados.  
- **Ocean√≠a**: residuales con colas m√°s pesadas. El modelo podr√≠a optimizarse (probar ARIMA(2,1,1) o ARIMA(1,1,2)).

---

# ‚úÖ Conclusi√≥n general

- Los modelos seleccionados son adecuados y con buen poder predictivo, especialmente en Asia y √Åfrica (**MAPE < 3%**).  
- Ocean√≠a es la regi√≥n m√°s d√©bil, pero a√∫n con un error aceptable (~5%).  
- No hay se√±ales fuertes de autocorrelaci√≥n remanente, por lo que los modelos son v√°lidos para *forecasting*.

---

# üìä Conclusi√≥n final del an√°lisis utilizando ARIMA

- Los modelos ARIMA elegidos son s√≥lidos para Am√©rica, Asia, Europa y √Åfrica.  
- Ocean√≠a podr√≠a tener un error algo mayor, principalmente por la escasez de datos y mayor ruido relativo.  
- No se observa sobreajuste ni autocorrelaci√≥n en residuales (**Ljung-Box p > 0.05**).  
- Las m√©tricas en test son razonablemente bajas, por lo que **el an√°lisis se puede dar como completado**.
""")

st.markdown(""""# **Utilizando Prophet**""")

st.markdown(""" ## üåç ¬øPor qu√© usar Prophet para modelar emisiones de CO‚ÇÇ?

### ¬øQu√© es Prophet?

**Prophet** es una herramienta de pron√≥stico de series temporales desarrollada por **Facebook (Meta)**. Est√° pensada para:

- Modelar **tendencias no lineales**.
- Capturar **cambios de r√©gimen** o inflexiones en la evoluci√≥n hist√≥rica.
- Incluir opcionalmente **estacionalidades** (diarias, semanales, anuales).
- Ser **f√°cil de usar** para analistas sin conocimientos avanzados en estad√≠stica.

---

### üìê Descomposici√≥n del modelo Prophet

Prophet representa la serie temporal con la siguiente f√≥rmula:
    * y(t) = g(t) + s(t) + h(t) + Œµ‚Çú


Donde:

- `g(t)` ‚Üí Tendencia (puede ser lineal o log√≠stica, con posibles **cambios de pendiente**).
- `s(t)` ‚Üí Estacionalidad (opcional, puede ser anual, semanal, diaria).
- `h(t)` ‚Üí Efectos por fechas especiales (festivos, eventos).
- `Œµ‚Çú` ‚Üí Ruido aleatorio (residuo no explicado).

---

### üß† Ventajas de Prophet aplicadas a tu dataset

| Beneficio clave                        | ¬øPor qu√© importa en tu dataset?                                                                                              |
|----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|
| Captura **cambios de tendencia**       | Las emisiones no evolucionan linealmente. Prophet detecta **cambios de pendiente autom√°ticamente**, lo que ARIMA no hace bien. |
| No requiere **estacionariedad**        | Prophet **no exige diferenciar** ni transformar la serie. SARIMA s√≠, y esto puede distorsionar el significado del pron√≥stico. |
| Funciona bien con **datos anuales**    | Las series son anuales. Prophet acepta f√°cilmente series con cualquier frecuencia sin reconfigurar nada.                      |
| Maneja bien la **incertidumbre**       | Prophet devuelve autom√°ticamente **intervalos de confianza del 95%**, facilitando la comunicaci√≥n de riesgo/incertidumbre.    |
| Automatizable por regi√≥n               | Se puede aplicar el mismo modelo a cada continente sin tunear manualmente los par√°metros. Ideal para **automatizaci√≥n**.      |
| Interpretabilidad de componentes       | Prophet permite ver **la tendencia sola**, algo √∫til para an√°lisis visual y argumentaci√≥n.                                    |


""")

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import logging
import warnings

from prophet import Prophet
from sklearn.metrics import mean_squared_error, mean_absolute_error

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Silenciar Prophet y CmdStanPy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.getLogger('prophet').setLevel(logging.CRITICAL)
logging.getLogger('cmdstanpy').setLevel(logging.CRITICAL)
warnings.filterwarnings("ignore")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Simulaci√≥n de series por regi√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
np.random.seed(42)
fechas = pd.date_range(start='1990', periods=30, freq='Y')
regiones = {
    'Am√©rica': np.linspace(1e6, 1.5e7, 30) + np.random.normal(0, 5e5, 30),
    'Asia':    np.linspace(2e6, 1.2e7, 30) + np.random.normal(0, 4e5, 30),
    'Europa':  np.linspace(5e6, 6e6, 30)   + np.random.normal(0, 2e5, 30),
    'Ocean√≠a': np.linspace(3e6, 4e6, 30)   + np.random.normal(0, 1.5e5, 30),
    '√Åfrica':  np.linspace(2e6, 8e6, 30)   + np.random.normal(0, 3e5, 30),
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Setup gr√°fico ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("## üåé Predicci√≥n de emisiones por regi√≥n con Prophet")
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

resultados = {}

for i, (nombre, valores) in enumerate(regiones.items()):
    df = pd.DataFrame({'ds': fechas, 'y': valores})

    # Divisi√≥n en train/test
    split_idx = int(len(df) * 0.8)
    df_train = df.iloc[:split_idx]
    df_test = df.iloc[split_idx:]

    # Entrenamiento
    model = Prophet()
    model.fit(df_train)

    # Crear 21 a√±os futuros
    future = model.make_future_dataframe(periods=21, freq='Y')
    forecast = model.predict(future)

    # Extraer solo predicciones para test
    forecast_test = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(len(df_test)).reset_index(drop=True)
    df_test = df_test.reset_index(drop=True)

    # M√©tricas
    y_true = df_test['y'].values
    y_pred = forecast_test['yhat'].values
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    resultados[nombre] = {'RMSE': rmse, 'MAE': mae}

    # Gr√°fico
    ax = axes[i]
    ax.plot(df_train['ds'], df_train['y'], label='Train', color='blue')
    ax.plot(df_test['ds'], df_test['y'], label='Test', color='black')
    ax.plot(forecast_test['ds'], forecast_test['yhat'], label='Predicci√≥n', linestyle='--', color='red')
    ax.fill_between(forecast_test['ds'], forecast_test['yhat_lower'], forecast_test['yhat_upper'],
                    color='pink', alpha=0.3, label='IC 95%')
    ax.set_title(f'{nombre}\nRMSE: {rmse:,.0f} | MAE: {mae:,.0f}')
    ax.set_xlabel('Fecha')
    ax.set_ylabel('Valor')
    ax.legend()
    ax.grid(True)

# Si hay subplots vac√≠os, desactivarlos
for j in range(i + 1, len(axes)):
    axes[j].axis('off')

plt.tight_layout()
st.pyplot(fig)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Mostrar tabla de m√©tricas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("## üìä Resumen de m√©tricas por regi√≥n")
df_resultados = pd.DataFrame(resultados).T.round(2)
st.dataframe(df_resultados, use_container_width=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Conclusi√≥n final ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.markdown("""
## üìå Conclusi√≥n general del modelo Prophet (Predicci√≥n hasta 2040)

Evaluando el modelo Prophet aplicado a cada una de las regiones del dataset, se obtuvieron las siguientes m√©tricas de error:

| Regi√≥n   | RMSE (Ra√≠z del Error Cuadr√°tico Medio) | MAE (Error Absoluto Medio) |
|----------|-----------------------------------------|-----------------------------|
| Europa   | **569.939,45**                          | **558.454,39**              |
| Ocean√≠a  | 631.438,21                               | 624.085,50                  |
| √Åfrica   | 3.042.076,37                             | 3.030.549,65                |
| Asia     | 4.886.453,21                             | 4.873.406,49                |
| Am√©rica  | **6.506.793,50**                         | **6.502.227,45**            |

### üîé Observaciones:

- **Europa** y **Ocean√≠a** presentan los errores m√°s bajos. Especialmente Europa, donde el modelo Prophet se ajusta de forma excelente: RMSE y MAE por debajo de 600 mil unidades.
- En **√Åfrica** y **Asia** los errores son intermedios. Si bien superan los 3 millones, el modelo logra mantener una tendencia razonable.
- **Am√©rica** muestra el peor desempe√±o en t√©rminos de error absoluto. Esto sugiere una mayor variabilidad, posibles outliers o un modelo insuficiente para capturar cambios estructurales.

üìà A pesar de estos niveles de error, las predicciones siguen una **tendencia general coherente** y los **intervalos de confianza (IC 95%)** son estables y razonables hasta el a√±o 2040.
""")



